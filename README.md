# å¼€æºè¯­è¨€æ¨¡å‹ç™¾å®è¢‹ (Ver. 3.4)
Open-Source Language Model Pocket

ğŸ‡æ˜¥èŠ‚éƒ½å®‰å¥½ï¼Œæ‰€æƒ³çš†å¦‚æ„¿ğŸ‡

ğŸ‡All the best for the Spring FestivalğŸ‡

ğŸ‡May all your wishes come trueğŸ‡

**Github**: https://github.com/createmomo/Open-Source-Language-Model-Pocket

## å¼€æºæ¨¡å‹ä¸€è§ˆ (Table of Contents)

*ä¸­æ–‡å‹å¥½æˆ–å›½å†…ä¸»åˆ›çš„å¼€æºæ¨¡å‹ï¼ˆChinese Open Source Language Modelsï¼‰*

|å¤šä¸ªé¢†åŸŸ/é€šç”¨|||
|---|---|---|
|ç™¾å·|ä¸­æ–‡Alpaca Luotuo|ä¸­æ–‡LLaMA&Alpacaå¤§æ¨¡å‹|
|ä¸­æ–‡LLaMA&Alpacaå¤§æ¨¡å‹2|æµè¤Firefly|å‡¤å‡°|
|å¤æ—¦MOSS|å¤æ—¦MOSS-RLHF|æ‚Ÿé“Â·å¤©é¹°Aquila&Aquila2|
|é›…æ„å¤§æ¨¡å‹| é€šä¹‰åƒé—®Qwen| *ã€æ´»å­—3.0ã€‘|
| Anima |BayLing|BELLE|
|Bloom|BiLLa |BLOOMChat176B|
|Chinese-Llama-2-7b (LinkSoul-AI) |GPT2 for Multiple Language |InternLM ä¹¦ç”Ÿãƒ»æµ¦è¯­|
|Llama2-chat-Chinese-50W|Llama2-Chinese (FlagAlpha) |Linlyä¼¶è”è¯´ ä¸­æ–‡ LLaMA1-2 & OpenLLaMA & Falcon å¤§æ¨¡å‹ |
|ChatRWKV|ChatYuan|ChatGLM-6B|
|ChatGLM2-6B|Chinese-Transformer-XL|OpenKG-KnowLLM |
|PromptCLUE|SkyText-Chinese-GPT3|CPM-Bee|
|TigerBot|XVERSE-13B|YuLan-Chat & YuLan-Chat-2|
|Ziya-LLaMA |TechGPT|EVA|
|FLM-101B|TinyLlama|Colossal-LLaMA-2|
|OpenBA (Encoder-Decoder)|Ziya-Reader-13B|Firefly-LLaMA2-Chinese|
|MindLLM|ChatGLM3|Skyworkå¤§æ¨¡å‹|
|Yi-6B/34Bï¼ˆé›¶ä¸€ä¸‡ç‰©ï¼‰|Nanbeige-16Bï¼ˆå—åŒ—é˜-16Bï¼‰|OrionStar-Yi-34B-Chat|
|æº2.0|TechGPT2.0|SUS-Chat-34B|
|Alaya å…ƒè¯†|OpenBuddy|MiniGPT4Qwen|
|ChatLM-Chinese-0.2B|YAYI 2|DeepSeek LLM&MoE|
|MachineMindset(MBTI)|æ˜Ÿè¾°è¯­ä¹‰ï¼ˆç”µä¿¡ï¼‰|Chinese-Mixtral-8x7B|
|Baby-Llama2-Chinese|XVERSE-13B-256K|Eagle 7Bï¼ˆRWKV-v5ï¼‰|
|iFlytekSpark-13B|MiniCPM|é€šä¹‰åƒé—®Qwen1.5|
|*ã€RethinkTinyLMã€‘|*ã€Chinese-Mixtralã€‘||

| åŒ»ç–—å¥åº· |  |  |
|---|---|---|
| æœ¬è‰ |åä½—  |æ‰é¹Š  |
| çµå¿ƒ | å¯çœŸ | å„¿ç«¥æƒ…æ„Ÿé™ªä¼´å¤§æ¨¡å‹â€œå·§æ¿â€ |
| OpenMEDLab æµ¦åŒ»|æ˜åŒ» (MING)ï¼šä¸­æ–‡åŒ»ç–—é—®è¯Šå¤§æ¨¡å‹ (åŸåï¼šMedicalGPT-zh) |æƒ…æ„Ÿå¤§æ¨¡å‹PICA|
|Chinese-Vicuna-medical|MedicalGPT| DISC-MedLLM ï¼ˆå¤æ—¦ï¼‰|
|DoctorGLM|ChatMed-TCM&ChatMed-Consult|ChatGLM-Med|
|MeChat|ShenNong-TCM-LLM|MindChat(æ¼«è°ˆ): å¿ƒç†å¤§æ¨¡å‹|
|WiNGPT|CareGPT|å­™æ€é‚ˆ|
|MolGenï¼ˆè¯ç‰©ç ”å‘ï¼‰|Taiyiï¼ˆå¤ªä¸€ï¼‰|MedAgents|
|Molecule Optimization|*ã€MolTCã€‘|*ã€Mol-Instructionsã€‘|
|*ã€Multilingual Medicineã€‘|||

|ç»æµ/é‡‘è|||
|---|---|---|
|è²”è²…FinMA & PIXIU: A Large Language Model, Instruction Data and Evaluation Benchmark for Finance|è½©è¾•|BBT-FinCUGE-Applications|
|Cornucopia-LLaMA-Fin-Chinese|EcomGPT|FinGLM|
|DISC-FinLLM|*ã€Deepmoneyã€‘||

|æ³•å¾‹|||
|---|---|---|
| éŸ©é HanFei| æ™ºæµ· å½•é—®|ChatLaw æ³•å¾‹å¤§æ¨¡å‹|
|LaWGPT|Lawyer LLaMA|LexiLaw|
|LawGPT_zh|å¤«å­â€¢æ˜å¯Ÿå¸æ³•å¤§æ¨¡å‹|DISC-LawLLM|
|LawBench|||

|äº¤é€š|
|---|
|TransGPT Â· è‡´è¿œ|

|æ•™è‚²&æ•°å­¦||
|---|---|
|æ¡ƒæ|EduChat|
|chatglm-maths|Abel|
|InternLM-Math|DeepSeekMath|

|è¡¨æ ¼/æ•°æ®åˆ†æ||
|---|---|
|TableGPT|Data-Copilot|
|Tabular LLM||

|è‡ªåª’ä½“&è§’è‰²æ‰®æ¼”|
|---|
|MediaGPT|
|CharacterGLM-6B|
|Haruhi-Zero|

|å¤æ±‰è¯­|
|---|
|å°”é›… Erya|
|è€å­|

|ç¼–ç¨‹/ä»£ç /Agent|
|---|
|CodeShell|
|CODEFUSION-75M|
|DeepSeek Coder|
|DevOps-Modelï¼ˆè¿ç»´ï¼‰|
|Magicoder|
|KwaiAgents|
|LLaMA-Pro|
|HuixiangDou|
|*ã€CodeActã€‘|

|å¤©æ–‡/æµ·æ´‹/åœ°çƒç§‘å­¦/ç§‘å­¦|
|---|
|æ˜Ÿè¯­StarWhisper|
|OceanGPT|
|K2&GeoGalactica|
|SciGLM|

*å¯å‚è€ƒçš„å…¶å®ƒå¼€æºæ¨¡å‹*
|  |  |
|---|---|
| Cerebras | MPT-7B |
| ChatDoctor | OpenGPT |
| Code Llama (Meta AI)| Orca |
| Dolly 1&2 | OpenChatKit |
| FinGPT | Open-Assistant |
| Falcon | Platypus|
| Facebook/Meta LLaMA/LLaMA2 | MedLLaMA-13B & PMC-LLaMA: Continue Training LLaMA on Medical Papers |
| Giraffe| RedPajama |
| GALACTICA | SQLCoder (Defog)|
| Goar-7B for Arithmetic Tasks | StableLM |
| HuggingChat | StableVicuna |
| Koala: A Dialogue Model for Academic Research | Stanford Alpaca |
| LongLLaMA | UltraLM-13B |
| LLaMAå¤åˆ»ç‰ˆOpenLLaMA | Vicuna: An Open-Source Chatbot Impressing GPT-4 with 90% ChatGPT Quality |
| Llama-X: Open Academic Research on Improving LLaMA to SOTA LLM | Wombat |
| Lit-LLaMA ï¸ | WizardMath|
| MammoTH | XGen-7B |
|Mistral 7B|Xwin-LM|
|LLaMA 2 Long|UltraLM-13B (UltraFeedback)|
|Llemma: An Open Language Model For Mathematics|Mistral-Trismegistus-7B ï¼ˆç¥ç§˜å­¦/ç„å­¦/çµæ€§ï¼‰|
|Memory-GPT(MemGPT)|MetaMath|
|ChipNeMo (èŠ¯ç‰‡è®¾è®¡)|Zephyr|
|neural-chat-7b-v3-1ï¼ˆIntelï¼‰|SteerLM|
|Llama Coder|Meditron|
|RankZephyr|StableLM Zephyr 3B|
|Orca 2|Mixtral 7b 8 Expert|
|Phi|LLM360ï¼ˆAmber,CrystalCoder,Diamondï¼‰|
|Mamba|SOLAR|
|NexusRavenï¼ˆfunction calling LLMï¼‰|LLaMA-MoE|
|TinyLlama|Nous-Hermes-2 Mixtral 8x7B|
|AlphaGeometry|MoE-Mamba|
|StarCoder|OLMo|
|H2O-Danube-1.8B|*ã€OpenMathInstruct-1ã€‘|
|*ã€Smaug-72Bã€‘|*ã€Gemmaã€‘|
|*ã€Aya Modelã€‘|*ã€MobiLlamaã€‘|
|*ã€StarCoder2ã€‘|*ã€SmallLanguageModel-projectã€‘|
|*ã€Command-Rã€‘||

*è®­ç»ƒ/æ¨ç†*
|  |  |
|---|---|
| Alpaca-LoRA | llama2.mojo |
| AlpacaFarm | LightLLM |
| ColossalAI | Medusa |
| ChatLLaMA | Megatron-LLaMA |
| Chinese-Guanaco | MeZO: Fine-Tuning Language Models with Just Forward Passes |
| DPO (Direct Preference Optimization) | MLC LLM |
| DialogADVï¼šEvaluate What You Can't Evaluate: Unassessable Generated Responses Quality | PKU-Beaver æ²³ç‹¸ (Safe RLHF) |
| DeepSpeed-Chat | PaLM + RLHF (Pytorch) |
| FlexGen | RL4LMs |
| FlagAI and FlagData | Reinforcement Learning with Language Model |
| Guanaco & QloRA | SpQR: A Sparse-Quantized Representation for Near-Lossless LLM Weight Compression |
| GPT4All | Scikit-LLM: Sklearn Meets Large Language Models |
| HugNLP | Transformer Reinforcement Learning |
| INSTRUCTEVAL | Train_Transformers_with_INT4 |
| LOw-Memory Optimization (LOMO) | Transformer Reinforcement Learning X |
| llama.cpp | vLLM |
| llama2.c | LongLoRA |
|RLLTE: Long-Term Evolution Project of Reinforcement Learning|FlashAttention|
|ExecuTorch|TensorRT-LLM|
|BPOï¼ˆBlack-Box Prompt Optimizationï¼‰|S-LoRA|
|SoRA|XuanCe(ç„ç­–): å¼€æºçš„æ·±åº¦å¼ºåŒ–å­¦ä¹ (DRL)åº“|
|EasyLMï¼ˆJAX/Flaxï¼‰|FATE-LLM - Federated Learning for LLMs|
|DeepSpeed-FastGen|NVIDIA NeMo-Aligner|
|RLAIF: Scaling Reinforcement Learning from Human Feedback with AI Feedback|MLX|
|OpenRLHF|CoLLiE: Collaborative Training of Large Language Models in an Efficient Way|
|Superalignment|LLMLingua: Compressing Prompts for Accelerated Inference of Large Language Models|
|Large Language Model Unlearning|PowerInfer|
|m-LoRA|LASER|
|StripedHyena-7B|SwiftInfer|
|SPINï¼ˆSelf-Play Fine-Tuning Converts Weak Language Models to Strong Language Modelsï¼‰|Self-Rewarding Language Models|
|OPOï¼ˆOn-the-fly Preference Optimizationï¼‰|ASPIRE|
|The Impact of Reasoning Step Length on Large Language Models|SliceGPT|
|FuseLLM|Tree of Thoughts|
|CogGPT|KTOï¼ˆKahneman-Tversky Optimisationï¼‰|
|Aligner|RPOï¼ˆRobust Prompt Optimizationï¼‰|
|Inference-Time Training Helps Long Text Generation|LiPO|
|ChatLLM.cpp|Self-Discover|
|*ã€DoRAã€‘|*ã€GPOï¼ˆGeneralized Preference Optimizationï¼‰ã€‘|
|*ã€CoT-decodingã€‘||

*è¯„ä»·*
|  ||
|---|---|
| å¤©ç§¤ï¼ˆFlagEvalï¼‰ |ç¬è±¸ï¼ˆXiezhiï¼‰Benchmark |
| C-Eval: A Multi-Level Multi-Discipline Chinese Evaluation Suite for Foundation Models | HaluEval: A Large-Scale Hallucination Evaluation Benchmark for Large Language Models|
| KoLA: Carefully Benchmarking World Knowledge of Large Language Models |LucyEvalâ€”ä¸­æ–‡å¤§è¯­è¨€æ¨¡å‹æˆç†Ÿåº¦è¯„æµ‹|
|CMB: A Comprehensive Medical Benchmark in Chinese|Multiscale Positive-Unlabeled Detection of AI-Generated Texts |
| PandaLM |Auto-J|
|CLEVA: Chinese Language Models EVAluation Platform|ALCUNA: Large Language Models Meet New Knowledge|
|HalluQAï¼šEvaluating Hallucinations in Chinese Large Language Models|GLoRE: Evaluating Logical Reasoning of Large Language Models|
|HelpSteer|AlignBench: å¤šç»´åº¦ä¸­æ–‡å¯¹é½è¯„æµ‹åŸºå‡†|
|UHGEval|Purple Llama (Meta)|
|OMGEval|SciGuard&SciMT-Safety|
|HaluEval 2.0, The Dawn After the Dark: An Empirical Study on Factuality Hallucination in Large Language Models|DebugBench: Evaluating Debugging Capability of Large Language Models|GenMedicalEval|
|R-Judge|TravelPlanner|
|EasyJailbreak|AgentBench|
|*ã€ä¸­æ–‡MT-Benchã€‘|*ã€E-EVALã€‘|
|*ã€ConflictingQAã€‘|*ã€Medical Information Retrieval-Augmented Generation Evaluation ï¼ˆMIRAGEï¼‰ã€‘|
|*ã€âˆBenchã€‘|*ã€Red Teaming Resistance Benchmarkã€‘|

*æ–‡æœ¬å‘é‡*
|  |  |
|---|---|
| Matryoshka Representation Learning |Jina Embeddings|
|BGE-M3|Nomic Embed|
|Moka Massive Mixed Embeddingï¼ˆM3Eï¼‰|*ã€GRITã€‘|

*Agent*
|  |  |
|---|---|
| Auto-GPT | ToolBench&ToolLLM |
|HuggingGPT |CAMEL:Communicative Agents for â€œMindâ€ Exploration of Large Scale Language Model Society|
|AgentLM (AgentTuning, AgentInstruct) |XAgent|
|OpenAgents|Personal LLM Agents - Survey|
|AUTOACT|MetaGPT|
|Multi-LLM-Agent|*ã€More Agents Is All You Needã€‘|
|*ã€Mistral-Interactã€‘|*ã€AgentLiteã€‘|
|*ã€KnowAgentã€‘|*ã€LlamaGymã€‘|
|*ã€WorkArenaã€‘||

*å…¶å®ƒ*
|  |  |
|---|---|
| Alpaca-CoT | Self-Instruct |
| ChatPiXiu | Wanda (Pruning by Weights and activations) |
| Gorilla | Streaming LLM |
| Sheared LLAMA (Structured Pruning) |gpu_poor|
| LLMPrunerï¼šå¤§è¯­è¨€æ¨¡å‹è£å‰ªå·¥å…· | QA-LoRA |
| LLM-Pruner: On the Structural Pruning of Large Language Models | LLM for Recommendation Systems |
|Transformer Index for GEnerative Recommenders (TIGER)|KnowPAT|
|AuthentiGPT: Detecting Machine-Generated Text|Curiosity-driven Red-teaming for Large Language Models|Language Models are Super Marioï¼ˆDARE, Drop And REscaleï¼‰|
|TinyGSM|MathPile|
|Blending Is All You Need: Cheaper, Better Alternative to Trillion-Parameters LLM|Unlocking Efficiency in Large Language Model Inference: A Comprehensive Survey of Speculative Decoding|
|QAnything|Meta-Prompting|
|Lepton Search|RLMRec|
|*ã€Open-Source AI Cookbookã€‘|*ã€MaLA-500ã€‘|
|*ã€NVIDIA Chat with RTXã€‘|*ã€RAG vs Fine-tuningã€‘|
|*ã€Chain of Abstractionã€‘|*ã€åºåˆ—çŒ´å­å¼€æºæ•°æ®é›†ã€‘|
|*ã€Transformer Debuggerã€‘|*ã€RecAIã€‘|

## ç›¸å…³æ–‡ç« 
- ç©·ç©·ç©·å­©å­å¦‚ä½•ä½“éªŒColossalAI SFTï¼ˆ[Kaggleç¯‡](https://mp.weixin.qq.com/s/Q29uSNxvPMy0rC-QxHiGZA)ï¼Œ[Colabç¯‡](https://mp.weixin.qq.com/s/NS4yySeYd7QUYb7CB9V0lA)ï¼‰
- [é€šä¿—ç†è§£æ–‡æœ¬ç”Ÿæˆçš„å¸¸ç”¨è§£ç ç­–ç•¥](https://mp.weixin.qq.com/s/sVZuEkYXQ9ZZYXJCQz7F4A)
- [é€šä¿—ç†è§£P-tuning (GPT Understands)](https://mp.weixin.qq.com/s/EvD9OW115XMnrxOcC2BKDA)
- [é€šä¿—ç†è§£Gradient Checkpointï¼ˆé™„ä»£ç ï¼‰](https://mp.weixin.qq.com/s/IwcfUP_j6JYFXH_xhnWWJQ)
- åƒâ€œå‚â€ç™¾ç‚¼ï¼šå‚ç›´é¢†åŸŸä¸è¯­è¨€æ¨¡å‹
  - [å¯¼è¯­](https://mp.weixin.qq.com/s/G24skuUbyrSatxWczVxEAg)
  - è·å¾—å¯ç”¨çš„å‚ç›´é¢†åŸŸæ•°æ®
    - ã€ä¸é™é¢†åŸŸã€‘[åˆ©ç”¨æœªæ ‡æ³¨æ–‡æœ¬æ”¹è¿›éµå¾ªæŒ‡ä»¤çš„è¯­è¨€æ¨¡å‹ (1) Instruction Backtranslation ç®€ä»‹](https://mp.weixin.qq.com/s/50wtP--W_cy-682g8cOYww)
    - ã€åŒ»ç–—/å¥åº·ã€‘ChatDoctor ï¼ˆè§£è¯» [ä¸Š](https://mp.weixin.qq.com/s/zSeRKUZ2te1wxwpvByhcvg) [ä¸­](https://mp.weixin.qq.com/s/TcwiQoIex7SDY5Teri9xnw) [ä¸‹](https://mp.weixin.qq.com/s/I1hXRS7gBMLUyOWMObfpBg) / PDFç‰ˆPPT [ä¸Š](https://github.com/createmomo/Open-Source-Language-Model-Pocket/blob/main/%E5%8D%83%E2%80%9C%E5%9E%82%E2%80%9D%E7%99%BE%E7%82%BC%20-%20%E3%80%90%E5%8C%BB%E7%96%97%26%E5%81%A5%E5%BA%B7%E3%80%91%20ChatDoctor%EF%BC%88%E4%B8%8A%EF%BC%89.pdf) [ä¸­](https://github.com/createmomo/Open-Source-Language-Model-Pocket/blob/main/%E5%8D%83%E2%80%9C%E5%9E%82%E2%80%9D%E7%99%BE%E7%82%BC%20-%20%E3%80%90%E5%8C%BB%E7%96%97%26%E5%81%A5%E5%BA%B7%E3%80%91%20ChatDoctor%EF%BC%88%E4%B8%AD%EF%BC%89.pdf) [ä¸‹](https://github.com/createmomo/Open-Source-Language-Model-Pocket/blob/main/%E5%8D%83%E2%80%9C%E5%9E%82%E2%80%9D%E7%99%BE%E7%82%BC%20-%20%E3%80%90%E5%8C%BB%E7%96%97%26%E5%81%A5%E5%BA%B7%E3%80%91%20ChatDoctor%EF%BC%88%E4%B8%8B%EF%BC%89.pdf)ï¼‰
    - ã€åŒ»ç–—/å¥åº·ã€‘MedicalGPT-zh ([è§£è¯»](https://mp.weixin.qq.com/s/QJKZYKh16fqLTC367WhzdA) / [PDFç‰ˆPPT](https://github.com/createmomo/Open-Source-Language-Model-Pocket/blob/main/%E5%8D%83%E2%80%9C%E5%9E%82%E2%80%9D%E7%99%BE%E7%82%BC%20-%20%E3%80%90%E5%8C%BB%E7%96%97%26%E5%81%A5%E5%BA%B7%E3%80%91%20MedicalGPT-zh.pdf))
    - ã€åŒ»ç–—/å¥åº·ã€‘æ˜åŒ»(MING) ([è§£è¯»](https://mp.weixin.qq.com/s/uM4FZeDhAc6JuMlW7NCvUA) / [PDFç‰ˆPPT](https://github.com/createmomo/Open-Source-Language-Model-Pocket/blob/main/%E5%8D%83%E2%80%9C%E5%9E%82%E2%80%9D%E7%99%BE%E7%82%BC%20-%20%E3%80%90%E5%8C%BB%E7%96%97%26%E5%81%A5%E5%BA%B7%E3%80%91%20MING.pdf))
    - ã€åŒ»ç–—/å¥åº·ã€‘çµå¿ƒ(SoulChat) ([è§£è¯»](https://mp.weixin.qq.com/s/0HOYSr-zQsGLFL_H9UZ2HA) / [PDFç‰ˆPPT](https://github.com/createmomo/Open-Source-Language-Model-Pocket/blob/main/%E5%8D%83%E2%80%9C%E5%9E%82%E2%80%9D%E7%99%BE%E7%82%BC%20-%20%E3%80%90%E5%8C%BB%E7%96%97%26%E5%81%A5%E5%BA%B7%E3%80%91%20SoulChat.pdf))
  - è‡ªåŠ¨è¯„ä¼°æ¨¡å‹
    - ã€ä¸é™é¢†åŸŸã€‘[ç”¨è¯­è¨€æ¨¡å‹è¯„ä¼°è¯­è¨€æ¨¡å‹ï¼ˆ1ï¼‰å¯¼è¯­](https://mp.weixin.qq.com/s/SUN_ywkI8ld1edXY7uq_1Q)
    - ã€ä¸é™é¢†åŸŸã€‘[ç”¨è¯­è¨€æ¨¡å‹è¯„ä¼°è¯­è¨€æ¨¡å‹ï¼ˆ2ï¼‰PandaLM](https://mp.weixin.qq.com/s/NTFu53MdVD9NusFJaORHcw)
    - ã€ä¸é™é¢†åŸŸã€‘ç”¨è¯­è¨€æ¨¡å‹è¯„ä¼°è¯­è¨€æ¨¡å‹ï¼ˆ3ï¼‰Shepherdï¼ˆ[1](https://mp.weixin.qq.com/s/pbK1Zsv9j_DVtOJaTm_tPw) [2](https://mp.weixin.qq.com/s/n4_kVw8j42ZQv6VjQ_P-Dw) [3](https://mp.weixin.qq.com/s/PeGJOmQPyAhwl7czJgKnQQ) [4](https://mp.weixin.qq.com/s/7_NX7S2AHabX-xU254sq5g)ï¼‰
    - ã€åŒ»ç–—/å¥åº·ã€‘[ä½¿ç”¨BERT-Scoreæ¯”è¾ƒChatDoctorä¸ChatGPT3.5](https://mp.weixin.qq.com/s/I1hXRS7gBMLUyOWMObfpBg)

---

## 1 Chinese Open Source Language Models

### æœ¬è‰
- https://zhuanlan.zhihu.com/p/626536996
- https://github.com/scir-hi/huatuo-llama-med-chinese

åŸºäºä¸­æ–‡åŒ»å­¦çŸ¥è¯†çš„LLaMaæŒ‡ä»¤å¾®è°ƒæ¨¡å‹

åœ¨ç”Ÿç‰©åŒ»å­¦é¢†åŸŸï¼ŒLLMæ¨¡å‹ï¼ˆå¦‚LLaMaï¼ŒChatGLMï¼‰å› ä¸ºç¼ºä¹ä¸€å®šçš„åŒ»å­¦ä¸“ä¸šçŸ¥è¯†è¯­æ–™è€Œè¡¨ç°ä¸ä½³ã€‚è¯¥é¡¹ç›®é€šè¿‡åŒ»å­¦çŸ¥è¯†å›¾è°±å’ŒGPT3.5APIæ„å»ºäº†ä¸­æ–‡åŒ»å­¦æŒ‡ä»¤æ•°æ®é›†ï¼Œå¹¶å¯¹LLaMaæ¨¡å‹è¿›è¡Œäº†æŒ‡ä»¤å¾®è°ƒå¾—åˆ°äº†ä¸€ä¸ªé’ˆå¯¹åŒ»å­¦é¢†åŸŸçš„æ™ºèƒ½é—®è¯Šæ¨¡å‹HuaTuoï¼Œç›¸æ¯”äºæœªç»è¿‡åŒ»å­¦æ•°æ®æŒ‡ä»¤å¾®è°ƒçš„åŸLLaMaè€Œè¨€ï¼ŒHuaTuoæ¨¡å‹åœ¨æ™ºèƒ½é—®è¯Šå±‚é¢è¡¨ç°å‡ºè‰²ï¼Œå¯ç”Ÿæˆä¸€äº›æ›´ä¸ºå¯é çš„åŒ»å­¦çŸ¥è¯†å›ç­”ï¼›ä¸æ­¤åŒæ—¶ï¼ŒåŸºäºç›¸åŒåŒ»å­¦æ•°æ®ï¼Œè¯¥é¡¹ç›®è¿˜è®­ç»ƒäº†åŒ»ç–—ç‰ˆæœ¬çš„ChatGLMæ¨¡å‹: ChatGLM-6B-Medï¼Œ

è¯¥å›¢é˜Ÿè¿˜å³å°†å‘å¸ƒæ‰é¹Šæ¨¡å‹PienChueh(åŒä¸ºåŸºäºåŒ»å­¦æ•°æ®è®­ç»ƒçš„å¤§æ¨¡å‹)ï¼Œæ¬¢è¿å¤§å®¶å±Šæ—¶ä½¿ç”¨ä½“éªŒã€‚

### ç™¾å· Baichuan-7B
- https://github.com/baichuan-inc/baichuan-7B
- https://huggingface.co/baichuan-inc/baichuan-7B

baichuan-7B æ˜¯ç”±ç™¾å·æ™ºèƒ½å¼€å‘çš„ä¸€ä¸ªå¼€æºå¯å•†ç”¨çš„å¤§è§„æ¨¡é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹ã€‚åŸºäº Transformer ç»“æ„ï¼Œåœ¨å¤§çº¦1.2ä¸‡äº¿ tokens ä¸Šè®­ç»ƒçš„70äº¿å‚æ•°æ¨¡å‹ï¼Œæ”¯æŒä¸­è‹±åŒè¯­ï¼Œä¸Šä¸‹æ–‡çª—å£é•¿åº¦ä¸º4096ã€‚åœ¨æ ‡å‡†çš„ä¸­æ–‡å’Œè‹±æ–‡æƒå¨ benchmarkï¼ˆC-EVAL/MMLUï¼‰ä¸Šå‡å–å¾—åŒå°ºå¯¸æœ€å¥½çš„æ•ˆæœã€‚

åŸå§‹æ•°æ®åŒ…æ‹¬å¼€æºçš„ä¸­è‹±æ–‡æ•°æ®å’Œè‡ªè¡ŒæŠ“å–çš„ä¸­æ–‡äº’è”ç½‘æ•°æ®ï¼Œä»¥åŠéƒ¨åˆ†é«˜è´¨é‡çŸ¥è¯†æ€§æ•°æ®ã€‚

å‚è€ƒç›¸å…³æ•°æ®å·¥ä½œï¼Œé¢‘ç‡å’Œè´¨é‡æ˜¯æ•°æ®å¤„ç†ç¯èŠ‚é‡ç‚¹è€ƒè™‘çš„ä¸¤ä¸ªç»´åº¦ã€‚ æˆ‘ä»¬åŸºäºå¯å‘å¼è§„åˆ™å’Œè´¨é‡æ¨¡å‹æ‰“åˆ†ï¼Œå¯¹åŸå§‹æ•°æ®é›†è¿›è¡Œç¯‡ç« å’Œå¥å­ç²’åº¦çš„è¿‡æ»¤ã€‚åœ¨å…¨é‡æ•°æ®ä¸Šï¼Œåˆ©ç”¨å±€éƒ¨æ•æ„Ÿå“ˆå¸Œæ–¹æ³•ï¼Œå¯¹ç¯‡ç« å’Œå¥å­ç²’åº¦åšæ»¤é‡ã€‚

### åä½—
- https://mp.weixin.qq.com/s/lwJb8N420xfMTvXJPM2gtg
- https://arxiv.org/pdf/2305.15075.pdf
- https://github.com/FreedomIntelligence/HuatuoGPT
- https://www.huatuogpt.cn/ 

è¯¥è®ºæ–‡æå‡ºçš„è¯­è¨€æ¨¡å‹è®­ç»ƒæ–¹æ³•å¯ä»¥ç»“åˆåŒ»ç”Ÿå’Œ ChatGPT çš„æ•°æ®ï¼Œå……åˆ†å‘æŒ¥å®ƒä»¬çš„äº’è¡¥ä½œç”¨ï¼Œæ—¢ä¿ç•™çœŸå®åŒ»ç–—æ•°æ®çš„ä¸“ä¸šæ€§å’Œå‡†ç¡®æ€§ï¼Œåˆå€ŸåŠ© ChatGPT çš„å¤šæ ·æ€§å’Œå†…å®¹ä¸°å¯Œæ€§çš„ç‰¹ç‚¹ã€‚

### æ‰é¹Š
- https://github.com/scutcyr/BianQue

åŸºäºä¸»åŠ¨å¥åº·çš„ä¸»åŠ¨æ€§ã€é¢„é˜²æ€§ã€ç²¾ç¡®æ€§ã€ä¸ªæ€§åŒ–ã€å…±å»ºå…±äº«ã€è‡ªå¾‹æ€§å…­å¤§ç‰¹å¾ï¼Œåå—ç†å·¥å¤§å­¦æœªæ¥æŠ€æœ¯å­¦é™¢-å¹¿ä¸œçœæ•°å­—å­ªç”Ÿäººé‡ç‚¹å®éªŒå®¤å¼€æºäº†ä¸­æ–‡é¢†åŸŸç”Ÿæ´»ç©ºé—´ä¸»åŠ¨å¥åº·å¤§æ¨¡å‹åŸºåº§ProactiveHealthGPTï¼ŒåŒ…æ‹¬ï¼š
- ç»è¿‡åƒä¸‡è§„æ¨¡ä¸­æ–‡å¥åº·å¯¹è¯æ•°æ®æŒ‡ä»¤å¾®è°ƒçš„ç”Ÿæ´»ç©ºé—´å¥åº·å¤§æ¨¡å‹æ‰é¹Šï¼ˆBianQueï¼‰
- ç»è¿‡ç™¾ä¸‡è§„æ¨¡å¿ƒç†å’¨è¯¢é¢†åŸŸä¸­æ–‡é•¿æ–‡æœ¬æŒ‡ä»¤ä¸å¤šè½®å…±æƒ…å¯¹è¯æ•°æ®è”åˆæŒ‡ä»¤å¾®è°ƒçš„å¿ƒç†å¥åº·å¤§æ¨¡å‹çµå¿ƒï¼ˆSoulChatï¼‰

æˆ‘ä»¬æœŸæœ›ï¼Œç”Ÿæ´»ç©ºé—´ä¸»åŠ¨å¥åº·å¤§æ¨¡å‹åŸºåº§ProactiveHealthGPT å¯ä»¥å¸®åŠ©å­¦æœ¯ç•ŒåŠ é€Ÿå¤§æ¨¡å‹åœ¨æ…¢æ€§ç—…ã€å¿ƒç†å’¨è¯¢ç­‰ä¸»åŠ¨å¥åº·é¢†åŸŸçš„ç ”ç©¶ä¸åº”ç”¨ã€‚æœ¬é¡¹ç›®ä¸º ç”Ÿæ´»ç©ºé—´å¥åº·å¤§æ¨¡å‹æ‰é¹Šï¼ˆBianQueï¼‰ ã€‚

### çµå¿ƒï¼ˆSoulChatï¼‰
- https://github.com/scutcyr/SoulChat

æˆ‘ä»¬è°ƒç ”äº†å½“å‰å¸¸è§çš„å¿ƒç†å’¨è¯¢å¹³å°ï¼Œå‘ç°ï¼Œç”¨æˆ·å¯»æ±‚åœ¨çº¿å¿ƒç†å¸®åŠ©æ—¶ï¼Œé€šå¸¸éœ€è¦è¿›è¡Œè¾ƒé•¿ç¯‡å¹…åœ°è¿›è¡Œè‡ªæˆ‘æè¿°ï¼Œç„¶åæä¾›å¸®åŠ©çš„å¿ƒç†å’¨è¯¢å¸ˆåŒæ ·åœ°æä¾›é•¿ç¯‡å¹…çš„å›å¤ï¼Œç¼ºå¤±äº†ä¸€ä¸ªæ¸è¿›å¼çš„å€¾è¯‰è¿‡ç¨‹ã€‚ä½†æ˜¯ï¼Œåœ¨å®é™…çš„å¿ƒç†å’¨è¯¢è¿‡ç¨‹å½“ä¸­ï¼Œç”¨æˆ·å’Œå¿ƒç†å’¨è¯¢å¸ˆä¹‹é—´ä¼šå­˜åœ¨å¤šè½®æ¬¡çš„æ²Ÿé€šè¿‡ç¨‹ï¼Œåœ¨è¯¥è¿‡ç¨‹å½“ä¸­ï¼Œå¿ƒç†å’¨è¯¢å¸ˆä¼šå¼•å¯¼ç”¨æˆ·è¿›è¡Œå€¾è¯‰ï¼Œå¹¶ä¸”æä¾›å…±æƒ…ï¼Œä¾‹å¦‚ï¼šâ€œéå¸¸æ£’â€ã€â€œæˆ‘ç†è§£ä½ çš„æ„Ÿå—â€ã€â€œå½“ç„¶å¯ä»¥â€ç­‰ç­‰ã€‚

è€ƒè™‘åˆ°å½“å‰ååˆ†æ¬ ç¼ºå¤šè½®å…±æƒ…å¯¹è¯æ•°æ®é›†ï¼Œæˆ‘ä»¬ä¸€æ–¹é¢ï¼Œæ„å»ºäº†è¶…è¿‡15ä¸‡è§„æ¨¡çš„ å•è½®é•¿æ–‡æœ¬å¿ƒç†å’¨è¯¢æŒ‡ä»¤ä¸ç­”æ¡ˆï¼ˆSoulChatCorpus-single_turnï¼‰ ï¼Œå›ç­”æ•°é‡è¶…è¿‡50ä¸‡ï¼ˆæŒ‡ä»¤æ•°æ˜¯å½“å‰çš„å¸¸è§çš„å¿ƒç†å’¨è¯¢æ•°æ®é›† PsyQA çš„6.7å€ï¼‰ï¼Œå¹¶åˆ©ç”¨ChatGPTä¸GPT4ï¼Œç”Ÿæˆæ€»å…±çº¦100ä¸‡è½®æ¬¡çš„ å¤šè½®å›ç­”æ•°æ®ï¼ˆSoulChatCorpus-multi_turnï¼‰ ã€‚ç‰¹åˆ«åœ°ï¼Œæˆ‘ä»¬åœ¨é¢„å®éªŒä¸­å‘ç°ï¼Œçº¯å•è½®é•¿æœ¬æ–‡é©±åŠ¨çš„å¿ƒç†å’¨è¯¢æ¨¡å‹ä¼šäº§ç”Ÿè®©ç”¨æˆ·æ„Ÿåˆ°åŒçƒ¦çš„æ–‡æœ¬é•¿åº¦ï¼Œè€Œä¸”ä¸å…·å¤‡å¼•å¯¼ç”¨æˆ·å€¾è¯‰çš„èƒ½åŠ›ï¼Œçº¯å¤šè½®å¿ƒç†å’¨è¯¢å¯¹è¯æ•°æ®é©±åŠ¨çš„å¿ƒç†å’¨è¯¢æ¨¡å‹åˆ™å¼±åŒ–äº†æ¨¡å‹çš„å»ºè®®èƒ½åŠ›ï¼Œå› æ­¤ï¼Œæˆ‘ä»¬æ··åˆSoulChatCorpus-single_turnå’ŒSoulChatCorpus-multi_turnæ„é€ æˆè¶…è¿‡120ä¸‡ä¸ªæ ·æœ¬çš„ å•è½®ä¸å¤šè½®æ··åˆçš„å…±æƒ…å¯¹è¯æ•°æ®é›†SoulChatCorpus ã€‚æ‰€æœ‰æ•°æ®é‡‡ç”¨â€œç”¨æˆ·ï¼šxxx\nå¿ƒç†å’¨è¯¢å¸ˆï¼šxxx\nç”¨æˆ·ï¼šxxx\nå¿ƒç†å’¨è¯¢å¸ˆï¼šâ€çš„å½¢å¼ç»Ÿä¸€ä¸ºä¸€ç§æŒ‡ä»¤æ ¼å¼ã€‚

æˆ‘ä»¬é€‰æ‹©äº† ChatGLM-6B ä½œä¸ºåˆå§‹åŒ–æ¨¡å‹ï¼Œè¿›è¡Œäº†å…¨é‡å‚æ•°çš„æŒ‡ä»¤å¾®è°ƒï¼Œæ—¨åœ¨æå‡æ¨¡å‹çš„å…±æƒ…èƒ½åŠ›ã€å¼•å¯¼ç”¨æˆ·å€¾è¯‰èƒ½åŠ›ä»¥åŠæä¾›åˆç†å»ºè®®çš„èƒ½åŠ›ã€‚æ›´å¤šè®­ç»ƒç»†èŠ‚è¯·ç•™æ„æˆ‘ä»¬åç»­å‘å¸ƒçš„è®ºæ–‡ã€‚

### å¯çœŸåŒ»å­¦å¤§æ¨¡å‹
- https://github.com/CMKRG/QiZhenGPT

æœ¬é¡¹ç›®åˆ©ç”¨å¯çœŸåŒ»å­¦çŸ¥è¯†åº“æ„å»ºçš„ä¸­æ–‡åŒ»å­¦æŒ‡ä»¤æ•°æ®é›†ï¼Œå¹¶åŸºäºæ­¤åœ¨Chinese-LLaMA-Plus-7Bã€CaMA-13Bã€ChatGLM-6Bæ¨¡å‹ä¸Šè¿›è¡ŒæŒ‡ä»¤ç²¾è°ƒï¼Œå¤§å¹…æé«˜äº†æ¨¡å‹åœ¨ä¸­æ–‡åŒ»ç–—åœºæ™¯ä¸‹æ•ˆæœï¼Œé¦–å…ˆé’ˆå¯¹è¯å“çŸ¥è¯†é—®ç­”å‘å¸ƒäº†è¯„æµ‹æ•°æ®é›†ï¼Œåç»­è®¡åˆ’ä¼˜åŒ–ç–¾ç—…ã€æ‰‹æœ¯ã€æ£€éªŒç­‰æ–¹é¢çš„é—®ç­”æ•ˆæœï¼Œå¹¶é’ˆå¯¹åŒ»æ‚£é—®ç­”ã€ç—…å†è‡ªåŠ¨ç”Ÿæˆç­‰åº”ç”¨å±•å¼€æ‹“å±•ã€‚

### è²”è²…FinMA & PIXIU: A Large Language Model, Instruction Data and Evaluation Benchmark for Finance
- https://github.com/chancefocus/PIXIU
- https://arxiv.org/abs/2306.05443
- https://huggingface.co/spaces/ChanceFocus/FLARE

The advancement of Natural Language Processing (NLP) and machine learning (ML) techniques in financial technology (FinTech) has enabled a diverse set of capabilities from predicting stock price movements to advanced financial analytics. However, to effectively understand the complex financial language and concepts, domain-specific LLMs are necessary.

Despite prior efforts, there is a lack of open-source financial LLMs and benchmarks to evaluate them. Additionally, these models are not fine-tuned to follow natural language instructions, limiting their performance in downstream financial tasks.

To address these gaps, we introduce PIXIU, providing:
- Open-source LLMs tailored for finance called FinMA, by fine-tuning LLaMA with the dataset constructed in PIXIU.
- Large-scale, high-quality multi-task and multi-modal financial instruction tuning data FIT.
- Holistic financial evaluation benchmarks FLARE for assessing financial LLMs.

Key Features
- Open resources: PIXIU openly provides the financial LLM, instruction tuning data, and datasets included in the evaluation benchmark to encourage open research and transparency.
- Multi-task: The instruction tuning data in PIXIU cover a diverse set of financial tasks, including four financial NLP tasks and one financial prediction task.
- Multi-modality: PIXIU's instruction tuning data consist of multi-modality financial data, including time series data from the stock movement prediction task. It covers various types of financial texts, including reports, news articles, tweets, and regulatory filings.
- Diversity: Unlike previous benchmarks focusing mainly on financial NLP tasks, PIXIU's evaluation benchmark includes critical financial prediction tasks aligned with real-world scenarios, making it more challenging.

### ä¸­æ–‡Alpacaæ¨¡å‹Luotuo
- https://sota.jiqizhixin.com/project/luotuo
- https://github.com/LC1332/Luotuo-Chinese-LLM

Alpaca æ˜¯æ–¯å¦ç¦å›¢é˜ŸåŸºäº LLaMA 7B åœ¨ 52k æŒ‡ä»¤ä¸Šå¾®è°ƒå¾—åˆ°çš„æ¨¡å‹ï¼Œèƒ½å‡ºè‰²é€‚åº”å¤šç§è‡ªç„¶è¯­è¨€åº”ç”¨åœºæ™¯ã€‚è¿‘æ—¥æ¥è‡ªå•†æ±¤ç§‘æŠ€å’Œåä¸­ç§‘æŠ€å¤§å­¦å¼€æºä¸­æ–‡è¯­è¨€æ¨¡å‹ Luotuoï¼ŒåŸºäº ChatGPT API ç¿»è¯‘ Alpaca å¾®è°ƒæŒ‡ä»¤æ•°æ®ï¼Œå¹¶ä½¿ç”¨ lora è¿›è¡Œå¾®è°ƒå¾—åˆ°ã€‚ç›®å‰è¯¥é¡¹ç›®å·²å…¬å¼€è®­ç»ƒçš„è¯­æ–™å’Œæ¨¡å‹æƒé‡æ–‡ä»¶ï¼ˆä¸¤ä¸ªå‹å·ï¼‰ï¼Œä¾›å¼€å‘è€…å¯ä½¿ç”¨è‡ªå·±å„ç§å¤§å°çš„è¯­æ–™ï¼Œè®­ç»ƒè‡ªå·±çš„è¯­è¨€æ¨¡å‹ï¼Œå¹¶é€‚ç”¨åˆ°å¯¹åº”çš„å‚ç›´é¢†åŸŸã€‚

### ä¸­æ–‡LLaMA&Alpacaå¤§æ¨¡å‹
- https://github.com/ymcui/Chinese-LLaMA-Alpaca

ä»¥ChatGPTã€GPT-4ç­‰ä¸ºä»£è¡¨çš„å¤§è¯­è¨€æ¨¡å‹ï¼ˆLarge Language Model, LLMï¼‰æ€èµ·äº†æ–°ä¸€è½®è‡ªç„¶è¯­è¨€å¤„ç†é¢†åŸŸçš„ç ”ç©¶æµªæ½®ï¼Œå±•ç°å‡ºäº†ç±»é€šç”¨äººå·¥æ™ºèƒ½ï¼ˆAGIï¼‰çš„èƒ½åŠ›ï¼Œå—åˆ°ä¸šç•Œå¹¿æ³›å…³æ³¨ã€‚ç„¶è€Œï¼Œç”±äºå¤§è¯­è¨€æ¨¡å‹çš„è®­ç»ƒå’Œéƒ¨ç½²éƒ½æä¸ºæ˜‚è´µï¼Œä¸ºæ„å»ºé€æ˜ä¸”å¼€æ”¾çš„å­¦æœ¯ç ”ç©¶é€ æˆäº†ä¸€å®šçš„é˜»ç¢ã€‚

ä¸ºäº†ä¿ƒè¿›å¤§æ¨¡å‹åœ¨ä¸­æ–‡NLPç¤¾åŒºçš„å¼€æ”¾ç ”ç©¶ï¼Œæœ¬é¡¹ç›®å¼€æºäº†ä¸­æ–‡LLaMAæ¨¡å‹å’Œç»è¿‡æŒ‡ä»¤ç²¾è°ƒçš„Alpacaå¤§æ¨¡å‹ã€‚è¿™äº›æ¨¡å‹åœ¨åŸç‰ˆLLaMAçš„åŸºç¡€ä¸Šæ‰©å……äº†ä¸­æ–‡è¯è¡¨å¹¶ä½¿ç”¨äº†ä¸­æ–‡æ•°æ®è¿›è¡ŒäºŒæ¬¡é¢„è®­ç»ƒï¼Œè¿›ä¸€æ­¥æå‡äº†ä¸­æ–‡åŸºç¡€è¯­ä¹‰ç†è§£èƒ½åŠ›ã€‚åŒæ—¶ï¼Œåœ¨ä¸­æ–‡LLaMAçš„åŸºç¡€ä¸Šï¼Œæœ¬é¡¹ç›®ä½¿ç”¨äº†ä¸­æ–‡æŒ‡ä»¤æ•°æ®è¿›è¡ŒæŒ‡ä»¤ç²¾è°ƒï¼Œæ˜¾è‘—æå‡äº†æ¨¡å‹å¯¹æŒ‡ä»¤çš„ç†è§£å’Œæ‰§è¡Œèƒ½åŠ›ã€‚

### ä¸­æ–‡LLaMA&Alpacaå¤§æ¨¡å‹2
- https://github.com/ymcui/Chinese-LLaMA-Alpaca-2
- https://mp.weixin.qq.com/s/s8bOcwRYiRA88kPlJKeAKA
- https://arxiv.org/abs/2304.08177v2

Chinese-LLaMA-Alpaca-2å¤§æ¨¡å‹é¡¹ç›®æ­£å¼å‘å¸ƒv1.0ç‰ˆæœ¬ï¼Œå¼€æºChinese-LLaMA-2-7Bï¼ˆåŸºåº§æ¨¡å‹ï¼‰å’ŒChinese-Alpaca-2-7Bï¼ˆæŒ‡ä»¤/chatæ¨¡å‹ï¼‰ã€‚è¿™äº›æ¨¡å‹åœ¨åŸç‰ˆLlama-2çš„åŸºç¡€ä¸Šæ‰©å……å¹¶ä¼˜åŒ–äº†ä¸­æ–‡è¯è¡¨ï¼Œä½¿ç”¨äº†å¤§è§„æ¨¡ä¸­æ–‡æ•°æ®è¿›è¡Œå¢é‡é¢„è®­ç»ƒï¼Œè¿›ä¸€æ­¥æå‡äº†ä¸­æ–‡åŸºç¡€è¯­ä¹‰å’ŒæŒ‡ä»¤ç†è§£èƒ½åŠ›ï¼Œç›¸æ¯”ä¸€ä»£ç›¸å…³æ¨¡å‹è·å¾—äº†æ˜¾è‘—æ€§èƒ½æå‡ã€‚ç›¸å…³æ¨¡å‹æ”¯æŒ4Kä¸Šä¸‹æ–‡å¹¶å¯é€šè¿‡NTKæ–¹æ³•æœ€é«˜æ‰©å±•è‡³18K+ã€‚

### ä¸­æ–‡å¯¹è¯å¼å¤§è¯­è¨€æ¨¡å‹Firefly
- https://mp.weixin.qq.com/s/tyH9Ifcvw4DKqoIoYjT6Kg
- https://github.com/yangjianxin1/Firefly

Fireflyï¼ˆæµè¤ï¼‰ æ˜¯ä¸€ä¸ªå¼€æºçš„ä¸­æ–‡å¯¹è¯å¼å¤§è¯­è¨€æ¨¡å‹ï¼Œä½¿ç”¨æŒ‡ä»¤å¾®è°ƒï¼ˆInstruction Tuningï¼‰åœ¨ä¸­æ–‡æ•°æ®é›†ä¸Šè¿›è¡Œè°ƒä¼˜ã€‚åŒæ—¶ä½¿ç”¨äº†è¯è¡¨è£å‰ªã€ZeROã€å¼ é‡å¹¶è¡Œç­‰æŠ€æœ¯ï¼Œæœ‰æ•ˆé™ä½æ˜¾å­˜æ¶ˆè€—å’Œæé«˜è®­ç»ƒæ•ˆç‡ã€‚ åœ¨è®­ç»ƒä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†æ›´å°çš„æ¨¡å‹å‚æ•°é‡ï¼Œä»¥åŠæ›´å°‘çš„è®¡ç®—èµ„æºã€‚

æˆ‘ä»¬æ„é€ äº†è®¸å¤šä¸ä¸­åæ–‡åŒ–ç›¸å…³çš„æ•°æ®ï¼Œä»¥æå‡æ¨¡å‹è¿™æ–¹é¢çš„è¡¨ç°ï¼Œå¦‚å¯¹è”ã€ä½œè¯—ã€æ–‡è¨€æ–‡ç¿»è¯‘ã€æ•£æ–‡ã€é‡‘åº¸å°è¯´ç­‰ã€‚

### å‡¤å‡°
- https://mp.weixin.qq.com/s/beAAh_MdqssV8bEKsccElg
- https://github.com/FreedomIntelligence/LLMZoo

LLM Zoo is a project that provides data, models, and evaluation benchmark for large language models.

### ã€å¤æ—¦ã€‘MOSS
- https://github.com/OpenLMLab/MOSS
- https://mp.weixin.qq.com/s/LjToZVWjQ-ot5KJFCFtA3g

MOSSæ˜¯ä¸€ä¸ªæ”¯æŒä¸­è‹±åŒè¯­å’Œå¤šç§æ’ä»¶çš„å¼€æºå¯¹è¯è¯­è¨€æ¨¡å‹ï¼Œmoss-moonç³»åˆ—æ¨¡å‹å…·æœ‰160äº¿å‚æ•°ï¼Œåœ¨FP16ç²¾åº¦ä¸‹å¯åœ¨å•å¼ A100/A800æˆ–ä¸¤å¼ 3090æ˜¾å¡è¿è¡Œï¼Œåœ¨INT4/8ç²¾åº¦ä¸‹å¯åœ¨å•å¼ 3090æ˜¾å¡è¿è¡Œã€‚MOSSåŸºåº§è¯­è¨€æ¨¡å‹åœ¨çº¦ä¸ƒåƒäº¿ä¸­è‹±æ–‡ä»¥åŠä»£ç å•è¯ä¸Šé¢„è®­ç»ƒå¾—åˆ°ï¼Œåç»­ç»è¿‡å¯¹è¯æŒ‡ä»¤å¾®è°ƒã€æ’ä»¶å¢å¼ºå­¦ä¹ å’Œäººç±»åå¥½è®­ç»ƒå…·å¤‡å¤šè½®å¯¹è¯èƒ½åŠ›åŠä½¿ç”¨å¤šç§æ’ä»¶çš„èƒ½åŠ›ã€‚

### ã€å¤æ—¦ã€‘MOSS-RLHF
- https://mp.weixin.qq.com/s/BjXtnEEVCQiPOy-_qCNM4g
- https://openlmlab.github.io/MOSS-RLHF/paper/SecretsOfRLHFPart1.pdf
- https://openlmlab.github.io/MOSS-RLHF/

FudanNLP å›¢é˜Ÿé€šè¿‡å¤§é‡ã€è¯¦å®å·¥ä½œï¼Œè®¾è®¡å®éªŒå……åˆ†æ¢ç´¢äº†å¤§æ¨¡å‹ RLHF çš„å®Œæ•´å·¥ä½œæµç¨‹ï¼Œä»”ç»†å‰–æäº† RLHF ä¸­çš„å¼ºåŒ–å­¦ä¹  PPO ç®—æ³•çš„å†…éƒ¨å·¥ä½œåŸç†ä»¥åŠå®ƒåœ¨æ•´ä¸ª RLHF ä¸­çš„ä½œç”¨ï¼Œå¹¶ç ”ç©¶å„ç§ä¼˜åŒ–æ–¹æ³•å¦‚ä½•å½±å“è®­ç»ƒè¿‡ç¨‹ã€‚é€šè¿‡è¿™äº›åŠªåŠ›ï¼Œç¡®å®šäº†ä½¿å¾— PPO ç®—æ³•åœ¨å¤§æ¨¡å‹äººç±»å¯¹é½æ–¹é¢è¡Œä¹‹æœ‰æ•ˆçš„å…³é”®å› ç´ ã€‚

ç»¼åˆä¸Šè¿°å‘ç°ï¼Œè¯¥å›¢é˜Ÿè¿›ä¸€æ­¥æ€»ç»“å‡ºåœ¨å¤§æ¨¡å‹ä¸Šè®­ç»ƒæ›´ç¨³å®šçš„ PPO ç®—æ³•ç‰ˆæœ¬ï¼šPPO-maxã€‚å¹¶ä½¿ç”¨ Helpful å’Œ Harmless æ•°æ®é›†å…¨é¢è¯„ä¼°ï¼Œç»“æœæ˜¾ç¤ºç»è¿‡ PPO-max ç®—æ³•è®­ç»ƒçš„æ¨¡å‹å±•ç°å‡ºäº†å‡ºè‰²çš„äººç±»å¯¹é½æ€§èƒ½ï¼

ç»¼åˆä¸Šè¿°å‘ç°ï¼Œè¯¥å›¢é˜Ÿè¿›ä¸€æ­¥æ€»ç»“å‡ºåœ¨å¤§æ¨¡å‹ä¸Šè®­ç»ƒæ›´ç¨³å®šçš„ PPO ç®—æ³•ç‰ˆæœ¬ï¼šPPO-maxã€‚å¹¶ä½¿ç”¨ Helpful å’Œ Harmless æ•°æ®é›†å…¨é¢è¯„ä¼°ï¼Œç»“æœæ˜¾ç¤ºç»è¿‡ PPO-max ç®—æ³•è®­ç»ƒçš„æ¨¡å‹å±•ç°å‡ºäº†å‡ºè‰²çš„äººç±»å¯¹é½æ€§èƒ½ï¼

### ã€åº¦å°æ»¡ã€‘è½©è¾•-é¦–ä¸ªåƒäº¿çº§ä¸­æ–‡é‡‘èå¯¹è¯æ¨¡å‹
- https://arxiv.org/pdf/2305.12002.pdf
- https://huggingface.co/xyz-nlp/XuanYuan2.0
- https://github.com/Duxiaoman-DI/XuanYuan
- https://huggingface.co/xyz-nlp/XuanYuan2.0
- https://zhuanlan.zhihu.com/p/632780608

è½©è¾•æ˜¯å›½å†…é¦–ä¸ªå¼€æºçš„åƒäº¿çº§ä¸­æ–‡å¯¹è¯å¤§æ¨¡å‹ï¼ŒåŒæ—¶ä¹Ÿæ˜¯é¦–ä¸ªé’ˆå¯¹ä¸­æ–‡é‡‘èé¢†åŸŸä¼˜åŒ–çš„åƒäº¿çº§å¼€æºå¯¹è¯å¤§æ¨¡å‹ã€‚è½©è¾•åœ¨BLOOM-176Bçš„åŸºç¡€ä¸Šé’ˆå¯¹ä¸­æ–‡é€šç”¨é¢†åŸŸå’Œé‡‘èé¢†åŸŸè¿›è¡Œäº†é’ˆå¯¹æ€§çš„é¢„è®­ç»ƒä¸å¾®è°ƒï¼Œå®ƒä¸ä»…å¯ä»¥åº”å¯¹é€šç”¨é¢†åŸŸçš„é—®é¢˜ï¼Œä¹Ÿå¯ä»¥è§£ç­”ä¸é‡‘èç›¸å…³çš„å„ç±»é—®é¢˜ï¼Œä¸ºç”¨æˆ·æä¾›å‡†ç¡®ã€å…¨é¢çš„é‡‘èä¿¡æ¯å’Œå»ºè®®ã€‚

### æ‚Ÿé“Â·å¤©é¹°ï¼ˆAquilaï¼‰
- https://github.com/FlagAI-Open/FlagAI/tree/master/examples/Aquila

è¿™æ˜¯é¦–ä¸ªå…·å¤‡ä¸­è‹±åŒè¯­çŸ¥è¯†ã€æ”¯æŒå•†ç”¨è®¸å¯åè®®ã€æ”¯æŒå›½å†…æ•°æ®åˆè§„è¦æ±‚çš„å¼€æºè¯­è¨€å¤§æ¨¡å‹ã€‚æ‚Ÿé“Â·å¤©é¹°ï¼ˆAquilaï¼‰ç³»åˆ—æ¨¡å‹åŒ…æ‹¬ AquilaåŸºç¡€æ¨¡å‹ï¼ˆ7Bã€33Bï¼‰ï¼ŒAquilaChatå¯¹è¯æ¨¡å‹ï¼ˆ7Bã€33Bï¼‰ä»¥åŠ AquilaCode â€œæ–‡æœ¬-ä»£ç â€ç”Ÿæˆæ¨¡å‹ã€‚ 

- https://github.com/FlagAI-Open/Aquila2

We announce that our Aquila2 series is now open source, comprising Aquila2 (the base language models: Aquila2-7B and Aquila2-34B) and AquilaChat2 (the chat models, namely AquilaChat2-7B and AquilaChat2-34B, as well as the long-text chat models, namely AquilaChat2-7B-16k and AquilaChat2-34B-16k). You can find the links in the following table. Kindly click on them to access the model cards.

### æ¡ƒæï¼šå›½é™…ä¸­æ–‡æ•™è‚²å¤§æ¨¡å‹
- https://github.com/blcuicall/taoli

éšç€ChatGPTå¼•èµ·å…¨ç¤¾ä¼šçš„å…³æ³¨ï¼ŒåŠå„ç±»å¤§è¯­è¨€æ¨¡å‹ï¼ˆLarge Language Modelï¼‰äº‰ç›¸äº®ç›¸ï¼Œé€šç”¨é¢†åŸŸè‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡å·²è·å¾—å·¨å¤§æˆåŠŸï¼Œå¼•èµ·äº†å›½é™…ä¸­æ–‡æ•™è‚²é¢†åŸŸçš„æ™®éå…³æ³¨ã€‚

å›½é™…ä¸­æ–‡æ•™è‚²äººå£«çº·çº·å±•å¼€äº†å¯¹å¤§æ¨¡å‹çš„æ¢è®¨ï¼š å¤§æ¨¡å‹æ˜¯å¦å¯ä»¥æ ¹æ®å­¦ä¹ è€…çš„æ°´å¹³ï¼Œæä¾›åˆé€‚çš„è¯­è¨€è¡¨è¾¾ï¼Œæˆ–æ ¹æ®å­¦ä¹ è€…çš„é—®é¢˜ç»™å‡ºè¯¦ç»†çš„è§£ç­”ï¼Œä»è€Œåœ¨ä¸€å®šç¨‹åº¦ä¸Šè¾…åŠ©ç”šè‡³å……å½“å­¦ä¹ ä¼™ä¼´ã€è¯­è¨€æ•™å¸ˆï¼Ÿ ç„¶è€Œï¼Œç›®å‰é€šç”¨é¢†åŸŸçš„å¤§æ¨¡å‹åœ¨å‚ç›´é¢†åŸŸçš„æ•ˆæœä»æœ‰é™ã€‚

ä¸ºè§£å†³ä¸Šè¿°é—®é¢˜ï¼Œæˆ‘ä»¬å…¨é¢æ¨å‡ºé€‚ç”¨äºå›½é™…ä¸­æ–‡æ•™è‚²é¢†åŸŸçš„å¤§æ¨¡å‹ â€œæ¡ƒæâ€ï¼ˆTaoliï¼‰1.0 ï¼Œä¸€ä¸ªåœ¨å›½é™…ä¸­æ–‡æ•™è‚²é¢†åŸŸæ•°æ®ä¸Šè¿›è¡Œäº†é¢å¤–è®­ç»ƒçš„æ¨¡å‹ã€‚

æˆ‘ä»¬åŸºäºç›®å‰å›½é™…ä¸­æ–‡æ•™è‚²é¢†åŸŸæµé€šçš„500ä½™å†Œå›½é™…ä¸­æ–‡æ•™è‚²æ•™æä¸æ•™è¾…ä¹¦ã€æ±‰è¯­æ°´å¹³è€ƒè¯•è¯•é¢˜ä»¥åŠæ±‰è¯­å­¦ä¹ è€…è¯å…¸ç­‰ï¼Œæ„å»ºäº†å›½é™…ä¸­æ–‡æ•™è‚²èµ„æºåº“ã€‚ æˆ‘ä»¬è®¾ç½®äº†å¤šç§å½¢å¼çš„æŒ‡ä»¤æ¥å……åˆ†åˆ©ç”¨çŸ¥è¯†ï¼Œæ„é€ äº†å…±è®¡ 88000 æ¡çš„é«˜è´¨é‡å›½é™…ä¸­æ–‡æ•™è‚²é—®ç­”æ•°æ®é›†ï¼Œå¹¶åˆ©ç”¨æ”¶é›†åˆ°çš„æ•°æ®å¯¹æ¨¡å‹è¿›è¡ŒæŒ‡ä»¤å¾®è°ƒï¼Œè®©æ¨¡å‹ä¹ å¾—å°†æ³•å¾‹çŸ¥è¯†åº”ç”¨åˆ°å…·ä½“åœºæ™¯ä¸­çš„èƒ½åŠ›ã€‚

### æƒ…æ„Ÿå¤§æ¨¡å‹PICA
- https://mp.weixin.qq.com/s/E37EFe10185THHa3pSqBig
- https://github.com/NEU-DataMining/PICA
- https://huggingface.co/NEUDM/PICA-V1

PICA ä»¥æ¸…åå¤§å­¦å¼€æºçš„ChatGLM2-6Bä¸ºåŸºç¡€ï¼Œé‡‡ç”¨Prompt tuningæŠ€æœ¯åœ¨4 å¡ A6000 è®­ç»ƒå¤§çº¦15ä¸ªå°æ—¶å¾—åˆ°ã€‚æˆ‘ä»¬å’ŒSoulChat è¿›è¡Œäº†å¯¹æ¯”ï¼ˆæœ€åéƒ¨åˆ†ï¼‰ï¼Œæˆ‘ä»¬çš„æ¨¡å‹åœ¨ä½“éªŒå’Œå®‰å…¨ä¸Šæ›´æœ‰ä¼˜åŠ¿ã€‚æˆ‘ä»¬åªä½¿ç”¨äº†2Kçš„æ•°æ®è¿›è¡Œäº†p-tuning å¾®è°ƒï¼Œè¿™å……åˆ†è¯´æ˜äº†æˆ‘ä»¬æ„é€ çš„æ•°æ®è´¨é‡æ¯”è¾ƒé«˜ã€‚æ¨¡å‹æƒé‡å¯ä»¥åœ¨ HuggingFace è®¿é—®ï¼Œæ¬¢è¿å„ä½ä½¿ç”¨å¹¶æå‡ºå®è´µçš„æ„è§ã€‚

### é›…æ„å¤§æ¨¡å‹
- https://github.com/wenge-research/YaYi
- https://yayi.wenge.com/

é›…æ„å¤§æ¨¡å‹åœ¨ç™¾ä¸‡çº§äººå·¥æ„é€ çš„é«˜è´¨é‡é¢†åŸŸæ•°æ®ä¸Šè¿›è¡ŒæŒ‡ä»¤å¾®è°ƒå¾—åˆ°ï¼Œè®­ç»ƒæ•°æ®è¦†ç›–åª’ä½“å®£ä¼ ã€èˆ†æƒ…åˆ†æã€å…¬å…±å®‰å…¨ã€é‡‘èé£æ§ã€åŸå¸‚æ²»ç†ç­‰äº”å¤§é¢†åŸŸï¼Œä¸Šç™¾ç§è‡ªç„¶è¯­è¨€æŒ‡ä»¤ä»»åŠ¡ã€‚é›…æ„å¤§æ¨¡å‹ä»é¢„è®­ç»ƒåˆå§‹åŒ–æƒé‡åˆ°é¢†åŸŸæ¨¡å‹çš„è¿­ä»£è¿‡ç¨‹ä¸­ï¼Œæˆ‘ä»¬é€æ­¥å¢å¼ºäº†å®ƒçš„ä¸­æ–‡åŸºç¡€èƒ½åŠ›å’Œé¢†åŸŸåˆ†æèƒ½åŠ›ï¼Œå¹¶å¢åŠ äº†å¤šè½®å¯¹è¯å’Œéƒ¨åˆ†æ’ä»¶èƒ½åŠ›ã€‚åŒæ—¶ï¼Œç»è¿‡æ•°ç™¾åç”¨æˆ·å†…æµ‹è¿‡ç¨‹ä¸­æŒç»­ä¸æ–­çš„äººå·¥åé¦ˆä¼˜åŒ–ï¼Œæˆ‘ä»¬è¿›ä¸€æ­¥æå‡äº†æ¨¡å‹æ€§èƒ½å’Œå®‰å…¨æ€§ã€‚

é€šè¿‡é›…æ„å¤§æ¨¡å‹çš„å¼€æºä¸ºä¿ƒè¿›ä¸­æ–‡é¢„è®­ç»ƒå¤§æ¨¡å‹å¼€æºç¤¾åŒºçš„å‘å±•ï¼Œè´¡çŒ®è‡ªå·±çš„ä¸€ä»½åŠ›é‡ï¼Œé€šè¿‡å¼€æºï¼Œä¸æ¯ä¸€ä½åˆä½œä¼™ä¼´å…±å»ºé›…æ„å¤§æ¨¡å‹ç”Ÿæ€ã€‚

### å„¿ç«¥æƒ…æ„Ÿé™ªä¼´å¤§æ¨¡å‹â€œå·§æ¿â€
- https://github.com/HIT-SCIR-SC/QiaoBan

å·§æ¿å¤§æ¨¡å‹æ˜¯ä¸€ä¸ª7Bè§„æ¨¡çš„å¤§è¯­è¨€æ¨¡å‹ã€‚å·§æ¿â€æŒ‡ä¸ƒå·§æ¿ï¼Œæ˜¯ä¸€æ¬¾æ‰¿è½½ç€ä¸­å›½ä¼ ç»Ÿæ™ºæ…§çš„ç›Šæ™ºæ‹¼å›¾ç©å…·ï¼Œæ›´æ˜¯ä¸€æ¬¾æ•™è‚²ç›Šæ™ºå·¥å…·ã€‚è¿™æ¬¡å‘å¸ƒçš„å„¿ç«¥å¤§æ¨¡å‹æ­£æ˜¯å¸Œæœ›é€šè¿‡é™ªä¼´ã€ç›Šæ™ºå’Œæ•™è‚²åŠŸèƒ½ï¼Œä¸å„¿ç«¥ä»¬å»ºç«‹æ›´æ·±åšçš„æƒ…æ„Ÿçº½å¸¦ã€‚æ­¤å¤–ï¼Œä¸ºç¬¦åˆSCIRå®éªŒå®¤å‘å¸ƒå¤§æ¨¡å‹å‘½åè§„èŒƒï¼Œæ•…å‘½åä¸ºâ€œå·§æ¿â€å¤§æ¨¡å‹ã€‚è€Œè¿™ä¸ªç‰¹åˆ«çš„åç§°ä¹Ÿè•´å«ç€æˆ‘ä»¬å¯¹å„¿ç«¥æˆé•¿çš„æ‚‰å¿ƒå‘µæŠ¤ï¼Œå°±åƒå·§æ¿ä¸€æ ·ï¼Œä¸ºä»–ä»¬æ‹¼å‡ºç¾å¥½æœªæ¥æä¾›å¸®åŠ©ã€‚

å·§æ¿å¤§æ¨¡å‹ç‹¬å…·ä¸‰å¤§ç‰¹ç‚¹ï¼š
1. å„¿ç«¥å¿ƒç†å­¦ç†è®ºæŒ‡å¯¼ã€‚åŸºäºæƒ…ç»ªè¾…å¯¼ç†è®ºçš„å„¿ç«¥æƒ…æ„Ÿé™ªä¼´å¯¹è¯æ•°æ®æ„å»ºï¼Œæ›´æœ‰æ•ˆåœ°å®ˆæŠ¤å­©å­çš„å¿ƒç†å¥åº·ã€‚

2. é«˜è´¨é‡çš„å„¿ç«¥å¯¹è¯æ•°æ®æ„å»ºã€‚é«˜è´¨é‡å¯¹è¯æ•°æ®ç”±å…·æœ‰å„¿ç«¥å¿ƒç†å­¦èƒŒæ™¯çš„å¿—æ„¿è€…ä¸ä¸“å®¶å‚ä¸å®Œæˆï¼Œç¡®ä¿æ•°æ®çš„çœŸå®æ€§ä¸æœ‰æ•ˆæ€§ã€‚

3. æ¸©æš–çš„å„¿ç«¥é™ªä¼´ä½“éªŒã€‚ä¸å„¿ç«¥çš„äº¤äº’æ–¹å¼æ›´åŠ è´´å¿ƒï¼Œèƒ½å¤ŸçœŸæ­£ä¸ä»–ä»¬å»ºç«‹æ·±å…¥çš„æƒ…æ„Ÿè¿æ¥ï¼Œè®©å„¿ç«¥æ„Ÿå—åˆ°æ¸©æš–å’Œè®¤åŒï¼Œæˆä¸ºä»–ä»¬åšå®æˆé•¿é“è·¯ä¸Šçš„å¾—åŠ›ä¼™ä¼´ã€‚

### é€šä¹‰åƒé—®Qwen
- https://github.com/QwenLM/Qwen-7B

æˆ‘ä»¬åœ¨ğŸ¤– ModelScopeä»¥åŠğŸ¤— Hugging Faceå‡å¼€æºäº†Qwen-7Bç³»åˆ—æ¨¡å‹ã€‚è¯·åœ¨æœ¬æ–‡æ¡£é¡¶éƒ¨ç‚¹å‡»ç›¸å…³é“¾æ¥æŸ¥çœ‹ä»“åº“ä¿¡æ¯ã€‚æœ¬ä»“åº“ä¸»è¦åŒ…æ‹¬Qwen-7Bçš„ç®€ä»‹ã€ä½¿ç”¨æŒ‡å—ã€æŠ€æœ¯å¤‡å¿˜ç­‰å†…å®¹ã€‚æƒ³äº†è§£æ›´å¤šå…³äºæ¨¡å‹çš„ä¿¡æ¯ï¼Œè¯·ç‚¹å‡»é“¾æ¥æŸ¥çœ‹æˆ‘ä»¬çš„æŠ€æœ¯å¤‡å¿˜å½•ã€‚

é€šä¹‰åƒé—®-7Bï¼ˆQwen-7Bï¼‰ æ˜¯é˜¿é‡Œäº‘ç ”å‘çš„é€šä¹‰åƒé—®å¤§æ¨¡å‹ç³»åˆ—çš„70äº¿å‚æ•°è§„æ¨¡çš„æ¨¡å‹ã€‚Qwen-7Bæ˜¯åŸºäºTransformerçš„å¤§è¯­è¨€æ¨¡å‹, åœ¨è¶…å¤§è§„æ¨¡çš„é¢„è®­ç»ƒæ•°æ®ä¸Šè¿›è¡Œè®­ç»ƒå¾—åˆ°ã€‚é¢„è®­ç»ƒæ•°æ®ç±»å‹å¤šæ ·ï¼Œè¦†ç›–å¹¿æ³›ï¼ŒåŒ…æ‹¬å¤§é‡ç½‘ç»œæ–‡æœ¬ã€ä¸“ä¸šä¹¦ç±ã€ä»£ç ç­‰ã€‚åŒæ—¶ï¼Œåœ¨Qwen-7Bçš„åŸºç¡€ä¸Šï¼Œæˆ‘ä»¬ä½¿ç”¨å¯¹é½æœºåˆ¶æ‰“é€ äº†åŸºäºå¤§è¯­è¨€æ¨¡å‹çš„AIåŠ©æ‰‹Qwen-7B-Chatã€‚Qwen-7Bç³»åˆ—æ¨¡å‹çš„ç‰¹ç‚¹åŒ…æ‹¬ï¼š
1. å¤§è§„æ¨¡é«˜è´¨é‡é¢„è®­ç»ƒæ•°æ®ï¼šæˆ‘ä»¬ä½¿ç”¨äº†è¶…è¿‡2.2ä¸‡äº¿tokençš„è‡ªå»ºå¤§è§„æ¨¡é¢„è®­ç»ƒæ•°æ®é›†è¿›è¡Œè¯­è¨€æ¨¡å‹çš„é¢„è®­ç»ƒã€‚æ•°æ®é›†åŒ…æ‹¬æ–‡æœ¬å’Œä»£ç ç­‰å¤šç§æ•°æ®ç±»å‹ï¼Œè¦†ç›–é€šç”¨é¢†åŸŸå’Œä¸“ä¸šé¢†åŸŸã€‚
2. ä¼˜ç§€çš„æ¨¡å‹æ€§èƒ½ï¼šç›¸æ¯”åŒè§„æ¨¡çš„å¼€æºæ¨¡å‹ï¼ŒQwen-7Båœ¨å¤šä¸ªè¯„æµ‹æ•°æ®é›†ä¸Šå…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ï¼Œç”šè‡³è¶…å‡º12-13Bç­‰æ›´å¤§è§„æ¨¡çš„æ¨¡å‹ã€‚è¯„æµ‹è¯„ä¼°çš„èƒ½åŠ›èŒƒå›´åŒ…æ‹¬è‡ªç„¶è¯­è¨€ç†è§£ä¸ç”Ÿæˆã€æ•°å­¦è¿ç®—è§£é¢˜ã€ä»£ç ç”Ÿæˆç­‰ã€‚
3. æ›´å¥½åœ°æ”¯æŒå¤šè¯­è¨€ï¼šåŸºäºæ›´å¤§è¯è¡¨çš„åˆ†è¯å™¨åœ¨åˆ†è¯ä¸Šæ›´é«˜æ•ˆï¼ŒåŒæ—¶å®ƒå¯¹å…¶ä»–è¯­è¨€è¡¨ç°æ›´åŠ å‹å¥½ã€‚ç”¨æˆ·å¯ä»¥åœ¨Qwen-7Bçš„åŸºç¡€ä¸Šæ›´æ–¹ä¾¿åœ°è®­ç»ƒç‰¹å®šè¯­è¨€çš„7Bè¯­è¨€æ¨¡å‹ã€‚
4. 8Kçš„ä¸Šä¸‹æ–‡é•¿åº¦ï¼šQwen-7BåŠQwen-7B-Chatå‡èƒ½æ”¯æŒ8Kçš„ä¸Šä¸‹æ–‡é•¿åº¦, å…è®¸ç”¨æˆ·è¾“å…¥æ›´é•¿çš„promptã€‚
5. æ”¯æŒæ’ä»¶è°ƒç”¨ï¼šQwen-7B-Chaté’ˆå¯¹æ’ä»¶è°ƒç”¨ç›¸å…³çš„å¯¹é½æ•°æ®åšäº†ç‰¹å®šä¼˜åŒ–ï¼Œå½“å‰æ¨¡å‹èƒ½æœ‰æ•ˆè°ƒç”¨æ’ä»¶ä»¥åŠå‡çº§ä¸ºAgentã€‚

### æ´»å­—
- https://mp.weixin.qq.com/s/WEitgZjOxZpp7KIbRU0ewg
- https://github.com/HIT-SCIR/huozi

å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰åœ¨è‡ªç„¶è¯­è¨€å¤„ç†çš„é€šç”¨é¢†åŸŸå·²å–å¾—äº†ä»¤äººç©ç›®çš„æˆåŠŸã€‚å¯¹äºå¹¿æ³›çš„åº”ç”¨åœºæ™¯ï¼Œè¿™ç§æŠ€æœ¯å±•ç¤ºäº†å¼ºå¤§çš„æ½œåŠ›ï¼Œå­¦æœ¯ç•Œå’Œå·¥ä¸šç•Œçš„å…´è¶£ä¹ŸæŒç»­å‡æ¸©ã€‚å“ˆå·¥å¤§è‡ªç„¶è¯­è¨€å¤„ç†ç ”ç©¶æ‰€30ä½™ä½è€å¸ˆå’Œå­¦ç”Ÿå‚ä¸å¼€å‘äº†é€šç”¨å¯¹è¯å¤§æ¨¡å‹æ´»å­—1.0ï¼Œå“ˆå·¥å¤§ç¤¾ä¼šè®¡ç®—ä¸ä¿¡æ¯æ£€ç´¢ç ”ç©¶ä¸­å¿ƒ(å“ˆå·¥å¤§-SCIR)ç ”å‘äº†æ´»å­—2.0ï¼Œè‡´åŠ›äºä¸ºè‡ªç„¶è¯­è¨€å¤„ç†çš„ç ”ç©¶å’Œå®é™…åº”ç”¨æä¾›æ›´å¤šå¯èƒ½æ€§å’Œé€‰æ‹©ã€‚

æ´»å­—3.0æ˜¯åŸºäºChinese-Mixtral-8x7Bï¼Œåœ¨å¤§çº¦30ä¸‡è¡ŒæŒ‡ä»¤æ•°æ®ä¸Šå¾®è°ƒå¾—åˆ°çš„æ¨¡å‹ã€‚è¯¥æ¨¡å‹æ”¯æŒ32Kä¸Šä¸‹æ–‡ï¼Œèƒ½å¤Ÿæœ‰æ•ˆå¤„ç†é•¿æ–‡æœ¬ã€‚æ´»å­—3.0ç»§æ‰¿äº†åŸºåº§æ¨¡å‹ä¸°å¯Œçš„ä¸­è‹±æ–‡çŸ¥è¯†ï¼Œå¹¶åœ¨æ•°å­¦æ¨ç†ã€ä»£ç ç”Ÿæˆç­‰ä»»åŠ¡ä¸Šå…·æœ‰å¼ºå¤§æ€§èƒ½ã€‚ç»è¿‡æŒ‡ä»¤å¾®è°ƒï¼Œæ´»å­—3.0è¿˜åœ¨æŒ‡ä»¤éµå¾ªèƒ½åŠ›å’Œå®‰å…¨æ€§æ–¹é¢å®ç°äº†æ˜¾è‘—æå‡ã€‚

### éŸ©é HanFei
- https://github.com/siat-nlp/HanFei

HanFei-1.0(éŸ©é)æ˜¯å›½å†…é¦–ä¸ªå…¨å‚æ•°è®­ç»ƒçš„æ³•å¾‹å¤§æ¨¡å‹ï¼Œå‚æ•°é‡7bï¼Œä¸»è¦åŠŸèƒ½åŒ…æ‹¬ï¼šæ³•å¾‹é—®ç­”ã€å¤šè½®å¯¹è¯ã€æ’°å†™æ–‡ç« ã€æ£€ç´¢ï¼ˆæ•¬è¯·æœŸå¾…ï¼‰ç­‰ã€‚

### æ™ºæµ· å½•é—®
- https://github.com/zhihaiLLM/wisdomInterrogatory

æ™ºæµ·-å½•é—®(wisdomInterrogatory)æ˜¯ç”±æµ™æ±Ÿå¤§å­¦ã€é˜¿é‡Œå·´å·´è¾¾æ‘©é™¢ä»¥åŠåé™¢è®¡ç®—ä¸‰å®¶å•ä½å…±åŒè®¾è®¡ç ”å‘çš„æ³•å¾‹å¤§æ¨¡å‹ã€‚æ ¸å¿ƒæ€æƒ³ï¼šä»¥â€œæ™®æ³•å…±äº«å’Œå¸æ³•æ•ˆèƒ½æå‡â€ä¸ºç›®æ ‡ï¼Œä»æ¨åŠ¨æ³•å¾‹æ™ºèƒ½åŒ–ä½“ç³»å…¥å¸æ³•å®è·µã€æ•°å­—åŒ–æ¡ˆä¾‹å»ºè®¾ã€è™šæ‹Ÿæ³•å¾‹å’¨è¯¢æœåŠ¡èµ‹èƒ½ç­‰æ–¹é¢æä¾›æ”¯æŒï¼Œå½¢æˆæ•°å­—åŒ–å’Œæ™ºèƒ½åŒ–çš„å¸æ³•åŸºåº§èƒ½åŠ›ã€‚

### Animaï¼šåŸºäºQLoRAçš„33Bä¸­æ–‡å¤§è¯­è¨€æ¨¡å‹
- https://github.com/lyogavin/Anima

AI Communityä»æ¥éƒ½æ˜¯éå¸¸å¼€æ”¾çš„ï¼ŒAIå‘å±•åˆ°ä»Šå¤©ï¼Œç¦»ä¸å¼€å¾ˆå¤šä»¥å‰çš„é‡è¦å¼€æºå·¥ä½œï¼Œå¼€æ”¾å…±äº«çš„Paperï¼Œæˆ–è€…çš„å¼€æºæ•°æ®å’Œä»£ç ã€‚æˆ‘ä»¬ç›¸ä¿¡AIçš„æœªæ¥ä¹Ÿä¸€å®šæ˜¯å¼€æ”¾çš„ã€‚å¸Œæœ›èƒ½ä¸ºå¼€æºç¤¾åŒºåšä¸€äº›è´¡çŒ®ã€‚

ä¸ºä»€ä¹ˆ33Bæ¨¡å‹å¾ˆé‡è¦ï¼ŸQLoRAæ˜¯ä¸ªGame Changerï¼Ÿ

ä¹‹å‰å¤§éƒ¨åˆ†å¼€æºå¯finetuneçš„æ¨¡å‹å¤§éƒ½æ˜¯æ¯”è¾ƒå°çš„æ¨¡å‹7Bæˆ–è€…13Bï¼Œè™½ç„¶å¯ä»¥åœ¨ä¸€äº›ç®€å•çš„chatbotè¯„æµ‹é›†ä¸Šï¼Œé€šè¿‡finetuneè®­ç»ƒæœ‰ä¸é”™çš„è¡¨ç°ã€‚ä½†æ˜¯ç”±äºè¿™äº›æ¨¡å‹è§„æ¨¡è¿˜æ˜¯æœ‰é™ï¼ŒLLMæ ¸å¿ƒçš„reasoningçš„èƒ½åŠ›è¿˜æ˜¯ç›¸å¯¹æ¯”è¾ƒå¼±ã€‚è¿™å°±æ˜¯ä¸ºä»€ä¹ˆå¾ˆå¤šè¿™ç§å°è§„æ¨¡çš„æ¨¡å‹åœ¨å®é™…åº”ç”¨çš„åœºæ™¯è¡¨ç°åƒæ˜¯ä¸ªç©å…·ã€‚å¦‚è¿™ä¸ªå·¥ä½œä¸­çš„è®ºè¿°ï¼šchatbotè¯„æµ‹é›†æ¯”è¾ƒç®€å•ï¼ŒçœŸæ­£æ¯”è¾ƒè€ƒéªŒæ¨¡å‹èƒ½åŠ›çš„å¤æ‚é€»è¾‘æ¨ç†åŠæ•°å­¦é—®é¢˜ä¸Šå°æ¨¡å‹å’Œå¤§æ¨¡å‹å·®è·è¿˜æ˜¯å¾ˆæ˜æ˜¾çš„ã€‚

å› æ­¤æˆ‘ä»¬è®¤ä¸ºQLoRA çš„å·¥ä½œå¾ˆé‡è¦ï¼Œé‡è¦åˆ°å¯èƒ½æ˜¯ä¸ªGame Changerã€‚é€šè¿‡QLoRAçš„ä¼˜åŒ–æ–¹æ³•ï¼Œç¬¬ä¸€æ¬¡è®©33Bè§„æ¨¡çš„æ¨¡å‹å¯ä»¥æ¯”è¾ƒæ°‘ä¸»åŒ–çš„ï¼Œæ¯”è¾ƒä½æˆæœ¬çš„finetuneè®­ç»ƒï¼Œå¹¶ä¸”æ™®åŠä½¿ç”¨ã€‚æˆ‘ä»¬è®¤ä¸º33Bæ¨¡å‹æ—¢å¯ä»¥å‘æŒ¥å¤§è§„æ¨¡æ¨¡å‹çš„æ¯”è¾ƒå¼ºçš„reasoningèƒ½åŠ›ï¼Œåˆå¯ä»¥é’ˆå¯¹ç§æœ‰ä¸šåŠ¡é¢†åŸŸæ•°æ®è¿›è¡Œçµæ´»çš„finetuneè®­ç»ƒæå‡å¯¹äºLLMçš„æ§åˆ¶åŠ›ã€‚

### BayLing: Bridging Cross-lingual Alignment and Instruction Following through Interactive Translation for Large Language Models
- https://github.com/ictnlp/BayLing
- https://arxiv.org/abs/2306.10968

BayLing (ç™¾è†, bÇi lÃ­ng) is an instruction-following large language model equipped with advanced language alignment, showing superior capability in English/Chinese generation, instruction following and multi-turn interaction. BayLing can be effortlessly deployed on a consumer-grade GPU with 16GB of memory, and assists users with tasks such as translation, writing, creation, suggestion...

### BBT-FinCUGE-Applications
- https://github.com/ssymmetry/BBT-FinCUGE-Applications
- https://arxiv.org/abs/2302.09432
- https://bbt.ssymmetry.com/index.html

1.ç›®å‰æœ€å¤§è§„æ¨¡çš„ä¸­æ–‡é‡‘èé¢†åŸŸå¼€æºè¯­æ–™åº“BBT-FinCorpusã€‚é¢„è®­ç»ƒè¯­æ–™åº“çš„è§„æ¨¡ä¸å¤šæ ·æ€§å¯¹PLMçš„æ€§èƒ½å’Œæ³›åŒ–èƒ½åŠ›å…·æœ‰é‡è¦ä½œç”¨ï¼Œæ‰€ä»¥ä¸ºäº†æ›´å¥½çš„è®­ç»ƒPLMï¼Œé¦–å…ˆéœ€è¦æœé›†å¤§è§„æ¨¡å¤šæ ·æ€§çš„è¯­æ–™åº“ã€‚ç„¶è€Œï¼Œç›®å‰ä¸­æ–‡é‡‘èé¢†åŸŸç¼ºä¹å¤§è§„æ¨¡å¤šæ ·æ€§å¼€æºè¯­æ–™åº“ï¼Œå·²æœ‰çš„ä¸­æ–‡é‡‘èé¢†åŸŸæ¨¡å‹å¤šæ•°åŸºäºå°è§„æ¨¡çš„ç§æœ‰è¯­æ–™åº“ï¼Œä¸¥é‡é™åˆ¶äº†ä¸­æ–‡é‡‘èPLMçš„èƒ½åŠ›æå‡ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬æ„å»ºäº†BBT-FinCorpusï¼Œä¸€ä¸ªåŒ…å«æœ‰ä»å››ç§å¼‚è´¨æ€§æ¥æºè·å–çš„çº¦300GBæ–‡æœ¬çš„å¤§è§„æ¨¡å¤šæ ·æ€§è¯­æ–™åº“ã€‚é’ˆå¯¹å¦‚ä½•ç¡®å®šè¯­æ–™åº“çš„è¦†ç›–èŒƒå›´å’Œè¯­æ–™æ¥æºé›†åˆçš„é—®é¢˜ï¼Œæˆ‘ä»¬é¦–å…ˆæœé›†äº†ä¸­æ–‡äº’è”ç½‘ä¸Šå¯è·å–çš„æ‰€æœ‰ä¸­æ–‡é‡‘èNLPä»»åŠ¡æ•°æ®é›†ï¼Œå¹¶æ ¹æ®å…¶æ–‡æœ¬æ¥æºåˆ†å¸ƒæ¥ç¡®å®šæ‰€éœ€è¦çˆ¬å–çš„æ–‡æœ¬æ¥æºé›†åˆã€‚åœ¨ç¡®è®¤å¥½éœ€è¦çˆ¬å–çš„æ–‡æœ¬æ¥æºé›†åˆä¹‹åï¼Œæˆ‘ä»¬ä½¿ç”¨åŸºäºä»£ç†çš„åˆ†å¸ƒå¼çˆ¬è™«æŠ€æœ¯å®ç°å¤§è§„æ¨¡çˆ¬å–ç½‘é¡µä¸Šçš„æ–‡æœ¬ã€‚

2.ç›®å‰æœ€å¤§è§„æ¨¡çš„ä¸­æ–‡é‡‘èé¢†åŸŸçŸ¥è¯†å¢å¼ºå‹é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹BBT-FinT5ã€‚PLMçš„æ¶æ„ä¸å‚æ•°é‡å¯¹å…¶æ€§èƒ½æœ‰é‡è¦å½±å“ã€‚ç°æœ‰çš„ä¸­æ–‡é‡‘èé¢†åŸŸPLMéƒ½åŸºäºè¾ƒä¸ºåŸå§‹çš„BERTæ¨¡å‹æ¶æ„ï¼Œå‚æ•°é‡ä¹Ÿç›¸å¯¹è¾ƒå°ï¼Œä¸èƒ½æ»¡è¶³æ—¥ç›Šä¸°å¯Œçš„é¢†åŸŸNLPéœ€æ±‚ã€‚å› æ­¤ï¼Œæˆ‘ä»¬åŸºäºT5æ¨¡å‹æ¶æ„æ„å»ºäº†ä¸€ä¸ªæ‹¥æœ‰åäº¿å‚æ•°é‡çš„ç›®å‰æœ€å¤§è§„æ¨¡çš„ä¸­æ–‡é‡‘èé¢†åŸŸé¢„è®­ç»ƒè¯­è¨€æ¨¡å‹BBT-FinT5ã€‚ä¸ºäº†åœ¨æœ‰é™çš„ç¡¬ä»¶ç®—åŠ›æ¡ä»¶ä¸‹ï¼Œå°½å¯èƒ½é«˜æ•ˆåœ°åˆ©ç”¨å¥½ç¡¬ä»¶ç®—åŠ›ï¼Œæˆ‘ä»¬ä½¿ç”¨DeepSpeedåŠ é€Ÿæ¡†æ¶å¯¹é¢„è®­ç»ƒè¿‡ç¨‹è¿›è¡Œæ•ˆç‡ä¼˜åŒ–ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜é’ˆå¯¹T5æ¨¡å‹è®¾è®¡äº†ç‹¬ç‰¹çš„çŸ¥è¯†å¢å¼ºé¢„è®­ç»ƒæ–¹æ³•ï¼Œé€šè¿‡å®éªŒè¯æ˜äº†è¯¥æ–¹æ³•çš„æœ‰æ•ˆæ€§ã€‚

3.é¦–ä¸ªä¸­æ–‡é‡‘èé¢†åŸŸè‡ªç„¶è¯­è¨€å¤„ç†è¯„æµ‹åŸºå‡†CFLEBã€‚ç°æœ‰çš„è‡ªç„¶è¯­è¨€å¤„ç†è¯„ä¼°åŸºå‡†å¤šæ˜¯é€šç”¨é¢†åŸŸçš„ï¼Œæ²¡æœ‰å…¬å¼€å¯ç”¨çš„ä¸­æ–‡é‡‘èé¢†åŸŸè¯„æµ‹åŸºå‡†ã€‚è¿™å¯¼è‡´ä¸­æ–‡é‡‘èé¢†åŸŸç°æœ‰çš„é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹åœ¨ä¸åŒçš„ä»»åŠ¡é›†åˆä¸Šè¿›è¡Œè¯„æµ‹ï¼Œéš¾ä»¥ç›¸äº’æ¯”è¾ƒï¼Œé˜»ç¢äº†ä¸­æ–‡é‡‘èé¢†åŸŸPLMæ€§èƒ½çš„å¿«é€Ÿæå‡ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬é¦–å…ˆæ„å»ºäº†é¦–ä¸ªä¸­æ–‡é‡‘èé¢†åŸŸè‡ªç„¶è¯­è¨€å¤„ç†è¯„æµ‹åŸºå‡†CFLEBï¼ŒåŒ…å«å…­ç§ä¸åŒçš„ä»»åŠ¡ï¼Œæ¶µç›–å¯¹PLMç†è§£ä¸ç”Ÿæˆèƒ½åŠ›çš„è¯„ä¼°ã€‚é’ˆå¯¹è¯„æµ‹åŸºå‡†ä»»åŠ¡çš„é€‰æ‹©åŠå…¶é€‰æ‹©æ ‡å‡†é—®é¢˜ï¼Œæˆ‘ä»¬è®¤ä¸ºé¢†åŸŸè¯„æµ‹åŸºå‡†åº”å½“ç€é‡å¼ºè°ƒä»»åŠ¡çš„å®ç”¨æ€§ï¼Œä»¥æ›´å¥½çš„åæ˜ å­¦æœ¯ç•Œæ”¹è¿›PLMå¯¹ç°å®ä¸–ç•Œçš„å¸®åŠ©ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬é¦–å…ˆé‚€è¯·é‡‘èé¢†åŸŸä¸“å®¶å¯¹æ‰€æœ‰å¯è·å–çš„ä¸­æ–‡é‡‘èä»»åŠ¡è¿›è¡Œäº†å®ç”¨æ€§è¯„ä»·ï¼Œç­›é€‰å‡ºå…·æœ‰è¾ƒé«˜å®ç”¨æ€§è¯„åˆ†çš„ä»»åŠ¡ã€‚ä¹‹åï¼Œæˆ‘ä»¬ç»¼åˆä»»åŠ¡æ•°æ®é›†çš„å¼€æºæƒ…å†µç¡®å®šäº†å…­ä¸ªä»»åŠ¡æ•°æ®é›†ä½œä¸ºæœ€ç»ˆçš„è¯„æµ‹åŸºå‡†ã€‚è¯¥è¯„æµ‹åŸºå‡†çš„æ—©æœŸç‰ˆæœ¬å‘½åä¸ºFinCUGEï¼ŒåŒ…å«å…«ä¸ªä»»åŠ¡ï¼Œè¯¥ç‰ˆæœ¬ç›®å‰å·²èˆå¼ƒã€‚


### BELLE: Bloom-Enhanced Large Language model Engine
- https://huggingface.co/BelleGroup
- https://github.com/LianjiaTech/BELLE
- https://zhuanlan.zhihu.com/p/616079388

æœ¬é¡¹ç›®ç›®æ ‡æ˜¯ä¿ƒè¿›ä¸­æ–‡å¯¹è¯å¤§æ¨¡å‹å¼€æºç¤¾åŒºçš„å‘å±•ï¼Œæ„¿æ™¯åšèƒ½å¸®åˆ°æ¯ä¸€ä¸ªäººçš„LLM Engineã€‚ç°é˜¶æ®µæœ¬é¡¹ç›®åŸºäºä¸€äº›å¼€æºé¢„è®­ç»ƒå¤§è¯­è¨€æ¨¡å‹ï¼ˆå¦‚BLOOMï¼‰ï¼Œé’ˆå¯¹ä¸­æ–‡åšäº†ä¼˜åŒ–ï¼Œæ¨¡å‹è°ƒä¼˜ä»…ä½¿ç”¨ç”±ChatGPTç”Ÿäº§çš„æ•°æ®ï¼ˆä¸åŒ…å«ä»»ä½•å…¶ä»–æ•°æ®ï¼‰ã€‚

æœ¬é¡¹ç›®åŸºäº Stanford Alpaca ï¼ŒStanford Alpaca çš„ç›®æ ‡æ˜¯æ„å»ºå’Œå¼€æºä¸€ä¸ªåŸºäºLLaMAçš„æ¨¡å‹ã€‚ Stanford Alpaca çš„ç§å­ä»»åŠ¡éƒ½æ˜¯è‹±è¯­ï¼Œæ”¶é›†çš„æ•°æ®ä¹Ÿéƒ½æ˜¯è‹±æ–‡ï¼Œå› æ­¤è®­ç»ƒå‡ºæ¥çš„æ¨¡å‹æœªå¯¹ä¸­æ–‡ä¼˜åŒ–ã€‚

æœ¬é¡¹ç›®ç›®æ ‡æ˜¯ä¿ƒè¿›ä¸­æ–‡å¯¹è¯å¤§æ¨¡å‹å¼€æºç¤¾åŒºçš„å‘å±•ã€‚æœ¬é¡¹ç›®é’ˆå¯¹ä¸­æ–‡åšäº†ä¼˜åŒ–ï¼Œæ¨¡å‹è°ƒä¼˜ä»…ä½¿ç”¨ç”±ChatGPTç”Ÿäº§çš„æ•°æ®ï¼ˆä¸åŒ…å«ä»»ä½•å…¶ä»–æ•°æ®ï¼‰ã€‚

### Bloom
- https://huggingface.co/blog/bloom
- https://huggingface.co/bigscience/bloom

BLOOM is an autoregressive Large Language Model (LLM), trained to continue text from a prompt on vast amounts of text data using industrial-scale computational resources. As such, it is able to output coherent text in 46 languages and 13 programming languages that is hardly distinguishable from text written by humans. BLOOM can also be instructed to perform text tasks it hasn't been explicitly trained for, by casting them as text generation tasks.

### BiLLa: A Bilingual LLaMA with Enhanced Reasoning Ability
- https://zhuanlan.zhihu.com/p/628688680
- https://github.com/Neutralzz/BiLLa

BiLLaæ˜¯å¼€æºçš„æ¨ç†èƒ½åŠ›å¢å¼ºçš„ä¸­è‹±åŒè¯­LLaMAæ¨¡å‹ã€‚æ¨¡å‹çš„ä¸»è¦ç‰¹æ€§æœ‰ï¼š
- è¾ƒå¤§æå‡LLaMAçš„ä¸­æ–‡ç†è§£èƒ½åŠ›ï¼Œå¹¶å°½å¯èƒ½å‡å°‘å¯¹åŸå§‹LLaMAè‹±æ–‡èƒ½åŠ›çš„æŸä¼¤ï¼›
- è®­ç»ƒè¿‡ç¨‹å¢åŠ è¾ƒå¤šçš„ä»»åŠ¡å‹æ•°æ®ï¼Œåˆ©ç”¨ChatGPTç”Ÿæˆè§£æï¼Œå¼ºåŒ–æ¨¡å‹ç†è§£ä»»åŠ¡æ±‚è§£é€»è¾‘ï¼›
- å…¨é‡å‚æ•°æ›´æ–°ï¼Œè¿½æ±‚æ›´å¥½çš„ç”Ÿæˆæ•ˆæœã€‚

### BLOOMChat176B
- https://mp.weixin.qq.com/s/cY6ORD8CUyXRL0l20EjwqQ
- https://sambanova.ai/blog/introducing-bloomchat-176b-the-multilingual-chat-based-llm/
- https://huggingface.co/spaces/sambanovasystems/BLOOMChat
- https://github.com/sambanova/bloomchat

å¼€æºå¯¹è¯æ¨¡å‹ä¸€ç›´è·Ÿé—­æºæ¨¡å‹åœ¨å¤šè¯­è¨€èƒ½åŠ›ä¸Šå­˜åœ¨å·®è·ã€‚SambaNova å’Œæ–¯å¦ç¦ Together Computer å¼€æºå¯å•†ç”¨çš„å¤šè¯­è¨€èŠå¤©æ¨¡å‹ BLOOMChat 176Bï¼Œæ”¯æŒä¸­æ–‡ã€‚BLOOMChat åœ¨SambaNova è‡ªç ”èŠ¯ç‰‡ RDU ä¸Šå®Œæˆè®­ç»ƒï¼Œå€ŸåŠ© SambaNova çš„ç‹¬ç‰¹å¯é‡æ„æ•°æ®æµæ¶æ„ï¼Œåˆ©ç”¨ BLOOM å¼€æºæ¨¡å‹çš„æ ¸å¿ƒèƒ½åŠ›ï¼Œé€šè¿‡åœ¨ OpenChatKitã€Dolly 2.0 å’Œ OASST1 çš„ OIG ä¸Šè¿›è¡Œå¾®è°ƒã€‚åœ¨åŸºäºå…­ç§è¯­è¨€çš„æ—©æœŸåŒç›²æµ‹è¯•ä¸­ï¼ŒBLOOMChat åœ¨ 66%çš„æµ‹è¯„æ•°æ®ä¸Šäº§ç”Ÿçš„å¯¹è¯è¡¨ç°ä¼˜äºè¿‘æœŸçš„å¼€æºå¯¹è¯æ¨¡å‹ã€‚åŒæ—¶åœ¨ä¸ GPT4 çš„åŸºäºå…­ç§è¯­è¨€çš„äººå·¥æµ‹è¯„å¯¹æ¯”ä¸­ï¼ŒBLOOMChat å¾—åˆ° 45%å¯¹ 55%çš„èƒœç‡ï¼Œå¤§å¤§ç¼©å°å¼€æºå’Œé—­æºæ¨¡å‹çš„å¤šè¯­è¨€å¯¹è¯èƒ½åŠ›å·®è·ã€‚å½“å‰ BLOOMChat å¼€æºæ¨¡å‹æ–‡ä»¶ï¼Œæ”¯æŒåœ¨ huggingface åœ¨çº¿æ¨ç†è¯•ç”¨ã€‚

### ChatLaw æ³•å¾‹å¤§æ¨¡å‹
- https://www.chatlaw.cloud/
- https://github.com/PKU-YuanGroup/ChatLaw
- https://arxiv.org/pdf/2306.16092.pdf

ä½†æ„¿ä¸–é—´ä¸çº·äº‰ï¼Œä½•æƒœæ³•å…¸å·ç”Ÿå°˜

ChatGPTæµªæ½®ä¸‹ï¼Œäººå·¥æ™ºèƒ½çš„ä¸æ–­æ‰©å±•å’Œå‘å±•ä¸ºLLMçš„æ‰©æ•£æä¾›äº†è‚¥æ²ƒçš„åœŸå£¤ï¼Œç›®å‰åŒ»ç–—ã€æ•™è‚²ã€é‡‘èé¢†åŸŸå·²é€æ¸æœ‰äº†å„è‡ªçš„æ¨¡å‹ï¼Œä½†æ³•å¾‹é¢†åŸŸè¿Ÿè¿Ÿæ²¡æœ‰æ˜æ˜¾è¿›å±•ã€‚

ä¸ºäº†ä¿ƒè¿›LLMåœ¨æ³•å¾‹ç”šè‡³å…¶ä»–å‚ç›´åº”ç”¨è½åœ°çš„å¼€æ”¾ç ”ç©¶ï¼Œæœ¬é¡¹ç›®å¼€æºäº†ä¸­æ–‡æ³•å¾‹å¤§æ¨¡å‹ï¼Œå¹¶é’ˆå¯¹LLMå’ŒçŸ¥è¯†åº“çš„ç»“åˆé—®é¢˜ç»™å‡ºäº†æ³•å¾‹åœºæ™¯ä¸‹åˆç†çš„è§£å†³æ–¹æ¡ˆã€‚

ChatLawæ³•å¾‹å¤§æ¨¡å‹ç›®å‰å¼€æºçš„ä»…ä¾›å­¦æœ¯å‚è€ƒçš„ç‰ˆæœ¬åº•åº§ä¸ºå§œå­ç‰™-13Bã€Anima-33Bï¼Œæˆ‘ä»¬ä½¿ç”¨å¤§é‡æ³•å¾‹æ–°é—»ã€æ³•å¾‹è®ºå›ã€æ³•æ¡ã€å¸æ³•è§£é‡Šã€æ³•å¾‹å’¨è¯¢ã€æ³•è€ƒé¢˜ã€åˆ¤å†³æ–‡ä¹¦ç­‰åŸå§‹æ–‡æœ¬æ¥æ„é€ å¯¹è¯æ•°æ®ã€‚

åŸºäºå§œå­ç‰™-13Bçš„æ¨¡å‹æ˜¯ç¬¬ä¸€ç‰ˆæ¨¡å‹ï¼Œå¾—ç›Šäºå§œå­ç‰™çš„ä¼˜ç§€ä¸­æ–‡èƒ½åŠ›å’Œæˆ‘ä»¬å¯¹æ•°æ®æ¸…æ´—ã€æ•°æ®å¢å¼ºè¿‡ç¨‹çš„ä¸¥æ ¼è¦æ±‚ï¼Œæˆ‘ä»¬åœ¨é€»è¾‘ç®€å•çš„æ³•å¾‹ä»»åŠ¡ä¸Šè¡¨ç°ä¼˜å¼‚ï¼Œä½†æ¶‰åŠåˆ°å¤æ‚é€»è¾‘çš„æ³•å¾‹æ¨ç†ä»»åŠ¡æ—¶å¾€å¾€è¡¨ç°ä¸ä½³ã€‚

éšååŸºäºAnima-33Bï¼Œæˆ‘ä»¬å¢åŠ äº†è®­ç»ƒæ•°æ®ï¼Œåšæˆäº†ChatLaw-33Bï¼Œå‘ç°é€»è¾‘æ¨ç†èƒ½åŠ›å¤§å¹…æå‡ï¼Œç”±æ­¤å¯è§ï¼Œå¤§å‚æ•°çš„ä¸­æ–‡LLMæ˜¯è‡³å…³é‡è¦çš„ã€‚

æˆ‘ä»¬çš„æŠ€æœ¯æŠ¥å‘Šåœ¨è¿™é‡Œ: arXiv: ChatLaw

åŸºäºå¯å•†ç”¨çš„æ¨¡å‹è®­ç»ƒè€Œæˆçš„ç‰ˆæœ¬ä¼šä½œä¸ºæˆ‘ä»¬åç»­äº§å“å†…éƒ¨æ¥å…¥çš„ç‰ˆæœ¬ï¼Œå¯¹å¤–ä¸å¼€æºï¼Œå¯ä»¥åœ¨è¿™é‡Œè¿›è¡Œå¼€æºç‰ˆæœ¬æ¨¡å‹çš„è¯•ç”¨

### Chinese-Llama-2-7b (LinkSoul-AI)
- https://github.com/LinkSoul-AI/Chinese-Llama-2-7b
- https://huggingface.co/spaces/LinkSoul/Chinese-Llama-2-7b

å…¨éƒ¨å¼€æºï¼Œå®Œå…¨å¯å•†ç”¨çš„ä¸­æ–‡ç‰ˆ Llama2 æ¨¡å‹åŠä¸­è‹±æ–‡ SFT æ•°æ®é›†ï¼Œè¾“å…¥æ ¼å¼ä¸¥æ ¼éµå¾ª llama-2-chat æ ¼å¼ï¼Œå…¼å®¹é€‚é…æ‰€æœ‰é’ˆå¯¹åŸç‰ˆ llama-2-chat æ¨¡å‹çš„ä¼˜åŒ–ã€‚

### Chinese-Vicuna-medical
- https://github.com/Facico/Chinese-Vicuna/blob/master/docs/performance-medical.md

åœ¨cMedQA2ä¸Šä½¿ç”¨æˆ‘ä»¬çš„checkpoint-11600 continue finetune

ç›®å‰ä»2ä¸ªepochçš„Vicunaå¼€å§‹continue finetuneï¼Œæ•ˆæœæ¯”3ä¸ªepochçš„åœ¨åŒ»ç–—é—®ç­”æ•°æ®æ›´å…·æœ‰ä¸“ä¸šæ€§ï¼ŒåŒæ—¶ç”±äºæ•°æ®é›†æ„å»ºçš„é—®é¢˜ï¼Œä¼šæ›´åŠ è§„èŒƒï¼Œæ¯”å¦‚ç»å¸¸æ€§çš„åŠ ä¸Šâ€œåˆ°æ­£è§„åŒ»é™¢æ£€æŸ¥â€ç­‰ç­‰

- åŒæ—¶éªŒè¯äº†æŒ‡ä»¤å¾®è°ƒçš„æœ‰æ•ˆæ€§
- ä½¿ç”¨å•æŒ‡ä»¤continue-finetuneèƒ½ä¿ç•™åŸæ¥æ›´å¤šçš„æ€§èƒ½

### Cornucopia-LLaMA-Fin-Chinese
- https://github.com/jerry1993-tech/Cornucopia-LLaMA-Fin-Chinese

èšå®ç›†(Cornucopia): åŸºäºä¸­æ–‡é‡‘èçŸ¥è¯†çš„LLaMAå¾®è°ƒæ¨¡å‹
æœ¬é¡¹ç›®å¼€æºäº†ç»è¿‡ä¸­æ–‡é‡‘èçŸ¥è¯†æŒ‡ä»¤ç²¾è°ƒ/æŒ‡ä»¤å¾®è°ƒ(Instruct-tuning) çš„LLaMA-7Bæ¨¡å‹ã€‚é€šè¿‡ä¸­æ–‡é‡‘èå…¬å¼€æ•°æ®+çˆ¬å–çš„é‡‘èæ•°æ®æ„å»ºæŒ‡ä»¤æ•°æ®é›†ï¼Œå¹¶åœ¨æ­¤åŸºç¡€ä¸Šå¯¹LLaMAè¿›è¡Œäº†æŒ‡ä»¤å¾®è°ƒï¼Œæé«˜äº† LLaMA åœ¨é‡‘èé¢†åŸŸçš„é—®ç­”æ•ˆæœã€‚

åŸºäºç›¸åŒçš„æ•°æ®ï¼ŒåæœŸè¿˜ä¼šåˆ©ç”¨GPT3.5 APIæ„å»ºé«˜è´¨é‡çš„æ•°æ®é›†ï¼Œå¦åœ¨ä¸­æ–‡çŸ¥è¯†å›¾è°±-é‡‘èä¸Šè¿›ä¸€æ­¥æ‰©å……é«˜è´¨é‡çš„æŒ‡ä»¤æ•°æ®é›†

é™†ç»­ä¼šå‘å¸ƒç ”å‘çš„æ–°æ¨¡å‹ï¼ˆnext-pretrainã€multi-task SFTã€RLHF Optimizeï¼‰ï¼Œæ¬¢è¿å¤§å®¶å±Šæ—¶ä½¿ç”¨ä½“éªŒã€‚

### chatglm-maths
- https://github.com/yongzhuo/chatglm-maths

chatglm-6bå¾®è°ƒ/LORA/PPO/æ¨ç†, æ ·æœ¬ä¸ºè‡ªåŠ¨ç”Ÿæˆçš„æ•´æ•°/å°æ•°åŠ å‡ä¹˜é™¤è¿ç®—, å¯gpu/cpuã€‚

### Abel
- https://github.com/GAIR-NLP/abel

Abel is created as a tribute to Niels Henrik Abel for his groundbreaking work in algebra and analysis, at which our model is relatively better as well. There is still a long way for us to go, though ğŸƒâ€â™‚ï¸ğŸƒâ€â™€ï¸ğŸğŸƒâ€â™‚ï¸ğŸƒâ€â™€ï¸.

We show that:
- without tools
- without continuing pretraining
- without reward model
- without RLHF
- ONLY using SFT

We have established a new state-of-the-art performance across open-source LLMs (that do not use external tools) on the GSM8k (83.62) and MATH (28.26) benchmarks. Specifically

### InternLM-Math
- https://github.com/InternLM/InternLM-Math

State-of-the-art bilingual open-sourced Math reasoning LLMs. A solver, prover, verifier, augmentor.

### DeepSeekMath
- https://arxiv.org/abs/2402.03300
- https://github.com/deepseek-ai/DeepSeek-Math

Mathematical reasoning poses a significant challenge for language models due to its complex and structured nature. In this paper, we introduce DeepSeekMath 7B, which continues pre-training DeepSeek-Coder-Base-v1.5 7B with 120B math-related tokens sourced from Common Crawl, together with natural language and code data. DeepSeekMath 7B has achieved an impressive score of 51.7% on the competition-level MATH benchmark without relying on external toolkits and voting techniques, approaching the performance level of Gemini-Ultra and GPT-4. Self-consistency over 64 samples from DeepSeekMath 7B achieves 60.9% on MATH. The mathematical reasoning capability of DeepSeekMath is attributed to two key factors: First, we harness the significant potential of publicly available web data through a meticulously engineered data selection pipeline. Second, we introduce Group Relative Policy Optimization (GRPO), a variant of Proximal Policy Optimization (PPO), that enhances mathematical reasoning abilities while concurrently optimizing the memory usage of PPO.

### ChatRWKV
- https://github.com/BlinkDL/ChatRWKV

ChatRWKV is like ChatGPT but powered by my RWKV (100% RNN) language model, which is the only RNN (as of now) that can match transformers in quality and scaling, while being faster and saves VRAM. Training sponsored by Stability EleutherAI :)

### ChatYuan
- https://github.com/clue-ai/ChatYuan
- https://modelscope.cn/models/ClueAI/ChatYuan-large

å…ƒè¯­åŠŸèƒ½å‹å¯¹è¯å¤§æ¨¡å‹, è¿™ä¸ªæ¨¡å‹å¯ä»¥ç”¨äºé—®ç­”ã€ç»“åˆä¸Šä¸‹æ–‡åšå¯¹è¯ã€åšå„ç§ç”Ÿæˆä»»åŠ¡ï¼ŒåŒ…æ‹¬åˆ›æ„æ€§å†™ä½œï¼Œä¹Ÿèƒ½å›ç­”ä¸€äº›åƒæ³•å¾‹ã€æ–°å† ç­‰é¢†åŸŸé—®é¢˜ã€‚å®ƒåŸºäºPromptCLUE-largeç»“åˆæ•°äº¿æ¡åŠŸèƒ½å¯¹è¯å¤šè½®å¯¹è¯æ•°æ®è¿›ä¸€æ­¥è®­ç»ƒå¾—åˆ°ã€‚

PromptCLUE-largeåœ¨1000äº¿tokenä¸­æ–‡è¯­æ–™ä¸Šé¢„è®­ç»ƒï¼Œç´¯è®¡å­¦ä¹ 1.5ä¸‡äº¿ä¸­æ–‡tokenï¼Œå¹¶ä¸”åœ¨æ•°ç™¾ç§ä»»åŠ¡ä¸Šè¿›è¡ŒPromptä»»åŠ¡å¼è®­ç»ƒã€‚é’ˆå¯¹ç†è§£ç±»ä»»åŠ¡ï¼Œå¦‚åˆ†ç±»ã€æƒ…æ„Ÿåˆ†æã€æŠ½å–ç­‰ï¼Œå¯ä»¥è‡ªå®šä¹‰æ ‡ç­¾ä½“ç³»ï¼›é’ˆå¯¹å¤šç§ç”Ÿæˆä»»åŠ¡ï¼Œå¯ä»¥è¿›è¡Œé‡‡æ ·è‡ªç”±ç”Ÿæˆã€‚

### ChatGLM-6B
- https://github.com/THUDM/ChatGLM-6B
- https://github.com/THUDM/ChatGLM-6B/tree/main/ptuning

ChatGLM-6B æ˜¯ä¸€ä¸ªå¼€æºçš„ã€æ”¯æŒä¸­è‹±åŒè¯­çš„å¯¹è¯è¯­è¨€æ¨¡å‹ï¼ŒåŸºäº General Language Model (GLM) æ¶æ„ï¼Œå…·æœ‰ 62 äº¿å‚æ•°ã€‚ç»“åˆæ¨¡å‹é‡åŒ–æŠ€æœ¯ï¼Œç”¨æˆ·å¯ä»¥åœ¨æ¶ˆè´¹çº§çš„æ˜¾å¡ä¸Šè¿›è¡Œæœ¬åœ°éƒ¨ç½²ï¼ˆINT4 é‡åŒ–çº§åˆ«ä¸‹æœ€ä½åªéœ€ 6GB æ˜¾å­˜ï¼‰ã€‚ ChatGLM-6B ä½¿ç”¨äº†å’Œ ChatGPT ç›¸ä¼¼çš„æŠ€æœ¯ï¼Œé’ˆå¯¹ä¸­æ–‡é—®ç­”å’Œå¯¹è¯è¿›è¡Œäº†ä¼˜åŒ–ã€‚ç»è¿‡çº¦ 1T æ ‡è¯†ç¬¦çš„ä¸­è‹±åŒè¯­è®­ç»ƒï¼Œè¾…ä»¥ç›‘ç£å¾®è°ƒã€åé¦ˆè‡ªåŠ©ã€äººç±»åé¦ˆå¼ºåŒ–å­¦ä¹ ç­‰æŠ€æœ¯çš„åŠ æŒï¼Œ62 äº¿å‚æ•°çš„ ChatGLM-6B å·²ç»èƒ½ç”Ÿæˆç›¸å½“ç¬¦åˆäººç±»åå¥½çš„å›ç­”ã€‚æ›´å¤šä¿¡æ¯è¯·å‚è€ƒæˆ‘ä»¬çš„åšå®¢ã€‚

### ChatGLM2-6B
- https://github.com/THUDM/ChatGLM2-6B

ChatGLM2-6B æ˜¯å¼€æºä¸­è‹±åŒè¯­å¯¹è¯æ¨¡å‹ ChatGLM-6B çš„ç¬¬äºŒä»£ç‰ˆæœ¬ï¼Œåœ¨ä¿ç•™äº†åˆä»£æ¨¡å‹å¯¹è¯æµç•…ã€éƒ¨ç½²é—¨æ§›è¾ƒä½ç­‰ä¼—å¤šä¼˜ç§€ç‰¹æ€§çš„åŸºç¡€ä¹‹ä¸Šï¼ŒChatGLM2-6B å¼•å…¥äº†å¦‚ä¸‹æ–°ç‰¹æ€§ï¼š

- æ›´å¼ºå¤§çš„æ€§èƒ½ï¼šåŸºäº ChatGLM åˆä»£æ¨¡å‹çš„å¼€å‘ç»éªŒï¼Œæˆ‘ä»¬å…¨é¢å‡çº§äº† ChatGLM2-6B çš„åŸºåº§æ¨¡å‹ã€‚ChatGLM2-6B ä½¿ç”¨äº† GLM çš„æ··åˆç›®æ ‡å‡½æ•°ï¼Œç»è¿‡äº† 1.4T ä¸­è‹±æ ‡è¯†ç¬¦çš„é¢„è®­ç»ƒä¸äººç±»åå¥½å¯¹é½è®­ç»ƒï¼Œè¯„æµ‹ç»“æœæ˜¾ç¤ºï¼Œç›¸æ¯”äºåˆä»£æ¨¡å‹ï¼ŒChatGLM2-6B åœ¨ MMLUï¼ˆ+23%ï¼‰ã€CEvalï¼ˆ+33%ï¼‰ã€GSM8Kï¼ˆ+571%ï¼‰ ã€BBHï¼ˆ+60%ï¼‰ç­‰æ•°æ®é›†ä¸Šçš„æ€§èƒ½å–å¾—äº†å¤§å¹…åº¦çš„æå‡ï¼Œåœ¨åŒå°ºå¯¸å¼€æºæ¨¡å‹ä¸­å…·æœ‰è¾ƒå¼ºçš„ç«äº‰åŠ›ã€‚
- æ›´é•¿çš„ä¸Šä¸‹æ–‡ï¼šåŸºäº FlashAttention æŠ€æœ¯ï¼Œæˆ‘ä»¬å°†åŸºåº§æ¨¡å‹çš„ä¸Šä¸‹æ–‡é•¿åº¦ï¼ˆContext Lengthï¼‰ç”± ChatGLM-6B çš„ 2K æ‰©å±•åˆ°äº† 32Kï¼Œå¹¶åœ¨å¯¹è¯é˜¶æ®µä½¿ç”¨ 8K çš„ä¸Šä¸‹æ–‡é•¿åº¦è®­ç»ƒï¼Œå…è®¸æ›´å¤šè½®æ¬¡çš„å¯¹è¯ã€‚ä½†å½“å‰ç‰ˆæœ¬çš„ ChatGLM2-6B å¯¹å•è½®è¶…é•¿æ–‡æ¡£çš„ç†è§£èƒ½åŠ›æœ‰é™ï¼Œæˆ‘ä»¬ä¼šåœ¨åç»­è¿­ä»£å‡çº§ä¸­ç€é‡è¿›è¡Œä¼˜åŒ–ã€‚
- æ›´é«˜æ•ˆçš„æ¨ç†ï¼šåŸºäº Multi-Query Attention æŠ€æœ¯ï¼ŒChatGLM2-6B æœ‰æ›´é«˜æ•ˆçš„æ¨ç†é€Ÿåº¦å’Œæ›´ä½çš„æ˜¾å­˜å ç”¨ï¼šåœ¨å®˜æ–¹çš„æ¨¡å‹å®ç°ä¸‹ï¼Œæ¨ç†é€Ÿåº¦ç›¸æ¯”åˆä»£æå‡äº† 42%ï¼ŒINT4 é‡åŒ–ä¸‹ï¼Œ6G æ˜¾å­˜æ”¯æŒçš„å¯¹è¯é•¿åº¦ç”± 1K æå‡åˆ°äº† 8Kã€‚
- æ›´å¼€æ”¾çš„åè®®ï¼šChatGLM2-6B æƒé‡å¯¹å­¦æœ¯ç ”ç©¶å®Œå…¨å¼€æ”¾ï¼Œåœ¨è·å¾—å®˜æ–¹çš„ä¹¦é¢è®¸å¯åï¼Œäº¦å…è®¸å•†ä¸šä½¿ç”¨ã€‚å¦‚æœæ‚¨å‘ç°æˆ‘ä»¬çš„å¼€æºæ¨¡å‹å¯¹æ‚¨çš„ä¸šåŠ¡æœ‰ç”¨ï¼Œæˆ‘ä»¬æ¬¢è¿æ‚¨å¯¹ä¸‹ä¸€ä»£æ¨¡å‹ ChatGLM3 ç ”å‘çš„æèµ ã€‚

### Chinese-Transformer-XL
- https://github.com/THUDM/Chinese-Transformer-XL

æœ¬é¡¹ç›®æä¾›äº†æ™ºæºç ”ç©¶é™¢"æ–‡æ±‡" é¢„è®­ç»ƒæ¨¡å‹Chinese-Transformer-XLçš„é¢„è®­ç»ƒå’Œæ–‡æœ¬ç”Ÿæˆä»£ç ã€‚

### ChatMed-TCM & ChatMed-Consult
- https://github.com/michael-wzhu/ChatMed

ğŸš€ ChatMed-Consult : åŸºäºä¸­æ–‡åŒ»ç–—åœ¨çº¿é—®è¯Šæ•°æ®é›†ChatMed_Consult_Datasetçš„50w+åœ¨çº¿é—®è¯Š+ChatGPTå›å¤ä½œä¸ºè®­ç»ƒé›†ã€‚æ¨¡å‹ä¸»å¹²ä¸ºLlaMA-7b,èåˆäº†Chinese-LlaMA-Alpacaçš„LoRAæƒé‡ä¸ä¸­æ–‡æ‰©å±•è¯è¡¨ï¼Œç„¶åå†è¿›è¡ŒåŸºäºLoRAçš„å‚æ•°é«˜æ•ˆå¾®è°ƒã€‚æˆ‘ä»¬å°†å…¨éƒ¨ä»£ç éƒ½è¿›è¡Œäº†å…¬å¼€ã€‚æˆ‘ä»¬ä¹Ÿå°†éƒ¨ç½²ä¸€ä¸ªåœ¨çº¿Gradio demo, æ•¬è¯·å…³æ³¨ã€‚

â³ ChatMed-TCM : å¤§æ¨¡å‹èµ‹èƒ½ä¸­åŒ»è¯ä¼ æ‰¿ã€‚è¿™ä¸€æ¨¡å‹çš„è®­ç»ƒæ•°æ®ä¸ºä¸­åŒ»è¯æŒ‡ä»¤æ•°æ®é›†ChatMed_TCM_Datasetã€‚ä»¥æˆ‘ä»¬å¼€æºçš„ä¸­åŒ»è¯çŸ¥è¯†å›¾è°±ä¸ºåŸºç¡€ï¼Œé‡‡ç”¨ä»¥å®ä½“ä¸ºä¸­å¿ƒçš„è‡ªæŒ‡ä»¤æ–¹æ³•(entity-centric self-instruct)ï¼Œè°ƒç”¨ChatGPTå¾—åˆ°2.6w+çš„å›´ç»•ä¸­åŒ»è¯çš„æŒ‡ä»¤æ•°æ®ã€‚ChatMed-TCMæ¨¡å‹ä¹Ÿæ˜¯ä»¥LlaMAä¸ºåº•åº§ï¼Œé‡‡ç”¨LoRAå¾®è°ƒå¾—åˆ°ã€‚

### ChatGLM-Med
- https://github.com/SCIR-HI/Med-ChatGLM

åŸºäºä¸­æ–‡åŒ»å­¦çŸ¥è¯†çš„ChatGLMæ¨¡å‹å¾®è°ƒï¼Œæœ¬é¡¹ç›®å¼€æºäº†ç»è¿‡ä¸­æ–‡åŒ»å­¦æŒ‡ä»¤ç²¾è°ƒ/æŒ‡ä»¤å¾®è°ƒ(Instruct-tuning) çš„ChatGLM-6Bæ¨¡å‹ã€‚æˆ‘ä»¬é€šè¿‡åŒ»å­¦çŸ¥è¯†å›¾è°±å’ŒGPT3.5 APIæ„å»ºäº†ä¸­æ–‡åŒ»å­¦æŒ‡ä»¤æ•°æ®é›†ï¼Œå¹¶åœ¨æ­¤åŸºç¡€ä¸Šå¯¹ChatGLM-6Bè¿›è¡Œäº†æŒ‡ä»¤å¾®è°ƒï¼Œæé«˜äº†ChatGLMåœ¨åŒ»ç–—é¢†åŸŸçš„é—®ç­”æ•ˆæœã€‚

### CPM-Bee
- https://mp.weixin.qq.com/s/UCW1BT60Lr9x24Rj0cLuxw
- https://huggingface.co/openbmb/cpm-bee-10b
- https://github.com/OpenBMB/CPM-Bee

CPM-Bee æ˜¯ä¸€ä¸ª å®Œå…¨å¼€æºã€å…è®¸å•†ç”¨ çš„ç™¾äº¿å‚æ•°ä¸­è‹±æ–‡åŸºåº§æ¨¡å‹ã€‚å®ƒé‡‡ç”¨ Transformer è‡ªå›å½’æ¶æ„ï¼ˆauto-regressiveï¼‰ï¼Œä½¿ç”¨ä¸‡äº¿çº§é«˜è´¨é‡è¯­æ–™è¿›è¡Œé¢„è®­ç»ƒï¼Œæ‹¥æœ‰å¼ºå¤§çš„åŸºç¡€èƒ½åŠ›ã€‚CPM-Bee çš„ç‰¹ç‚¹å¯ä»¥æ€»ç»“å¦‚ä¸‹ï¼š

å¼€æºå¯å•†ç”¨ï¼šOpenBMB å§‹ç»ˆç§‰æ‰¿â€œè®©å¤§æ¨¡å‹é£å…¥åƒå®¶ä¸‡æˆ·â€çš„å¼€æºç²¾ç¥ï¼ŒCPM-Bee åŸºåº§æ¨¡å‹å°†å®Œå…¨å¼€æºå¹¶ä¸”å¯å•†ç”¨ï¼Œä»¥æ¨åŠ¨å¤§æ¨¡å‹é¢†åŸŸçš„å‘å±•ã€‚å¦‚éœ€å°†æ¨¡å‹ç”¨äºå•†ä¸šç”¨é€”ï¼Œåªéœ€ä¼ä¸šå®åé‚®ä»¶ç”³è¯·å¹¶è·å¾—å®˜æ–¹æˆæƒè¯ä¹¦ï¼Œå³å¯å•†ç”¨ä½¿ç”¨ã€‚

ä¸­è‹±åŒè¯­æ€§èƒ½ä¼˜å¼‚ï¼šCPM-Bee åŸºåº§æ¨¡å‹åœ¨é¢„è®­ç»ƒè¯­æ–™ä¸Šè¿›è¡Œäº†ä¸¥æ ¼çš„ç­›é€‰å’Œé…æ¯”ï¼ŒåŒæ—¶åœ¨ä¸­è‹±åŒè¯­ä¸Šå…·æœ‰äº®çœ¼è¡¨ç°ï¼Œå…·ä½“å¯å‚è§è¯„æµ‹ä»»åŠ¡å’Œç»“æœã€‚

è¶…å¤§è§„æ¨¡é«˜è´¨é‡è¯­æ–™ï¼šCPM-BeeåŸºåº§æ¨¡å‹åœ¨ä¸‡äº¿çº§è¯­æ–™ä¸Šè¿›è¡Œè®­ç»ƒï¼Œæ˜¯å¼€æºç¤¾åŒºå†…ç»è¿‡è¯­æ–™æœ€å¤šçš„æ¨¡å‹ä¹‹ä¸€ã€‚åŒæ—¶ï¼Œæˆ‘ä»¬å¯¹é¢„è®­ç»ƒè¯­æ–™è¿›è¡Œäº†ä¸¥æ ¼çš„ç­›é€‰ã€æ¸…æ´—å’Œåå¤„ç†ä»¥ç¡®ä¿è´¨é‡ã€‚

OpenBMBå¤§æ¨¡å‹ç³»ç»Ÿç”Ÿæ€æ”¯æŒï¼šOpenBMB å¤§æ¨¡å‹ç³»ç»Ÿåœ¨é«˜æ€§èƒ½é¢„è®­ç»ƒã€é€‚é…ã€å‹ç¼©ã€éƒ¨ç½²ã€å·¥å…·å¼€å‘äº†ä¸€ç³»åˆ—å·¥å…·ï¼ŒCPM-Bee åŸºåº§æ¨¡å‹å°†é…å¥—æ‰€æœ‰çš„å·¥å…·è„šæœ¬ï¼Œé«˜æ•ˆæ”¯æŒå¼€å‘è€…è¿›è¡Œè¿›é˜¶ä½¿ç”¨ã€‚ 

å¼ºå¤§çš„å¯¹è¯å’Œå·¥å…·ä½¿ç”¨èƒ½åŠ›ï¼šç»“åˆOpenBMB åœ¨æŒ‡ä»¤å¾®è°ƒå’Œå·¥å…·å­¦ä¹ çš„æ¢ç´¢ï¼Œæˆ‘ä»¬åœ¨ CPM-Bee åŸºåº§æ¨¡å‹çš„åŸºç¡€ä¸Šè¿›è¡Œå¾®è°ƒï¼Œè®­ç»ƒå‡ºäº†å…·æœ‰å¼ºå¤§å¯¹è¯å’Œå·¥å…·ä½¿ç”¨èƒ½åŠ›çš„å®ä¾‹æ¨¡å‹ï¼Œç°å·²å¼€æ”¾å®šå‘é‚€è¯·å†…æµ‹ï¼Œæœªæ¥ä¼šé€æ­¥å‘å…¬ä¼—å¼€æ”¾ã€‚

### DISC-MedLLMï¼ˆå¤æ—¦ï¼‰
- https://med.fudan-disc.com
- https://github.com/FudanDISC/DISC-MedLLM
- https://arxiv.org/abs/2308.14346

DISC-MedLLM æ˜¯åŸºäºæˆ‘ä»¬æ„å»ºçš„é«˜è´¨é‡æ•°æ®é›† DISC-Med-SFT åœ¨é€šç”¨é¢†åŸŸä¸­æ–‡å¤§æ¨¡å‹ Baichuan-13B ä¸Šè®­ç»ƒå¾—åˆ°çš„åŒ»ç–—å¤§æ¨¡å‹ã€‚å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œæˆ‘ä»¬çš„è®­ç»ƒæ•°æ®å’Œè®­ç»ƒæ–¹æ³•å¯ä»¥è¢«é€‚é…åˆ°ä»»ä½•åŸºåº§å¤§æ¨¡å‹ä¹‹ä¸Šã€‚

DISC-MedLLM å…·æœ‰ä¸‰ä¸ªå…³é”®ç‰¹ç‚¹ï¼š

- å¯é ä¸°å¯Œçš„ä¸“ä¸šçŸ¥è¯†ã€‚æˆ‘ä»¬ä»¥åŒ»å­¦çŸ¥è¯†å›¾è°±ä½œä¸ºä¿¡æ¯æºï¼Œé€šè¿‡é‡‡æ ·ä¸‰å…ƒç»„ï¼Œå¹¶ä½¿ç”¨é€šç”¨å¤§æ¨¡å‹çš„è¯­è¨€èƒ½åŠ›è¿›è¡Œå¯¹è¯æ ·æœ¬çš„æ„é€ ã€‚
- å¤šè½®å¯¹è¯çš„é—®è¯¢èƒ½åŠ›ã€‚æˆ‘ä»¬ä»¥çœŸå®å’¨è¯¢å¯¹è¯çºªå½•ä½œä¸ºä¿¡æ¯æºï¼Œä½¿ç”¨å¤§æ¨¡å‹è¿›è¡Œå¯¹è¯é‡å»ºï¼Œæ„å»ºè¿‡ç¨‹ä¸­è¦æ±‚æ¨¡å‹å®Œå…¨å¯¹é½å¯¹è¯ä¸­çš„åŒ»å­¦ä¿¡æ¯ã€‚
- å¯¹é½äººç±»åå¥½çš„å›å¤ã€‚ç—…äººå¸Œæœ›åœ¨å’¨è¯¢çš„è¿‡ç¨‹ä¸­è·å¾—æ›´ä¸°å¯Œçš„æ”¯æ’‘ä¿¡æ¯å’ŒèƒŒæ™¯çŸ¥è¯†ï¼Œä½†äººç±»åŒ»ç”Ÿçš„å›ç­”å¾€å¾€ç®€ç»ƒï¼›æˆ‘ä»¬é€šè¿‡äººå·¥ç­›é€‰ï¼Œæ„å»ºé«˜è´¨é‡çš„å°è§„æ¨¡æŒ‡ä»¤æ ·æœ¬ï¼Œå¯¹é½ç—…äººçš„éœ€æ±‚ã€‚

### Data-Copilot
- https://github.com/zwq2018/Data-Copilot
- https://arxiv.org/abs/2306.07209
- https://huggingface.co/spaces/zwq2018/Data-Copilot

Data-Copilot æ˜¯ä¸€ä¸ªåŸºäº LLM çš„ç³»ç»Ÿï¼Œç”¨äºå¤„ç†ä¸æ•°æ®ç›¸å…³çš„ä»»åŠ¡ï¼Œè¿æ¥äº†æ•°åäº¿æ¡æ•°æ®å’Œå¤šæ ·åŒ–çš„ç”¨æˆ·éœ€æ±‚ã€‚å®ƒç‹¬ç«‹è®¾è®¡æ¥å£å·¥å…·ï¼Œä»¥é«˜æ•ˆåœ°ç®¡ç†ã€è°ƒç”¨ã€å¤„ç†å’Œå¯è§†åŒ–æ•°æ®ã€‚åœ¨æ¥æ”¶åˆ°å¤æ‚è¯·æ±‚æ—¶ï¼ŒData-Copilot ä¼šè‡ªä¸»è°ƒç”¨è¿™äº›è‡ªè®¾è®¡çš„æ¥å£ï¼Œæ„å»ºä¸€ä¸ªå·¥ä½œæµç¨‹æ¥æ»¡è¶³ç”¨æˆ·çš„æ„å›¾ã€‚åœ¨æ²¡æœ‰äººç±»ååŠ©çš„æƒ…å†µä¸‹ï¼Œå®ƒèƒ½å¤Ÿç†Ÿç»ƒåœ°å°†æ¥è‡ªä¸åŒæ¥æºã€ä¸åŒæ ¼å¼çš„åŸå§‹æ•°æ®è½¬åŒ–ä¸ºäººæ€§åŒ–çš„è¾“å‡ºï¼Œå¦‚å›¾å½¢ã€è¡¨æ ¼å’Œæ–‡æœ¬ã€‚

### Tabular LLM
- https://github.com/SpursGoZmy/Tabular-LLM

æˆ‘ä»¬æå‡ºTabular-LLMé¡¹ç›®ï¼Œé¡¹ç›®çš„æ ¸å¿ƒè®¡åˆ’å¦‚ä¸‹ï¼š

- æ¢ç´¢ä¸åŒç±»å‹è¡¨æ ¼çš„è¡¨ç¤ºæ–¹æ³•ï¼šè®­ç»ƒLLMåŠ¿å¿…éœ€è¦å°†è¡¨æ ¼è½¬åŒ–ä¸ºä¸€ä¸ªæ–‡æœ¬åºåˆ—ï¼ŒChatGPTç­‰LLMä½¿ç”¨Markdownæ ¼å¼æ¥è¡¨ç¤ºç®€å•è¡¨æ ¼ï¼Œä½†è¿™ç§æ–¹æ³•æ— æ³•å¾ˆå¥½åœ°è¡¨ç¤ºæ›´å¤æ‚çš„è¡¨æ ¼ï¼Œæ¯”å¦‚åŒ…å«åˆå¹¶å•å…ƒæ ¼çš„å±‚çº§è¡¨æ ¼ï¼Œå› æ­¤æˆ‘ä»¬éœ€è¦æ¢ç´¢å¦‚ä½•ï¼ˆç»Ÿä¸€ï¼‰è¡¨ç¤ºä¸åŒç±»å‹çš„è¡¨æ ¼ï¼Œæ›´å¤šè®¨è®ºè§ä¸‹ä¸€èŠ‚ã€‚
- æ”¶é›†å¹¶æ•´ç†æ¶µç›–å¤šç§ç±»å‹è¡¨æ ¼ã€å¤šç§è¡¨æ ¼æ™ºèƒ½ä»»åŠ¡çš„æ•°æ®ï¼šè€ƒè™‘å­¦ç•Œç›®å‰ç ”ç©¶è¾ƒå¤šçš„è¡¨æ ¼æ™ºèƒ½ä»»åŠ¡ï¼Œæ”¶é›†å¼€æºçš„æ•°æ®é›†å¹¶å°†å…¶è½¬åŒ–ä¸ºæŒ‡ä»¤å¾®è°ƒæ ¼å¼çš„æ•°æ®ï¼Œä»¥ä¾¿ç”¨æˆ·æŒ‰éœ€é€‰æ‹©ã€‚
- å¼€æºè¡¨æ ¼æ™ºèƒ½LLMå¹¶è¿›è¡Œæµ‹è¯•åˆ†æï¼šåˆ©ç”¨æ”¶é›†åˆ°çš„æ•°æ®å»å¾®è°ƒAlpaca-CoTç­‰æ¨¡å‹ï¼Œæ„å»ºé¦–æ‰¹é¢å‘è¡¨æ ¼æ™ºèƒ½ä»»åŠ¡çš„å¼€æºLLMï¼Œåœ¨æ­¤åŸºç¡€ä¸Šå¯¹è®­ç»ƒå¥½çš„æ¨¡å‹è¿›è¡Œæµ‹è¯•åˆ†æï¼Œæ¯”å¦‚æµ‹è¯•è®­ç»ƒåçš„æ¨¡å‹åœ¨å­¦ç•Œæµ‹è¯•æ•°æ®é›†ä¸Šçš„è¡¨ç°ï¼Œåç»­å°†ç›¸å…³å®éªŒç»“æœæ•´ç†ä¸ºæ–‡æ¡£ï¼Œå¸Œæœ›èƒ½ä¸ºå¤§å®¶æä¾›ä¸€äº›æœ‰ç”¨çš„ç»éªŒã€‚

### DoctorGLM
- https://github.com/xionghonglin/DoctorGLM

DoctorGLMï¼ŒåŸºäº ChatGLM-6Bçš„ä¸­æ–‡é—®è¯Šæ¨¡å‹ã€‚

### EduChat
- https://github.com/icalk-nlp/EduChat

æ•™è‚²æ˜¯å½±å“äººçš„èº«å¿ƒå‘å±•çš„ç¤¾ä¼šå®è·µæ´»åŠ¨ï¼Œæ—¨åœ¨æŠŠäººæ‰€å›ºæœ‰çš„æˆ–æ½œåœ¨çš„ç´ è´¨è‡ªå†…è€Œå¤–æ¿€å‘å‡ºæ¥ã€‚å› æ­¤ï¼Œå¿…é¡»è´¯å½»â€œä»¥äººä¸ºæœ¬â€çš„æ•™è‚²ç†å¿µï¼Œé‡ç‚¹å…³æ³¨äººçš„ä¸ªæ€§åŒ–ã€å¼•å¯¼å¼ã€èº«å¿ƒå…¨é¢å‘å±•ã€‚ä¸ºäº†æ›´å¥½åœ°åŠ©åŠ›â€ä»¥äººä¸ºæœ¬â€œçš„æ•™è‚²ï¼Œåä¸œå¸ˆèŒƒå¤§å­¦è®¡ç®—æœºç§‘å­¦ä¸æŠ€æœ¯å­¦é™¢çš„EduNLPå›¢é˜Ÿæ¢ç´¢äº†é’ˆå¯¹æ•™è‚²å‚ç›´é¢†åŸŸçš„å¯¹è¯å¤§æ¨¡å‹EduChatç›¸å…³é¡¹ç›®ç ”å‘ã€‚è¯¥é¡¹ç›®ä¸»è¦ç ”ç©¶ä»¥é¢„è®­ç»ƒå¤§æ¨¡å‹ä¸ºåŸºåº•çš„æ•™è‚²å¯¹è¯å¤§æ¨¡å‹ç›¸å…³æŠ€æœ¯ï¼Œèåˆå¤šæ ·åŒ–çš„æ•™è‚²å‚ç›´é¢†åŸŸæ•°æ®ï¼Œè¾…ä»¥æŒ‡ä»¤å¾®è°ƒã€ä»·å€¼è§‚å¯¹é½ç­‰æ–¹æ³•ï¼Œæä¾›æ•™è‚²åœºæ™¯ä¸‹è‡ªåŠ¨å‡ºé¢˜ã€ä½œä¸šæ‰¹æ”¹ã€æƒ…æ„Ÿæ”¯æŒã€è¯¾ç¨‹è¾…å¯¼ã€é«˜è€ƒå’¨è¯¢ç­‰ä¸°å¯ŒåŠŸèƒ½ï¼ŒæœåŠ¡äºå¹¿å¤§è€å¸ˆã€å­¦ç”Ÿå’Œå®¶é•¿ç¾¤ä½“ï¼ŒåŠ©åŠ›å®ç°å› ææ–½æ•™ã€å…¬å¹³å…¬æ­£ã€å¯Œæœ‰æ¸©åº¦çš„æ™ºèƒ½æ•™è‚²ã€‚

### EVA: å¤§è§„æ¨¡ä¸­æ–‡å¼€æ”¾åŸŸå¯¹è¯ç³»ç»Ÿ
- https://github.com/thu-coai/EVA

EVA æ˜¯ç›®å‰æœ€å¤§çš„å¼€æºä¸­æ–‡é¢„è®­ç»ƒå¯¹è¯æ¨¡å‹ï¼Œæ‹¥æœ‰28äº¿å‚æ•°ï¼Œä¸»è¦æ“…é•¿å¼€æ”¾åŸŸé—²èŠï¼Œç›®å‰æœ‰ 1.0 å’Œ 2.0 ä¸¤ä¸ªç‰ˆæœ¬ã€‚å…¶ä¸­ï¼Œ1.0ç‰ˆæœ¬åœ¨ WudaoCorpus-Dialog ä¸Šè®­ç»ƒè€Œæˆï¼Œ2.0 ç‰ˆæœ¬åœ¨ä» WudaoCorpus-Dialog ä¸­æ¸…æ´—å‡ºçš„æ›´é«˜è´¨é‡çš„å¯¹è¯æ•°æ®ä¸Šè®­ç»ƒè€Œæˆï¼Œæ¨¡å‹æ€§èƒ½ä¹Ÿæ˜æ˜¾å¥½äº EVA1.0ã€‚

### EcomGPT
- https://arxiv.org/abs/2308.06966
- https://github.com/Alibaba-NLP/EcomGPT

- we proposed the first E-commerce instruction dataset EcomInstruct, with a total of 2.5 million instruction data.
- EcomInstruct scales up the data size and task diversity by constructing atomic tasks with E-commerce basic data types, such as product information, user reviews. Atomic tasks are defined as intermediate tasks implicitly involved in solving a final task, which we also call Chain-of-Task tasks.
- We developed EcomGPT by training the backbone model BLOOMZ with the EcomInstruct. Benefiting from the fundamental semantic understanding capabilities acquired from the Chain-of-Task tasks, EcomGPT exhibits excellent zero-shot generalization capabilities.

### FinGLM
- https://github.com/MetaGLM/FinGLM/

ğŸ“ˆ ä¸€ä¸ªæ—¨åœ¨æ·±åº¦è§£æä¸Šå¸‚å…¬å¸å¹´æŠ¥çš„å¯¹è¯äº¤äº’æ™ºèƒ½ç³»ç»Ÿã€‚é¢å¯¹é‡‘èæ–‡æœ¬ä¸­çš„ä¸“ä¸šæœ¯è¯­ä¸æš—å«ä¿¡æ¯ï¼Œæˆ‘ä»¬è‡´åŠ›äºç”¨AIå®ç°ä¸“å®¶çº§åˆ«çš„é‡‘èåˆ†æã€‚

ğŸš€ åœ¨AIé¢†åŸŸï¼Œè™½ç„¶å·²åœ¨æ–‡æœ¬å¯¹è¯å–å¾—è¿›å±•ï¼Œä½†çœŸæ­£çš„é‡‘èäº¤äº’åœºæ™¯ä»ç„¶æ˜¯ä¸€ä¸ªå·¨å¤§æŒ‘æˆ˜ã€‚å¤šæ–¹æœºæ„è”æ‰‹ä¸¾åŠæ­¤æ¬¡ç«èµ›ï¼Œæ¢ç´¢é‡‘èé¢†åŸŸAIçš„è¾¹ç•Œã€‚

ğŸ“˜ ä¸Šå¸‚å…¬å¸å¹´æŠ¥ä¸ºæŠ•èµ„è€…å‘ˆç°äº†å…¬å¸çš„ç»è¥çŠ¶å†µã€è´¢åŠ¡çŠ¶å†µå’Œæœªæ¥è§„åˆ’ã€‚ä¸“ä¸šçŸ¥è¯†æ˜¯è§£è¯»çš„å…³é”®ï¼Œè€Œæˆ‘ä»¬çš„ç›®æ ‡æ˜¯é€šè¿‡AIæŠ€æœ¯è®©è¿™ä¸€è¿‡ç¨‹å˜å¾—æ›´ç®€å•ã€æ›´å‡†ç¡®ã€‚

### DISC-FinLLM
- https://fin.fudan-disc.com
- https://github.com/FudanDISC/DISC-FinLLM

DISC-FinLLM æ˜¯ä¸€ä¸ªä¸“é—¨é’ˆå¯¹é‡‘èåœºæ™¯ä¸‹ä¸ºç”¨æˆ·æä¾›ä¸“ä¸šã€æ™ºèƒ½ã€å…¨é¢çš„é‡‘èå’¨è¯¢æœåŠ¡çš„é‡‘èé¢†åŸŸå¤§æ¨¡å‹ï¼Œç”±å¤æ—¦å¤§å­¦æ•°æ®æ™ºèƒ½ä¸ç¤¾ä¼šè®¡ç®—å®éªŒå®¤ (Fudan-DISC) å¼€å‘å¹¶å¼€æºã€‚

### Deepmoney
- https://sota.jiqizhixin.com/project/deepmoney
- https://huggingface.co/TriadParty

DeepMoneyæ˜¯ä¸€ä¸ªä¸“æ³¨äºé‡‘èé¢†åŸŸæŠ•èµ„çš„å¤§å‹è¯­è¨€æ¨¡å‹é¡¹ç›®ã€‚è¯¥æ¨¡å‹åŸºäºYi-34Bã€DeepSeek 67Bã€miqu-70bæ„å»ºï¼Œå½“å‰ä½œè€…å¾®è°ƒäº†ä¸‰ä¸ªæ¨¡å‹ç‰ˆæœ¬ï¼šbaseå’Œsft (åŸºäºyi-34B)ã€deepmoney-67b-chat (DeepSeek) ï¼Œå’Œdeepmoney-miqu-70b(migu-70b)ã€‚åŸºç¡€æ¨¡å‹é‡‡ç”¨äº†å…¨å‚æ•°è®­ç»ƒã€‚å…¶è®­ç»ƒæ•°æ®åŒ…æ‹¬é«˜è´¨é‡çš„ç ”ç©¶æŠ¥å‘Šï¼Œè¦†ç›–2019å¹´è‡³2023å¹´12æœˆçš„æ•°æ®ï¼Œè¿™äº›æŠ¥å‘Šä¸»è¦æ¥è‡ªä¼ ç»Ÿåˆ¸å•†å’Œä¸“ä¸šç ”ç©¶æœºæ„ï¼Œå¤§å¤šæ•°ä¸ºæœ‰å¿ä¸”ä»…å¯¹æœºæ„å¼€æ”¾ã€‚ä¸å¤§å¤šæ•°åŸºäºå…¬å…±çŸ¥è¯†è®­ç»ƒçš„é‡‘èæ¨¡å‹ä¸åŒï¼Œdeepmoneyèƒ½å¤Ÿæä¾›æ·±å…¥çš„å¸‚åœºè§£é‡Šï¼Œå¼¥è¡¥å…¬å…±çŸ¥è¯†åœ¨å®é™…é‡‘èé¢†åŸŸä¸­çš„ä¸è¶³ã€‚è¯¥é¡¹ç›®è¿˜é›†æˆäº†å¤šæ¨¡æ€æ¨¡å‹ï¼Œä»¥æå–å…³é”®ä¿¡æ¯ã€‚

### GPT2 for Multiple Language
- https://github.com/imcaspar/gpt2-ml

- ç®€åŒ–æ•´ç† GPT2 è®­ç»ƒä»£ç ï¼ˆbased on Grover, supporting TPUsï¼‰
- ç§»æ¤ bert tokenizerï¼Œæ·»åŠ å¤šè¯­è¨€æ”¯æŒ
- 15äº¿å‚æ•° GPT2 ä¸­æ–‡é¢„è®­ç»ƒæ¨¡å‹( 15G è¯­æ–™ï¼Œè®­ç»ƒ 10w æ­¥ )
- å¼€ç®±å³ç”¨çš„æ¨¡å‹ç”Ÿæˆæ•ˆæœ demo #
- 15äº¿å‚æ•° GPT2 ä¸­æ–‡é¢„è®­ç»ƒæ¨¡å‹( 30G è¯­æ–™ï¼Œè®­ç»ƒ 22w æ­¥ )

### InternLM ä¹¦ç”Ÿãƒ»æµ¦è¯­
- https://github.com/InternLM
- https://mp.weixin.qq.com/s/oTXnvWZJVdoOpFLHngbTYQ
- https://intern-ai.org.cn/home

InternLM has open-sourced a 7 billion parameter base model and a chat model tailored for practical scenarios. The model has the following characteristics:

It leverages trillions of high-quality tokens for training to establish a powerful knowledge base.
It supports an 8k context window length, enabling longer input sequences and stronger reasoning capabilities.

It provides a versatile toolset for users to flexibly build their own workflows.
Additionally, a lightweight training framework is offered to support model pre-training without the need for extensive dependencies. With a single codebase, it supports pre-training on large-scale clusters with thousands of GPUs, and fine-tuning on a single GPU while achieving remarkable performance optimizations. InternLM achieves nearly 90% acceleration efficiency during training on 1024 GPUs.

### Llama2-chat-Chinese-50W
- https://mp.weixin.qq.com/s/r_hKK5_cYm8ClqYVApkUYQ
- https://huggingface.co/RicardoLee/Llama2-chat-Chinese-50W

ç”±äºç›®å‰çš„LLama2-chatæ¨¡å‹å¾ˆéš¾çº¦æŸå…¶ä»¥ä¸­æ–‡è¿›è¡Œé—®é¢˜å›å¤ï¼Œå› æ­¤è¯¥æ¨¡å‹æ—¨åœ¨æä¾›ä¸€ä¸ªèƒ½ä»¥ä¸­æ–‡è¿›è¡Œé—®ç­”çš„LLama2-chat 7B æ¨¡å‹ã€‚

è¯¥æ¨¡å‹ä½¿ç”¨LLama2-chat 7B ä½œä¸ºåŸºåº•æ¨¡å‹ï¼Œä½¿ç”¨å¸¦embedding å’Œ LM head çš„Loraè®­ç»ƒæ–¹å¼è®­ç»ƒã€‚æ¨¡å‹å·²å®Œæˆå‚æ•°åˆå¹¶ï¼Œå¯ç›´æ¥ä½¿ç”¨ã€‚ä¹Ÿå¯ä»¥æ‰‹åŠ¨å°†sft_lora_modelåŒLlama2-chatè¿›è¡Œåˆå¹¶ã€‚

è®­ç»ƒæ•°æ®ä½¿ç”¨BELLEé¡¹ç›®ä¸­é‡‡æ ·çš„50ä¸‡SFTæ•°æ®è¿›è¡ŒSFTè®­ç»ƒã€‚

### Llama2-Chinese (FlagAlpha)
- https://github.com/FlagAlpha/Llama2-Chinese
- https://llama.family/

æˆ‘ä»¬æ˜¯ä¸€ä¸ªä¸“æ³¨äºLlama2æ¨¡å‹åœ¨ä¸­æ–‡æ–¹é¢çš„ä¼˜åŒ–å’Œä¸Šå±‚å»ºè®¾çš„é«˜çº§æŠ€æœ¯ç¤¾åŒºã€‚ *åŸºäºå¤§è§„æ¨¡ä¸­æ–‡æ•°æ®ï¼Œä»é¢„è®­ç»ƒå¼€å§‹å¯¹Llama2æ¨¡å‹è¿›è¡Œä¸­æ–‡èƒ½åŠ›çš„æŒç»­è¿­ä»£å‡çº§*ã€‚ æˆ‘ä»¬çƒ­å¿±æ¬¢è¿å¯¹å¤§æ¨¡å‹LLMå……æ»¡çƒ­æƒ…çš„å¼€å‘è€…å’Œç ”ç©¶è€…åŠ å…¥æˆ‘ä»¬çš„è¡Œåˆ—ã€‚

### LaWGPT
- https://github.com/pengxiao-song/LaWGPT

LaWGPT æ˜¯ä¸€ç³»åˆ—åŸºäºä¸­æ–‡æ³•å¾‹çŸ¥è¯†çš„å¼€æºå¤§è¯­è¨€æ¨¡å‹ã€‚

è¯¥ç³»åˆ—æ¨¡å‹åœ¨é€šç”¨ä¸­æ–‡åŸºåº§æ¨¡å‹ï¼ˆå¦‚ Chinese-LLaMAã€ChatGLM ç­‰ï¼‰çš„åŸºç¡€ä¸Šæ‰©å……æ³•å¾‹é¢†åŸŸä¸“æœ‰è¯è¡¨ã€å¤§è§„æ¨¡ä¸­æ–‡æ³•å¾‹è¯­æ–™é¢„è®­ç»ƒï¼Œå¢å¼ºäº†å¤§æ¨¡å‹åœ¨æ³•å¾‹é¢†åŸŸçš„åŸºç¡€è¯­ä¹‰ç†è§£èƒ½åŠ›ã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œæ„é€ æ³•å¾‹é¢†åŸŸå¯¹è¯é—®ç­”æ•°æ®é›†ã€ä¸­å›½å¸æ³•è€ƒè¯•æ•°æ®é›†è¿›è¡ŒæŒ‡ä»¤ç²¾è°ƒï¼Œæå‡äº†æ¨¡å‹å¯¹æ³•å¾‹å†…å®¹çš„ç†è§£å’Œæ‰§è¡Œèƒ½åŠ›ã€‚

### å¤«å­â€¢æ˜å¯Ÿå¸æ³•å¤§æ¨¡å‹
- https://github.com/irlab-sdu/fuzi.mingcha

å¤«å­â€¢æ˜å¯Ÿå¸æ³•å¤§æ¨¡å‹æ˜¯ç”±å±±ä¸œå¤§å­¦ã€æµªæ½®äº‘ã€ä¸­å›½æ”¿æ³•å¤§å­¦è”åˆç ”å‘ï¼Œä»¥ ChatGLM ä¸ºå¤§æ¨¡å‹åº•åº§ï¼ŒåŸºäºæµ·é‡ä¸­æ–‡æ— ç›‘ç£å¸æ³•è¯­æ–™ï¼ˆåŒ…æ‹¬å„ç±»åˆ¤å†³æ–‡ä¹¦ã€æ³•å¾‹æ³•è§„ç­‰ï¼‰ä¸æœ‰ç›‘ç£å¸æ³•å¾®è°ƒæ•°æ®ï¼ˆåŒ…æ‹¬æ³•å¾‹é—®ç­”ã€ç±»æ¡ˆæ£€ç´¢ï¼‰è®­ç»ƒçš„ä¸­æ–‡å¸æ³•å¤§æ¨¡å‹ã€‚è¯¥æ¨¡å‹æ”¯æŒæ³•æ¡æ£€ç´¢ã€æ¡ˆä¾‹åˆ†æã€ä¸‰æ®µè®ºæ¨ç†åˆ¤å†³ä»¥åŠå¸æ³•å¯¹è¯ç­‰åŠŸèƒ½ï¼Œæ—¨åœ¨ä¸ºç”¨æˆ·æä¾›å…¨æ–¹ä½ã€é«˜ç²¾å‡†çš„æ³•å¾‹å’¨è¯¢ä¸è§£ç­”æœåŠ¡ã€‚

### DISC-LawLLM
- https://law.fudan-disc.com
- https://github.com/FudanDISC/DISC-LawLLM
- https://arxiv.org/abs/2309.11325

å¤æ—¦å¤§å­¦æ•°æ®æ™ºèƒ½ä¸ç¤¾ä¼šè®¡ç®—å®éªŒå®¤ï¼ˆFudanDISCï¼‰å‘å¸ƒå¤§è¯­è¨€æ¨¡å‹é©±åŠ¨çš„ä¸­æ–‡æ™ºæ…§æ³•å¾‹ç³»ç»Ÿâ€”â€”DISC-LawLLMã€‚è¯¥ç³»ç»Ÿå¯ä»¥é¢å‘ä¸åŒç”¨æˆ·ç¾¤ä½“ï¼Œæä¾›å¤šæ ·çš„æ³•å¾‹æœåŠ¡ã€‚æ­¤å¤–ï¼Œæ„å»ºäº†è¯„æµ‹åŸºå‡†DISC-Law-Evalï¼Œä»å®¢è§‚å’Œä¸»è§‚ä¸¤ä¸ªæ–¹é¢æ¥è¯„æµ‹æ³•å¾‹å¤§è¯­è¨€æ¨¡å‹ï¼Œæ¨¡å‹åœ¨è¯„æµ‹ä¸­çš„è¡¨ç°ç›¸è¾ƒç°æœ‰çš„æ³•å¾‹å¤§æ¨¡å‹æœ‰æ˜æ˜¾ä¼˜åŠ¿ã€‚

è¯¾é¢˜ç»„åŒæ—¶å…¬å¼€åŒ…å«30ä¸‡é«˜è´¨é‡çš„ç›‘ç£å¾®è°ƒï¼ˆSFTï¼‰æ•°æ®é›†â€”â€”DISC-Law-SFTï¼Œæ¨¡å‹å‚æ•°å’ŒæŠ€æœ¯æŠ¥å‘Šä¹Ÿä¸€å¹¶å¼€æºã€‚

### LawBench
- https://github.com/open-compass/LawBench
- https://arxiv.org/abs/2309.16289

LawBenchç»è¿‡ç²¾å¿ƒè®¾è®¡ï¼Œå¯å¯¹å¤§è¯­è¨€æ¨¡å‹çš„æ³•å¾‹èƒ½åŠ›è¿›è¡Œç²¾ç¡®è¯„ä¼°ã€‚ åœ¨è®¾è®¡æµ‹è¯•ä»»åŠ¡æ—¶ï¼Œæˆ‘ä»¬æ¨¡æ‹Ÿäº†å¸æ³•è®¤çŸ¥çš„ä¸‰ä¸ªç»´åº¦ï¼Œå¹¶é€‰æ‹©äº†20ä¸ªä»»åŠ¡æ¥è¯„ä¼°å¤§æ¨¡å‹çš„èƒ½åŠ›ã€‚ä¸ä¸€äº›ä»…æœ‰å¤šé¡¹é€‰æ‹©é¢˜çš„ç°æœ‰åŸºå‡†ç›¸æ¯”ï¼Œæˆ‘ä»¬åŒ…å«äº†æ›´å¤šä¸ç°å®ä¸–ç•Œåº”ç”¨å¯†åˆ‡ç›¸å…³çš„ä»»åŠ¡ç±»å‹ï¼Œå¦‚æ³•å¾‹å®ä½“è¯†åˆ«ã€é˜…è¯»ç†è§£ã€çŠ¯ç½ªé‡‘é¢è®¡ç®—å’Œå’¨è¯¢ç­‰ã€‚ æˆ‘ä»¬è®¤è¯†åˆ°å½“å‰å¤§æ¨¡å‹çš„å®‰å…¨æ€§ç­–ç•¥å¯èƒ½ä¼šæ‹’ç»å›åº”æŸäº›æ³•å¾‹è¯¢é—®ï¼Œæˆ–åœ¨ç†è§£æŒ‡ä»¤æ–¹é¢é‡åˆ°å›°éš¾ï¼Œä»è€Œå¯¼è‡´ç¼ºä¹å›åº”ã€‚å› æ­¤ï¼Œæˆ‘ä»¬å¼€å‘äº†ä¸€ä¸ªå•ç‹¬çš„è¯„ä¼°æŒ‡æ ‡ "å¼ƒæƒç‡"ï¼Œä»¥è¡¡é‡æ¨¡å‹æ‹’ç»æä¾›ç­”æ¡ˆæˆ–æœªèƒ½æ­£ç¡®ç†è§£æŒ‡ä»¤çš„é¢‘ç‡ã€‚ æˆ‘ä»¬æ±‡æŠ¥äº†51ç§å¤§è¯­è¨€æ¨¡å‹åœ¨LawBenchä¸Šçš„è¡¨ç°ï¼ŒåŒ…æ‹¬20ç§å¤šè¯­è¨€æ¨¡å‹ã€22ç§ä¸­æ–‡æ¨¡å‹å’Œ9ç§æ³•å¾‹ä¸“ç”¨å¤§è¯­è¨€æ¨¡å‹ã€‚

### Lawyer LLaMA
- https://github.com/AndrewZhe/lawyer-llama

Lawyer LLaMA é¦–å…ˆåœ¨å¤§è§„æ¨¡æ³•å¾‹è¯­æ–™ä¸Šè¿›è¡Œäº†continual pretrainingï¼Œè®©å®ƒç³»ç»Ÿçš„å­¦ä¹ ä¸­å›½çš„æ³•å¾‹çŸ¥è¯†ä½“ç³»ã€‚ åœ¨æ­¤åŸºç¡€ä¸Šï¼Œæˆ‘ä»¬å€ŸåŠ©ChatGPTæ”¶é›†äº†ä¸€æ‰¹å¯¹ä¸­å›½å›½å®¶ç»Ÿä¸€æ³•å¾‹èŒä¸šèµ„æ ¼è€ƒè¯•å®¢è§‚é¢˜ï¼ˆä»¥ä¸‹ç®€ç§°æ³•è€ƒï¼‰çš„åˆ†æå’Œå¯¹æ³•å¾‹å’¨è¯¢çš„å›ç­”ï¼Œåˆ©ç”¨æ”¶é›†åˆ°çš„æ•°æ®å¯¹æ¨¡å‹è¿›è¡ŒæŒ‡ä»¤å¾®è°ƒï¼Œè®©æ¨¡å‹ä¹ å¾—å°†æ³•å¾‹çŸ¥è¯†åº”ç”¨åˆ°å…·ä½“åœºæ™¯ä¸­çš„èƒ½åŠ›ã€‚

æˆ‘ä»¬çš„æ¨¡å‹èƒ½å¤Ÿï¼š
- æŒæ¡ä¸­å›½æ³•å¾‹çŸ¥è¯†ï¼š èƒ½å¤Ÿæ­£ç¡®çš„ç†è§£æ°‘æ³•ã€åˆ‘æ³•ã€è¡Œæ”¿æ³•ã€è¯‰è®¼æ³•ç­‰å¸¸è§é¢†åŸŸçš„æ³•å¾‹æ¦‚å¿µã€‚ä¾‹å¦‚ï¼ŒæŒæ¡äº†åˆ‘æ³•ä¸­çš„çŠ¯ç½ªæ„æˆç†è®ºï¼Œèƒ½å¤Ÿä»åˆ‘äº‹æ¡ˆä»¶çš„äº‹å®æè¿°ä¸­è¯†åˆ«çŠ¯ç½ªä¸»ä½“ã€çŠ¯ç½ªå®¢ä½“ã€çŠ¯ç½ªè¡Œä¸ºã€ä¸»è§‚å¿ƒç†çŠ¶æ€ç­‰çŠ¯ç½ªæ„æˆè¦ä»¶ã€‚æ¨¡å‹åˆ©ç”¨å­¦åˆ°çš„æ³•å¾‹æ¦‚å¿µä¸ç†è®ºï¼Œèƒ½å¤Ÿè¾ƒå¥½å›ç­”æ³•è€ƒä¸­çš„å¤§éƒ¨åˆ†é¢˜ç›®ã€‚
- åº”ç”¨äºä¸­å›½æ³•å¾‹å®åŠ¡ï¼šèƒ½å¤Ÿä»¥é€šä¿—æ˜“æ‡‚çš„è¯­è¨€è§£é‡Šæ³•å¾‹æ¦‚å¿µï¼Œå¹¶ä¸”è¿›è¡ŒåŸºç¡€çš„æ³•å¾‹å’¨è¯¢ï¼Œæ¶µç›–å©šå§»ã€å€Ÿè´·ã€æµ·å•†ã€åˆ‘äº‹ç­‰æ³•å¾‹é¢†åŸŸã€‚
- ä¸ºäº†ç»™ä¸­æ–‡æ³•å¾‹å¤§æ¨¡å‹çš„å¼€æ”¾ç ”ç©¶æ·»ç –åŠ ç“¦ï¼Œæœ¬é¡¹ç›®å°†å¼€æºä¸€ç³»åˆ—æ³•å¾‹é¢†åŸŸçš„æŒ‡ä»¤å¾®è°ƒæ•°æ®å’ŒåŸºäºLLaMAè®­ç»ƒçš„ä¸­æ–‡æ³•å¾‹å¤§æ¨¡å‹çš„å‚æ•° ã€‚

### LexiLaw
- https://github.com/CSHaitao/LexiLaw

LexiLaw æ˜¯ä¸€ä¸ªç»è¿‡å¾®è°ƒçš„ä¸­æ–‡æ³•å¾‹å¤§æ¨¡å‹ï¼Œå®ƒåŸºäº ChatGLM-6B æ¶æ„ï¼Œé€šè¿‡åœ¨æ³•å¾‹é¢†åŸŸçš„æ•°æ®é›†ä¸Šè¿›è¡Œå¾®è°ƒï¼Œä½¿å…¶åœ¨æä¾›æ³•å¾‹å’¨è¯¢å’Œæ”¯æŒæ–¹é¢å…·å¤‡æ›´é«˜çš„æ€§èƒ½å’Œä¸“ä¸šæ€§ã€‚

è¯¥æ¨¡å‹æ—¨åœ¨ä¸ºæ³•å¾‹ä»ä¸šè€…ã€å­¦ç”Ÿå’Œæ™®é€šç”¨æˆ·æä¾›å‡†ç¡®ã€å¯é çš„æ³•å¾‹å’¨è¯¢æœåŠ¡ã€‚æ— è®ºæ‚¨æ˜¯éœ€è¦é’ˆå¯¹å…·ä½“æ³•å¾‹é—®é¢˜çš„å’¨è¯¢ï¼Œè¿˜æ˜¯å¯¹æ³•å¾‹æ¡æ¬¾ã€æ¡ˆä¾‹è§£æã€æ³•è§„è§£è¯»ç­‰æ–¹é¢çš„æŸ¥è¯¢ï¼ŒLexiLaw éƒ½èƒ½å¤Ÿä¸ºæ‚¨æä¾›æœ‰ç›Šçš„å»ºè®®å’ŒæŒ‡å¯¼ã€‚

åŒæ—¶ï¼Œæˆ‘ä»¬å°†åˆ†äº«åœ¨å¤§æ¨¡å‹åŸºç¡€ä¸Šå¾®è°ƒçš„ç»éªŒå’Œæœ€ä½³å®è·µï¼Œä»¥å¸®åŠ©ç¤¾åŒºå¼€å‘æ›´å¤šä¼˜ç§€çš„ä¸­æ–‡æ³•å¾‹å¤§æ¨¡å‹ï¼Œæ¨åŠ¨ä¸­æ–‡æ³•å¾‹æ™ºèƒ½åŒ–çš„å‘å±•ã€‚

### LawGPT_zh ä¸­æ–‡æ³•å¾‹å¤§æ¨¡å‹ï¼ˆç¬è±¸ï¼‰
- https://mp.weixin.qq.com/s/Pk4NdFQq5G6iZ3QmcyyFUg
- https://github.com/LiuHC0428/LAW-GPT

æˆ‘ä»¬çš„æ„¿æ™¯æ˜¯ä¸ºè®©æ‰€æœ‰äººåœ¨é‡åˆ°æ³•å¾‹é—®é¢˜æ—¶èƒ½ç¬¬ä¸€æ—¶é—´è·å¾—ä¸“ä¸šå¯é çš„å›ç­”ã€‚å› ä¸ºä¸“ä¸šçš„å¾‹å¸ˆæœåŠ¡åªæœ‰çœŸæ­£è§¦æ‰‹å¯åŠï¼Œæ‰ä¼šè®©äººä»¬ä¹ æƒ¯è¿ç”¨ï¼Œä¸€å¦‚äºŒåå¹´å‰çš„æœç´¢å¼•æ“ï¼Œåå¹´å‰çš„å¿«é€’ä¸šåŠ¡ã€‚æˆ‘ä»¬å¸Œæœ›è®©æ³•å¾‹èµ°è¿›æ—¥å¸¸ç”Ÿæ´»ï¼Œä¸ºæ„å»ºæ³•æ²»ç¤¾ä¼šè´¡çŒ®æˆ‘ä»¬çš„åŠ›é‡ã€‚é¡¹ç›®æµ·æŠ¥ç”±Midjourneyç”Ÿæˆã€‚

æœ¬é¡¹ç›®å¼€æºçš„ä¸­æ–‡æ³•å¾‹é€šç”¨æ¨¡å‹ç”±ChatGLM-6B LoRA 16-bitæŒ‡ä»¤å¾®è°ƒå¾—åˆ°ã€‚æ•°æ®é›†åŒ…æ‹¬ç°æœ‰çš„æ³•å¾‹é—®ç­”æ•°æ®é›†å’ŒåŸºäºæ³•æ¡å’ŒçœŸå®æ¡ˆä¾‹æŒ‡å¯¼çš„self-Instructæ„å»ºçš„é«˜è´¨é‡æ³•å¾‹æ–‡æœ¬é—®ç­”ï¼Œæé«˜äº†é€šç”¨è¯­è¨€å¤§æ¨¡å‹åœ¨æ³•å¾‹é¢†åŸŸçš„è¡¨ç°ï¼Œæé«˜äº†æ¨¡å‹å›ç­”çš„å¯é æ€§å’Œä¸“ä¸šç¨‹åº¦ã€‚

### Linlyä¼¶è”è¯´ ä¸­æ–‡ LLaMA1-2 & OpenLLaMA & Falcon å¤§æ¨¡å‹
- https://github.com/CVI-SZU/Linly
- https://mp.weixin.qq.com/s/zSxsArP1pxYNubNDZua7iA
- https://mp.weixin.qq.com/s/AuAG3tw4JI8lHyLkSdM18g

æœ¬é¡¹ç›®å‘ç¤¾åŒºæä¾›ä¸­æ–‡å¯¹è¯æ¨¡å‹ Linly-ChatFlow ã€ä¸­æ–‡åŸºç¡€æ¨¡å‹ Chinese-LLaMA (1-2)ã€Chinese-Falcon åŠå…¶è®­ç»ƒæ•°æ®ã€‚ æ¨¡å‹åŸºäº TencentPretrain é¢„è®­ç»ƒæ¡†æ¶å…¨å‚æ•°è®­ç»ƒï¼ˆFull-tuningï¼‰ã€‚ ä¸­æ–‡åŸºç¡€æ¨¡å‹ä»¥ LLaMA å’Œ Falcon ä¸ºåº•åº§ï¼Œåˆ©ç”¨ä¸­æ–‡å’Œä¸­è‹±å¹³è¡Œå¢é‡é¢„è®­ç»ƒï¼Œå°†å®ƒåœ¨è‹±æ–‡ä¸Šè¯­è¨€èƒ½åŠ›è¿ç§»åˆ°ä¸­æ–‡ä¸Šã€‚è¿›ä¸€æ­¥ï¼Œé¡¹ç›®æ±‡æ€»äº†ç›®å‰å…¬å¼€çš„å¤šè¯­è¨€æŒ‡ä»¤æ•°æ®ï¼Œå¯¹ä¸­æ–‡æ¨¡å‹è¿›è¡Œäº†å¤§è§„æ¨¡æŒ‡ä»¤è·Ÿéšè®­ç»ƒï¼Œå®ç°äº† Linly-ChatFlow å¯¹è¯æ¨¡å‹ã€‚

æ­¤å¤–ï¼Œæœ¬é¡¹ç›®è¿˜å…¬å¼€ä»å¤´è®­ç»ƒçš„ Linly-OpenLLaMA æ¨¡å‹ï¼ŒåŒ…å« 3Bã€7Bã€13B è§„æ¨¡ï¼Œåœ¨ 1TB ä¸­è‹±æ–‡è¯­æ–™é¢„è®­ç»ƒï¼Œé’ˆå¯¹ä¸­æ–‡ä¼˜åŒ–å­—è¯ç»“åˆtokenizerï¼Œæ¨¡å‹ä»¥ Apache 2.0 åè®®å…¬å¼€ã€‚

### MediaGPT
- https://github.com/IMOSR/MediaGPT

è™½ç„¶LLaMAæ¨¡å‹åœ¨é€šç”¨é¢†åŸŸé€šè¿‡æŒ‡ä»¤å¾®è°ƒå·²ç»å±•ç¤ºå‡ºäº†ä»¤äººå°è±¡æ·±åˆ»çš„æ€§èƒ½ï¼Œä½†å¯¹äºè‡ªåª’ä½“åˆ›ä½œã€ç›´æ’­å’Œè¿è¥ç­‰é¢†åŸŸï¼Œç”±äºç¼ºä¹ä¸“ä¸šçš„è®­ç»ƒæ•°æ®ï¼Œå…¶èƒ½åŠ›ä»æœ‰å¾…æé«˜ã€‚ä¸ºäº†è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæˆ‘ä»¬æå‡ºäº†MediaGPTï¼Œä¸€ä¸ªé’ˆå¯¹è‡ªåª’ä½“é¢†åŸŸè¿›è¡Œç‰¹æ®Šè®­ç»ƒçš„æ¨¡å‹ã€‚

MediaGPTï¼ˆæ›¾ç”¨åMedia LLaMAï¼‰é¦–å…ˆåœ¨å¤§è§„æ¨¡è‡ªåª’ä½“è¯­æ–™ä¸Šè¿›è¡Œè¿ç»­é¢„è®­ç»ƒï¼Œç³»ç»Ÿåœ°å­¦ä¹ è‡ªåª’ä½“çš„çŸ¥è¯†ä½“ç³»ã€‚ç„¶åï¼Œæˆ‘ä»¬å€ŸåŠ©ChatGPTæ”¶é›†äº†ä¸€æ‰¹å…³äºæŠ–éŸ³è¿è¥ã€çŸ­è§†é¢‘åˆ›ä½œã€å·¨é‡åƒå·æŠ•æ”¾ã€ç›´æ’­è¿è¥å’Œç›´æ’­è¯æœ¯æŠ€å·§ç­‰é¢†åŸŸçŸ¥è¯†é—®é¢˜çš„åˆ†æå’Œå›ç­”ï¼Œå¹¶åˆ©ç”¨è¿™äº›æ•°æ®å¯¹æ¨¡å‹è¿›è¡ŒæŒ‡ä»¤å¾®è°ƒï¼Œä½¿æ¨¡å‹ä¹ å¾—å¦‚ä½•å°†è‡ªåª’ä½“çŸ¥è¯†åº”ç”¨åˆ°å®é™…åœºæ™¯ä¸­ã€‚

æˆ‘ä»¬çš„æ¨¡å‹å…·æœ‰ä»¥ä¸‹èƒ½åŠ›ï¼š
1. æŒæ¡è‡ªåª’ä½“çŸ¥è¯†ï¼š èƒ½å¤Ÿç†è§£æŠ–éŸ³è¿è¥ã€çŸ­è§†é¢‘åˆ›ä½œã€å·¨é‡åƒå·æŠ•æ”¾ã€ç›´æ’­è¿è¥ç­‰é¢†åŸŸçš„æ ¸å¿ƒæ¦‚å¿µå’Œç­–ç•¥ã€‚

2. é€‚ç”¨äºå®é™…æ“ä½œï¼š èƒ½å¤Ÿä»¥é€šä¿—æ˜“æ‡‚çš„è¯­è¨€è§£é‡Šè‡ªåª’ä½“æ¦‚å¿µï¼Œå¹¶è¿›è¡ŒåŸºç¡€çš„è‡ªåª’ä½“è¿è¥å’¨è¯¢ï¼Œæ¶µç›–å†…å®¹åˆ›ä½œã€å¹³å°è¿è¥ã€å¹¿å‘ŠæŠ•æ”¾ç­‰é¢†åŸŸã€‚

ä¸ºäº†æ¨åŠ¨ä¸­æ–‡è‡ªåª’ä½“å¤§æ¨¡å‹çš„å¼€æ”¾ç ”ç©¶ï¼Œæˆ‘ä»¬å°†å¼€æºä¸€ç³»åˆ—è‡ªåª’ä½“é¢†åŸŸçš„æŒ‡ä»¤å¾®è°ƒæ•°æ®å’ŒåŸºäºLLaMAè®­ç»ƒçš„ä¸­æ–‡è‡ªåª’ä½“å¤§æ¨¡å‹çš„å‚æ•°ã€‚

### CharacterGLM-6B
- https://github.com/thu-coai/CharacterGLM-6B
- https://arxiv.org/pdf/2311.16832.pdf

In this paper, we present CharacterGLM, a series of models built upon ChatGLM, with model sizes ranging from 6B to 66B parameters. Our CharacterGLM is designed for generating Character-based Dialogues (CharacterDial), which aims to equip a conversational AI system with character customization for satisfying people's inherent social desires and emotional needs. On top of CharacterGLM, we can customize various AI characters or social agents by configuring their attributes (identities, interests, viewpoints, experiences, achievements, social relationships, etc.) and behaviors (linguistic features, emotional expressions, interaction patterns, etc.). Our model outperforms most mainstream close-source large langauge models, including the GPT series, especially in terms of consistency, human-likeness, and engagement according to manual evaluations. We will release our 6B version of CharacterGLM and a subset of training data to facilitate further research development in the direction of character-based dialogue generation.

### Haruhi-Zero
- https://github.com/LC1332/Zero-Haruhi
- https://huggingface.co/silk-road/Haruhi-Zero-7B-0_3

å‡‰å®«æ˜¥æ—¥-Zeroæ˜¯ä¸€ä¸ªåŒæ—¶æ”¯æŒZero-Shotè§’è‰²æ„é€ å’ŒRAGè§’è‰²æ„é€ (åŸChatHaruhi)çš„è§’è‰²æ‰®æ¼”æ¨¡å‹ã€‚

### MeChat (Mental Health Support Chatbot)
- https://github.com/qiuhuachuan/smile
- https://huggingface.co/qiuhuachuan/MeChat
- https://mechat.fly.dev/

æˆ‘ä»¬çš„æ„¿æ™¯æ˜¯ä¸ºè®©æ‰€æœ‰äººåœ¨é‡åˆ°å¿ƒç†å¥åº·é—®é¢˜æ—¶èƒ½å¤Ÿè·å¾—åŠæ—¶ã€æœ‰æ•ˆçš„å€¾å¬å’Œæ”¯æŒã€‚æˆ‘ä»¬ç›¸ä¿¡ï¼Œå¿ƒç†å¥åº·æ˜¯æ¯ä¸ªäººçš„æƒåˆ©ï¼Œè€Œä¸æ˜¯å¥¢ä¾ˆå“ã€‚æˆ‘ä»¬çš„ä½¿å‘½æ˜¯ä¸ºäººä»¬æä¾›å¹³ç­‰ã€å…¨é¢ã€æ˜“äºè®¿é—®çš„å¿ƒç†å¥åº·æœåŠ¡ï¼Œæ— è®ºä»–ä»¬èº«åœ¨ä½•å¤„ã€é¢ä¸´ä½•ç§æŒ‘æˆ˜ã€‚æˆ‘ä»¬çš„æ„¿æ™¯è¿˜åŒ…æ‹¬æ¨åŠ¨ç¤¾ä¼šå¯¹å¿ƒç†å¥åº·é—®é¢˜çš„è®¤è¯†å’Œç†è§£ï¼Œæ‰“ç ´å¿ƒç†å¥åº·é—®é¢˜å¸¦æ¥çš„æ±¡åå’Œæ­§è§†ï¼Œä¸ºåˆ›å»ºä¸€ä¸ªæ›´åŠ å¥åº·ã€åŒ…å®¹å’Œå¹³ç­‰çš„ç¤¾ä¼šåšå‡ºè´¡çŒ®ã€‚é¡¹ç›®æµ·æŠ¥å–è‡ª flaticon ã€‚

### MedicalGPT
- https://github.com/shibing624/MedicalGPT

MedicalGPT è®­ç»ƒåŒ»ç–—å¤§æ¨¡å‹ï¼Œå®ç°åŒ…æ‹¬äºŒæ¬¡é¢„è®­ç»ƒã€æœ‰ç›‘ç£å¾®è°ƒã€å¥–åŠ±å»ºæ¨¡ã€å¼ºåŒ–å­¦ä¹ è®­ç»ƒã€‚

åŸºäºChatGPT Training Pipelineï¼Œæœ¬é¡¹ç›®å®ç°äº†é¢†åŸŸæ¨¡å‹--åŒ»ç–—æ¨¡å‹çš„å››é˜¶æ®µè®­ç»ƒï¼š

ç¬¬ä¸€é˜¶æ®µï¼šPT(Continue PreTraining)å¢é‡é¢„è®­ç»ƒï¼Œåœ¨æµ·é‡é¢†åŸŸæ–‡æ¡£æ•°æ®ä¸ŠäºŒæ¬¡é¢„è®­ç»ƒGPTæ¨¡å‹ï¼Œä»¥æ³¨å…¥é¢†åŸŸçŸ¥è¯†

ç¬¬äºŒé˜¶æ®µï¼šSFT(Supervised Fine-tuning)æœ‰ç›‘ç£å¾®è°ƒï¼Œæ„é€ æŒ‡ä»¤å¾®è°ƒæ•°æ®é›†ï¼Œåœ¨é¢„è®­ç»ƒæ¨¡å‹åŸºç¡€ä¸ŠåšæŒ‡ä»¤ç²¾è°ƒï¼Œä»¥å¯¹é½æŒ‡ä»¤æ„å›¾

ç¬¬ä¸‰é˜¶æ®µï¼šRM(Reward Model)å¥–åŠ±æ¨¡å‹å»ºæ¨¡ï¼Œæ„é€ äººç±»åå¥½æ’åºæ•°æ®é›†ï¼Œè®­ç»ƒå¥–åŠ±æ¨¡å‹ï¼Œç”¨æ¥å¯¹é½äººç±»åå¥½ï¼Œä¸»è¦æ˜¯"HHH"åŸåˆ™ï¼Œå…·ä½“æ˜¯"helpful, honest, harmless"

ç¬¬å››é˜¶æ®µï¼šRL(Reinforcement Learning)åŸºäºäººç±»åé¦ˆçš„å¼ºåŒ–å­¦ä¹ (RLHF)ï¼Œç”¨å¥–åŠ±æ¨¡å‹æ¥è®­ç»ƒSFTæ¨¡å‹ï¼Œç”Ÿæˆæ¨¡å‹ä½¿ç”¨å¥–åŠ±æˆ–æƒ©ç½šæ¥æ›´æ–°å…¶ç­–ç•¥ï¼Œä»¥ä¾¿ç”Ÿæˆæ›´é«˜è´¨é‡ã€æ›´ç¬¦åˆäººç±»åå¥½çš„æ–‡æœ¬

### æ˜åŒ» (MING)ï¼šä¸­æ–‡åŒ»ç–—é—®è¯Šå¤§æ¨¡å‹ ï¼ˆåŸåï¼šMedicalGPT-zhï¼‰
- https://github.com/MediaBrain-SJTU/MING

**MedicalGPT-zh**
è¯¥å¼€æºäº†åŸºäºChatGLM-6B LoRA 16-bitæŒ‡ä»¤å¾®è°ƒçš„ä¸­æ–‡åŒ»ç–—é€šç”¨æ¨¡å‹ã€‚åŸºäºå…±è®¡28ç§‘å®¤çš„ä¸­æ–‡åŒ»ç–—å…±è¯†ä¸ä¸´åºŠæŒ‡å—æ–‡æœ¬ï¼Œæˆ‘ä»¬ç”ŸæˆåŒ»ç–—çŸ¥è¯†è¦†ç›–é¢æ›´å…¨ï¼Œå›ç­”å†…å®¹æ›´åŠ ç²¾å‡†çš„é«˜è´¨é‡æŒ‡ä»¤æ•°æ®é›†ã€‚

**æ˜åŒ»ï¼ˆMINGï¼‰**
æœ¬é¡¹ç›®å¼€æºäº†åŸºäºåŒ»ç–—æŒ‡ä»¤å¾®è°ƒçš„ä¸­æ–‡åŒ»ç–—é—®è¯Šæ¨¡å‹ï¼šæ˜åŒ» (MING)ã€‚

### OpenKG-KnowLLM
- https://github.com/zjunlp/KnowLLM

Knowledgable Large Language Model Series.

With the rapid development of deep learning technology, large language models such as ChatGPT have achieved significant success in the field of natural language processing. However, these large models still face some challenges and issues in learning and understanding knowledge, including the difficulty of knowledge updating, and issues with potential errors and biases within the model, known as knowledge fallacies. The Deep Model series aims to release a series of open-source large models to mitigate these knowledge fallacy issues. The first phase of this project released a knowledge extraction large model based on LLaMA, named Zhishi. To provide Chinese capabilities without disrupting the original model's distribution, we firstly (1) use Chinese corpora for the full-scale pre-training of LLaMA (13B), in order to improve the model's understanding of Chinese and knowledge reserve as much as possible while retaining its original English and code capabilities; Then (2) we fine-tune the model from the first step using an instruction dataset, to enhance the language model's understanding of human extraction instructions.

### OpenMEDLab æµ¦åŒ»
- https://github.com/OpenMEDLab
- https://github.com/openmedlab/PULSE
- https://stcsm.sh.gov.cn/xwzx/kjzl/20230630/c783c30d8e62494e83073535f841675f.html

OpenMEDLab is an open-source platform to share medical foundation models in multi-modalities, e.g., medical imaging, medical NLP, bioinformatics, protein, etc. It targets promoting novel approaches to long-tail problems in medicine, and meanwhile, it seeks solutions to achieve lower cost, higher efficiency, and better generalizability in training medical AI models. The new learning paradigm of adapting foundation models to downstream applications makes it possible to develop innovative solutions for cross-domain and cross-modality diagnostic tasks efficiently. OpenMEDLab is distinguished by several features:
- World's first open-source platform for medical foundation models.
- 10+ medical data modalities targeting a variety of clinical and research problems.
- Pioneering works of the new learning paradigm using foundation models, including pre-trained models, code, and data.
- Releasing multiple sets of medical data for pre-training and downstream applications.
- Collaboration with top medical institutes and facilities.

### PromptCLUE
- https://github.com/clue-ai/PromptCLUE

PromptCLUEï¼šå¤§è§„æ¨¡å¤šä»»åŠ¡Prompté¢„è®­ç»ƒä¸­æ–‡å¼€æºæ¨¡å‹ã€‚

ä¸­æ–‡ä¸Šçš„ä¸‰å¤§ç»Ÿä¸€ï¼šç»Ÿä¸€æ¨¡å‹æ¡†æ¶ï¼Œç»Ÿä¸€ä»»åŠ¡å½¢å¼ï¼Œç»Ÿä¸€åº”ç”¨æ–¹å¼ã€‚

æ”¯æŒå‡ åä¸ªä¸åŒç±»å‹çš„ä»»åŠ¡ï¼Œå…·æœ‰è¾ƒå¥½çš„é›¶æ ·æœ¬å­¦ä¹ èƒ½åŠ›å’Œå°‘æ ·æœ¬å­¦ä¹ èƒ½åŠ›ã€‚é’ˆå¯¹ç†è§£ç±»ä»»åŠ¡ï¼Œå¦‚åˆ†ç±»ã€æƒ…æ„Ÿåˆ†æã€æŠ½å–ç­‰ï¼Œå¯ä»¥è‡ªå®šä¹‰æ ‡ç­¾ä½“ç³»ï¼›é’ˆå¯¹ç”Ÿæˆä»»åŠ¡ï¼Œå¯ä»¥è¿›è¡Œé‡‡æ ·è‡ªç”±ç”Ÿæˆã€‚

åƒäº¿ä¸­æ–‡tokenä¸Šå¤§è§„æ¨¡é¢„è®­ç»ƒï¼Œç´¯è®¡å­¦ä¹ 1.5ä¸‡äº¿ä¸­æ–‡tokenï¼Œäº¿çº§ä¸­æ–‡ä»»åŠ¡æ•°æ®ä¸Šå®Œæˆè®­ç»ƒï¼Œè®­ç»ƒä»»åŠ¡è¶…è¿‡150+ã€‚æ¯”baseç‰ˆå¹³å‡ä»»åŠ¡æå‡7ä¸ªç‚¹+ï¼›å…·æœ‰æ›´å¥½çš„ç†è§£ã€ç”Ÿæˆå’ŒæŠ½å–èƒ½åŠ›ï¼Œå¹¶ä¸”æ”¯æŒæ–‡æœ¬æ”¹å†™ã€çº é”™ã€çŸ¥è¯†å›¾è°±é—®ç­”ã€‚

### SkyText-Chinese-GPT3
- https://github.com/SkyWorkAIGC/SkyText-Chinese-GPT3

SkyTextæ˜¯ç”±å¥‡ç‚¹æ™ºæºå‘å¸ƒçš„ä¸­æ–‡GPT3é¢„è®­ç»ƒå¤§æ¨¡å‹ï¼Œå¯ä»¥è¿›è¡ŒèŠå¤©ã€é—®ç­”ã€ä¸­è‹±äº’è¯‘ç­‰ä¸åŒçš„ä»»åŠ¡ã€‚ åº”ç”¨è¿™ä¸ªæ¨¡å‹ï¼Œé™¤äº†å¯ä»¥å®ç°åŸºæœ¬çš„èŠå¤©ã€å¯¹è¯ã€ä½ é—®æˆ‘ç­”å¤–ï¼Œè¿˜èƒ½æ”¯æŒä¸­è‹±æ–‡äº’è¯‘ã€å†…å®¹ç»­å†™ã€å¯¹å¯¹è”ã€å†™å¤è¯—ã€ç”Ÿæˆèœè°±ã€ç¬¬ä¸‰äººç§°è½¬è¿°ã€åˆ›å»ºé‡‡è®¿é—®é¢˜ç­‰å¤šç§åŠŸèƒ½ã€‚

### ShenNong-TCM-LLM
- https://github.com/michael-wzhu/ShenNong-TCM-LLM

ä¸ºæ¨åŠ¨LLMåœ¨ä¸­åŒ»è¯é¢†åŸŸçš„å‘å±•å’Œè½åœ°ï¼Œæå‡LLMçš„åœ¨ä¸­åŒ»è¯æ–¹é¢çš„çŸ¥è¯†ä¸å›ç­”åŒ»å­¦å’¨è¯¢çš„èƒ½åŠ›ï¼ŒåŒæ—¶æ¨åŠ¨å¤§æ¨¡å‹èµ‹èƒ½ä¸­åŒ»è¯ä¼ æ‰¿ï¼Œæˆ‘ä»¬ç°æ¨å‡ºShenNongä¸­åŒ»è¯å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹:

ğŸš€ ShenNong-TCM :
- è¿™ä¸€æ¨¡å‹çš„è®­ç»ƒæ•°æ®ä¸ºä¸­åŒ»è¯æŒ‡ä»¤æ•°æ®é›†ShenNong_TCM_Datasetã€‚
- ChatMed_TCM_Datasetä»¥æˆ‘ä»¬å¼€æºçš„ä¸­åŒ»è¯çŸ¥è¯†å›¾è°±ä¸ºåŸºç¡€ï¼›
- é‡‡ç”¨ä»¥å®ä½“ä¸ºä¸­å¿ƒçš„è‡ªæŒ‡ä»¤æ–¹æ³•entity-centric self-instructï¼Œè°ƒç”¨ChatGPTå¾—åˆ°11w+çš„å›´ç»•ä¸­åŒ»è¯çš„æŒ‡ä»¤æ•°æ®ï¼›
- ShenNong-TCMæ¨¡å‹ä¹Ÿæ˜¯ä»¥LlaMAä¸ºåº•åº§ï¼Œé‡‡ç”¨LoRA (rank=16)å¾®è°ƒå¾—åˆ°ã€‚å¾®è°ƒä»£ç ä¸ChatMedä»£ç åº“ç›¸åŒ

### TableGPT
- https://github.com/ZJU-M3/TableGPT-techreport

TableGPT is a specifically designed for table analysis. By unifying tables, natural language, and commands into one model, TableGPT comprehends tabular data, understands user intent through natural language, dissects the desired actions, and executes external commands on the table. It subsequently returns the processed results in both tabular and textual explanations to the user. This novel approach simplifies the way users engage with table data, bringing an intuitive feel to data analysis.

### TransGPT Â· è‡´è¿œ
- https://mp.weixin.qq.com/s/WvzyjHqI0lOGIyPlCIFNQg
- https://github.com/DUOMO/TransGPT

TransGPTãƒ»è‡´è¿œçš„è®­ç»ƒåŸºäºçº¦ 34.6 ä¸‡æ¡äº¤é€šé¢†åŸŸæ–‡æœ¬æ•°æ®ï¼ˆç”¨äºé¢†åŸŸå†…é¢„è®­ç»ƒï¼‰å’Œ 5.8 ä¸‡æ¡äº¤é€šé¢†åŸŸå¯¹è¯æ•°æ®ï¼ˆç”¨äºå¾®è°ƒï¼‰ï¼Œå¯æ”¯æŒå®æ—¶ç±» APP æ¥å…¥ï¼ˆåœ°å›¾ã€å…¬äº¤ç­‰åº”ç”¨ï¼‰ã€‚ç›®å‰ï¼ŒTransGPTãƒ»è‡´è¿œå·²å¼€æºï¼Œç›¸å…³èµ„æºä¸ä»…å¯¹å­¦æœ¯ç ”ç©¶å®Œå…¨å¼€æ”¾ï¼Œä»…éœ€é‚®ä»¶ç”³è¯·å¹¶è·å¾—å®˜æ–¹å•†ç”¨è®¸å¯åï¼Œå³å¯ä»¥å…è´¹å•†ç”¨ã€‚

ä¸é€šç”¨å‹çš„å¤šæ¨¡æ€äº¤é€šå¤§æ¨¡å‹äº§å“ä¸åŒï¼ŒTransGPT ä¸»è¦è‡´åŠ›äºåœ¨çœŸå®äº¤é€šåœºæ™¯ä¸­å‘æŒ¥å®é™…ä»·å€¼ï¼ŒåŒ…æ‹¬äº¤é€šæƒ…å†µé¢„æµ‹ã€æ™ºèƒ½å’¨è¯¢åŠ©æ‰‹ã€å…¬å…±äº¤é€šæœåŠ¡ã€äº¤é€šè§„åˆ’è®¾è®¡ã€äº¤é€šå®‰å…¨æ•™è‚²ã€ååŠ©ç®¡ç†ã€äº¤é€šäº‹æ•…æŠ¥å‘Šå’Œåˆ†æã€è‡ªåŠ¨é©¾é©¶è¾…åŠ©ç³»ç»Ÿç­‰èƒ½åŠ›ã€‚

### TechGPT
- https://mp.weixin.qq.com/s/nF1He7jhAHfh7PzhjqHoZg
- https://huggingface.co/neukg/TechGPT-7B
- https://github.com/neukg/TechGPT

2023å¹´6æœˆ26æ—¥ï¼Œâ€œä¸œåŒ—å¤§å­¦çŸ¥è¯†å›¾è°±ç ”ç©¶ç»„â€æ­£å¼å‘å¸ƒå¤§è¯­è¨€æ¨¡å‹TechGPTã€‚

TechGPTçš„åå­—ä¸»è¦æ¥æºäºå°ç»„åœ¨2018å¹´æ¨å‡ºçš„TechKGå¤§è§„æ¨¡ä¸­æ–‡å­¦æœ¯å¤šé¢†åŸŸçš„çŸ¥è¯†åº“ã€‚

ä¸å½“å‰å…¶ä»–å„ç±»å¤§æ¨¡å‹ç›¸æ¯”ï¼ŒTechGPTä¸»è¦å¼ºåŒ–äº†ä»¥â€œçŸ¥è¯†å›¾è°±æ„å»ºâ€ä¸ºæ ¸å¿ƒçš„å…³ç³»ä¸‰å…ƒç»„æŠ½å–ç­‰å„ç±»ä¿¡æ¯æŠ½å–ä»»åŠ¡ã€ä»¥â€œé€»è¾‘æ¨ç†â€ä¸ºæ ¸å¿ƒçš„æœºå™¨é˜…è¯»ç†è§£ç­‰å„ç±»æ™ºèƒ½é—®ç­”ä»»åŠ¡ã€ä»¥â€œæ–‡æœ¬ç†è§£â€ä¸ºæ ¸å¿ƒçš„å…³é”®è¯ç”Ÿæˆç­‰å„ç±»åºåˆ—ç”Ÿæˆä»»åŠ¡ã€‚

åœ¨è¿™ä¸‰å¤§è‡ªç„¶è¯­è¨€å¤„ç†æ ¸å¿ƒèƒ½åŠ›ä¹‹å†…ï¼ŒTechGPTè¿˜å…·å¤‡äº†å¯¹è®¡ç®—æœºç§‘å­¦ã€ææ–™ã€æœºæ¢°ã€å†¶é‡‘ã€é‡‘èå’Œèˆªç©ºèˆªå¤©ç­‰åä½™ç§å‚ç›´ä¸“ä¸šé¢†åŸŸè‡ªç„¶è¯­è¨€æ–‡æœ¬çš„å¤„ç†èƒ½åŠ›ã€‚

### TigerBot
- https://github.com/TigerResearch/TigerBot

TigerBot æ˜¯ä¸€ä¸ªå¤šè¯­è¨€å¤šä»»åŠ¡çš„å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹(LLM)ã€‚æ ¹æ® OpenAI InstructGPT è®ºæ–‡åœ¨å…¬å¼€ NLP æ•°æ®é›†ä¸Šçš„è‡ªåŠ¨è¯„æµ‹ï¼ŒTigerBot-7B è¾¾åˆ° OpenAI åŒæ ·å¤§å°æ¨¡å‹çš„ç»¼åˆè¡¨ç°çš„ 96%ï¼Œå¹¶ä¸”è¿™åªæ˜¯æˆ‘ä»¬çš„ MVPï¼Œåœ¨æ­¤æˆ‘ä»¬å°†å¦‚ä¸‹æ¢ç´¢æˆæœå¼€æºï¼š

- æ¨¡å‹ï¼šTigerBot-7B, TigerBot-7B-baseï¼ŒTigerBot-180B (research version)ï¼Œ
- ä»£ç ï¼šåŸºæœ¬è®­ç»ƒå’Œæ¨ç†ä»£ç ï¼ŒåŒ…æ‹¬åŒå¡æ¨ç† 180B æ¨¡å‹çš„é‡åŒ–å’Œæ¨ç†ä»£ç ï¼Œ
- æ•°æ®ï¼šé¢„è®­ç»ƒ 100Gï¼Œä» 2TB è¿‡æ»¤åçš„æ•°æ®ä¸­ç»è¿‡å»å™ªå»é‡æ¸…æ´—è€Œå¾—ï¼›ç›‘ç£å¾®è°ƒ 1G æˆ– 100 ä¸‡æ¡æ•°æ®ï¼ŒæŒ‰æ¯”ä¾‹æ¶µç›–ç”¨æˆ·æŒ‡ä»¤å¸¸è§çš„ 10 å¤§ç±» 120 å°ç±»ä»»åŠ¡ï¼Œ
- API: chat, plugin, finetune, è®©ç”¨æˆ·èƒ½åœ¨åŠå°æ—¶å†…æ— ä»£ç çš„è®­ç»ƒå’Œä½¿ç”¨ä¸“å±äºè‡ªå·±çš„å¤§æ¨¡å‹å’Œæ•°æ®ï¼Œ
- é¢†åŸŸæ•°æ®ï¼šæ¶µç›–é‡‘èï¼Œæ³•å¾‹ï¼Œç™¾ç§‘ï¼Œå¹¿é‚€å¤§æ¨¡å‹åº”ç”¨å¼€å‘è€…ï¼Œä¸€èµ·æ‰“é€ ä¸­å›½çš„ä¸–ç•Œçº§çš„åº”ç”¨ã€‚

æˆ‘ä»¬åœ¨ BLOOM åŸºç¡€ä¸Šï¼Œåœ¨æ¨¡å‹æ¶æ„å’Œç®—æ³•ä¸Šåšäº†å¦‚ä¸‹ä¼˜åŒ–ï¼š

- æŒ‡ä»¤å®Œæˆç›‘ç£å¾®è°ƒçš„åˆ›æ–°ç®—æ³•ä»¥è·å¾—æ›´å¥½çš„å¯å­¦ä¹ å‹(learnability)ï¼Œ
- è¿ç”¨ ensemble å’Œ probabilistic modeling çš„æ–¹æ³•å®ç°æ›´å¯æ§çš„äº‹å®æ€§(factuality)å’Œåˆ›é€ æ€§(generativeness)ï¼Œ
- åœ¨å¹¶è¡Œè®­ç»ƒä¸Šï¼Œæˆ‘ä»¬çªç ´äº† deep-speed ç­‰ä¸»æµæ¡†æ¶ä¸­è‹¥å¹²å†…å­˜å’Œé€šä¿¡é—®é¢˜ï¼Œä½¿å¾—åœ¨åƒå¡ç¯å¢ƒä¸‹æ•°æœˆæ— é—´æ–­ï¼Œ
- å¯¹ä¸­æ–‡è¯­è¨€çš„æ›´ä¸è§„åˆ™çš„åˆ†å¸ƒï¼Œä» tokenizer åˆ°è®­ç»ƒç®—æ³•ä¸Šåšäº†æ›´é€‚åˆçš„ç®—æ³•ä¼˜åŒ–ã€‚

### XVERSE-13B
- https://github.com/xverse-ai/XVERSE-13B

XVERSE-13B æ˜¯ç”±æ·±åœ³å…ƒè±¡ç§‘æŠ€è‡ªä¸»ç ”å‘çš„æ”¯æŒå¤šè¯­è¨€çš„å¤§è¯­è¨€æ¨¡å‹ï¼ˆLarge Language Modelï¼‰ï¼Œä¸»è¦ç‰¹ç‚¹å¦‚ä¸‹ï¼š
- æ¨¡å‹ç»“æ„ï¼šXVERSE-13B ä½¿ç”¨ä¸»æµ Decoder-only çš„æ ‡å‡† Transformer ç½‘ç»œç»“æ„ï¼Œæ”¯æŒ 8K çš„ä¸Šä¸‹æ–‡é•¿åº¦ï¼ˆContext Lengthï¼‰ï¼Œä¸ºåŒå°ºå¯¸æ¨¡å‹ä¸­æœ€é•¿ï¼Œèƒ½æ»¡è¶³æ›´é•¿çš„å¤šè½®å¯¹è¯ã€çŸ¥è¯†é—®ç­”ä¸æ‘˜è¦ç­‰éœ€æ±‚ï¼Œæ¨¡å‹åº”ç”¨åœºæ™¯æ›´å¹¿æ³›ã€‚
- è®­ç»ƒæ•°æ®ï¼šæ„å»ºäº† 1.4 ä¸‡äº¿ token çš„é«˜è´¨é‡ã€å¤šæ ·åŒ–çš„æ•°æ®å¯¹æ¨¡å‹è¿›è¡Œå……åˆ†è®­ç»ƒï¼ŒåŒ…å«ä¸­ã€è‹±ã€ä¿„ã€è¥¿ç­‰ 40 å¤šç§è¯­è¨€ï¼Œé€šè¿‡ç²¾ç»†åŒ–è®¾ç½®ä¸åŒç±»å‹æ•°æ®çš„é‡‡æ ·æ¯”ä¾‹ï¼Œä½¿å¾—ä¸­è‹±ä¸¤ç§è¯­è¨€è¡¨ç°ä¼˜å¼‚ï¼Œä¹Ÿèƒ½å…¼é¡¾å…¶ä»–è¯­è¨€æ•ˆæœã€‚
- åˆ†è¯ï¼šåŸºäº BPEï¼ˆByte-Pair Encodingï¼‰ç®—æ³•ï¼Œä½¿ç”¨ä¸Šç™¾ GB è¯­æ–™è®­ç»ƒäº†ä¸€ä¸ªè¯è¡¨å¤§å°ä¸º 100,278 çš„åˆ†è¯å™¨ï¼Œèƒ½å¤ŸåŒæ—¶æ”¯æŒå¤šè¯­è¨€ï¼Œè€Œæ— éœ€é¢å¤–æ‰©å±•è¯è¡¨ã€‚
- è®­ç»ƒæ¡†æ¶ï¼šè‡ªä¸»ç ”å‘å¤šé¡¹å…³é”®æŠ€æœ¯ï¼ŒåŒ…æ‹¬é«˜æ•ˆç®—å­ã€æ˜¾å­˜ä¼˜åŒ–ã€å¹¶è¡Œè°ƒåº¦ç­–ç•¥ã€æ•°æ®-è®¡ç®—-é€šä¿¡é‡å ã€å¹³å°å’Œæ¡†æ¶ååŒç­‰ï¼Œè®©è®­ç»ƒæ•ˆç‡æ›´é«˜ï¼Œæ¨¡å‹ç¨³å®šæ€§å¼ºï¼Œåœ¨åƒå¡é›†ç¾¤ä¸Šçš„å³°å€¼ç®—åŠ›åˆ©ç”¨ç‡å¯è¾¾åˆ° 58.5%ï¼Œä½å±…ä¸šç•Œå‰åˆ—ã€‚

### YuLan-Chat & YuLan-Chat-2
- https://github.com/RUC-GSAI/YuLan-Chat
- https://huggingface.co/yulan-team
- https://mp.weixin.qq.com/s/nPS4N3stAAG_51fnZANbMA

**YuLan-Chat**
ä¸­å›½äººæ°‘å¤§å­¦é«˜ç“´äººå·¥æ™ºèƒ½å­¦é™¢ç›¸å…³ç ”ç©¶å›¢é˜Ÿï¼ˆç”±å¤šä½å­¦é™¢è€å¸ˆè”åˆæŒ‡å¯¼ï¼‰å±•å¼€äº†ä¸€ç³»åˆ—å…³äºæŒ‡ä»¤å¾®è°ƒæŠ€æœ¯çš„ç ”ç©¶ï¼Œå¹¶å‘å¸ƒäº†å­¦é™¢åˆç‰ˆå¤§è¯­è¨€å¯¹è¯æ¨¡å‹â€”â€”YuLan-Chatï¼Œæ—¨åœ¨æ¢ç´¢å’Œæå‡å¤§è¯­è¨€æ¨¡å‹çš„ä¸­è‹±æ–‡åŒè¯­å¯¹è¯èƒ½åŠ›ã€‚

æˆ‘ä»¬åˆ†åˆ«å¼€æºäº†13Bå’Œ65Bçš„YuLan-Chatæ¨¡å‹æ–‡ä»¶åŠç›¸å…³ä»£ç ï¼Œå¹¶é‡‡ç”¨é‡åŒ–æŠ€æœ¯ä½¿å…¶åˆ†åˆ«å¯ä»¥åœ¨å•å¼ RTX3090-24Gå’ŒA800-80Gæ˜¾å¡ä¸Šéƒ¨ç½²ã€‚YuLan-Chatæ¨¡å‹åŸºäºLLaMAåº•åº§æ¨¡å‹ï¼Œé‡‡ç”¨ç²¾å¿ƒä¼˜åŒ–çš„é«˜è´¨é‡ä¸­è‹±æ–‡æ··åˆæŒ‡ä»¤è¿›è¡Œå¾®è°ƒï¼Œå…¶ä¸­YuLan-Chat-65Bæ¨¡å‹ç›®å‰èƒ½å¤Ÿåœ¨ä¸­è‹±æ–‡ç›¸å…³è¯„æµ‹æ•°æ®é›†ä¸Šæ˜¾è‘—è¶…è¶Šå·²æœ‰å¼€æºæ¨¡å‹æ•ˆæœã€‚åç»­æˆ‘ä»¬ä¼šç»§ç»­ä¼˜åŒ–æŒ‡ä»¤å¾®è°ƒæ–¹æ³•ä¸åº•åº§æ¨¡å‹ï¼ŒæŒç»­æ›´æ–°YuLan-Chatæ¨¡å‹ã€‚

**YuLan-Chat-2**
åœ¨2023å¹´6æœˆå‘å¸ƒYuLan-Chatç¬¬ä¸€ç‰ˆæ¨¡å‹åï¼Œé«˜ç“´äººå·¥æ™ºèƒ½å­¦é™¢ç ”ç©¶å›¢é˜Ÿç»§ç»­æ¢ç´¢å¤§è¯­è¨€æ¨¡å‹é¢„è®­ç»ƒä¸æŒ‡ä»¤å¾®è°ƒç­‰æŠ€æœ¯ï¼Œå¹¶åœ¨LLaMA-2çš„åŸºç¡€ä¸Šè®­ç»ƒå¾—åˆ°äº†æ–°ç‰ˆåŸºçŸ³æ¨¡å‹YuLan-LLaMA-2-13Bå’Œå¯¹è¯æ¨¡å‹YuLan-Chat-2-13Bã€‚è¿™äº›æ¨¡å‹åœ¨åŸç‰ˆLLaMA-2çš„åŸºç¡€ä¸Šæ‰©å……ä¸­æ–‡è¯è¡¨ä¸ä¸Šä¸‹æ–‡é•¿åº¦ï¼ˆè¾¾åˆ°8kï¼‰ï¼Œä½¿ç”¨äº†å¤§è§„æ¨¡ä¸­è‹±æ–‡æ•°æ®è¿›è¡Œå¢é‡é¢„è®­ç»ƒå’ŒæŒ‡ä»¤å¾®è°ƒï¼ŒåŒæ—¶æå‡äº†æ¨¡å‹çš„ä¸­è‹±æ–‡åŸºç¡€è¯­ä¹‰å’Œç†è§£èƒ½åŠ›ï¼Œç›¸æ¯”å‰ä¸€ä»£æ¨¡å‹æ•ˆæœè·å¾—äº†æ˜¾è‘—æå‡ï¼Œä¸åŒæœŸå…¶ä»–åŸºäºLLaMA-2å¾—åˆ°çš„æ¨¡å‹ç›¸æ¯”ï¼Œä¹Ÿå…·æœ‰æ˜¾è‘—æ€§èƒ½ä¼˜åŠ¿ã€‚ç»è¿‡é‡åŒ–ï¼Œæ¨¡å‹å¯ä»¥åœ¨å•å¼ RTX-3090 24Gæ˜¾å¡ä¸­éƒ¨ç½²ã€‚

### Ziya-LLaMA
- https://huggingface.co/IDEA-CCNL/Ziya-LLaMA-13B-v1
- https://github.com/IDEA-CCNL/Fengshenbang-LM
- https://mp.weixin.qq.com/s/IeXgq8blGoeVbpIlAUCAjA

å§œå­ç‰™é€šç”¨å¤§æ¨¡å‹V1æ˜¯åŸºäºLLaMaçš„130äº¿å‚æ•°çš„å¤§è§„æ¨¡é¢„è®­ç»ƒæ¨¡å‹ï¼Œå…·å¤‡ç¿»è¯‘ï¼Œç¼–ç¨‹ï¼Œæ–‡æœ¬åˆ†ç±»ï¼Œä¿¡æ¯æŠ½å–ï¼Œæ‘˜è¦ï¼Œæ–‡æ¡ˆç”Ÿæˆï¼Œå¸¸è¯†é—®ç­”å’Œæ•°å­¦è®¡ç®—ç­‰èƒ½åŠ›ã€‚ç›®å‰å§œå­ç‰™é€šç”¨å¤§æ¨¡å‹å·²å®Œæˆå¤§è§„æ¨¡é¢„è®­ç»ƒã€å¤šä»»åŠ¡æœ‰ç›‘ç£å¾®è°ƒå’Œäººç±»åé¦ˆå­¦ä¹ ä¸‰é˜¶æ®µçš„è®­ç»ƒè¿‡ç¨‹ã€‚

The Ziya-LLaMA-13B-v1 is a large-scale pre-trained model based on LLaMA with 13 billion parameters. It has the ability to perform tasks such as translation, programming, text classification, information extraction, summarization, copywriting, common sense Q&A, and mathematical calculation. The Ziya-LLaMA-13B-v1 has undergone three stages of training: large-scale continual pre-training (PT), multi-task supervised fine-tuning (SFT), and human feedback learning (RM, PPO).

### FLM-101B
- https://arxiv.org/pdf/2309.03852.pdf
- https://huggingface.co/CofeAI/FLM-101B

FLM-101B is an open-source decoder-only LLM with 101 billion parameters. During the training process, model growth technique was employed. The model rapidly acquires knowledge on a small-scale model(16B) in the early stages of training and gradually scales up to 101B, resulting in a cost-effective 100B-scale LLM training(costing approximately $100,000). FLM-101B supports both Chinese and English languages. It has a context window length of 2048 in training. Thanks to the use of xPos rotary position embedding, it allows for efficient expansion of the window size during inference.

To advance the development of 100B-scale Large Language Models (LLMs), FLM-101B has now been fully open-sourced.

### MindChat(æ¼«è°ˆ): å¿ƒç†å¤§æ¨¡å‹
- https://github.com/X-D-Lab/MindChat

å¿ƒç†å¤§æ¨¡å‹â€”â€”æ¼«è°ˆ(MindChat)æœŸæœ›ä»å¿ƒç†å’¨è¯¢ã€å¿ƒç†è¯„ä¼°ã€å¿ƒç†è¯Šæ–­ã€å¿ƒç†æ²»ç–—å››ä¸ªç»´åº¦å¸®åŠ©äººä»¬çº¾è§£å¿ƒç†å‹åŠ›ä¸è§£å†³å¿ƒç†å›°æƒ‘, æé«˜å¿ƒç†å¥åº·æ°´å¹³. ä½œä¸ºä¸€ä¸ªå¿ƒç†å¤§æ¨¡å‹, MindChaté€šè¿‡è¥é€ è½»æ¾ã€å¼€æ”¾çš„äº¤è°ˆç¯å¢ƒ, ä»¥æ”¾æ¾èº«å¿ƒã€äº¤æµæ„Ÿå—æˆ–åˆ†äº«ç»éªŒçš„æ–¹å¼, ä¸ç”¨æˆ·å»ºç«‹ä¿¡ä»»å’Œç†è§£çš„å…³ç³». MindChatå¸Œæœ›ä¸ºç”¨æˆ·æä¾›éšç§ã€æ¸©æš–ã€å®‰å…¨ã€åŠæ—¶ã€æ–¹ä¾¿çš„å¯¹è¯ç¯å¢ƒ, ä»è€Œå¸®åŠ©ç”¨æˆ·å…‹æœå„ç§å›°éš¾å’ŒæŒ‘æˆ˜, å®ç°è‡ªæˆ‘æˆé•¿å’Œå‘å±•.

æ— è®ºæ˜¯åœ¨å·¥ä½œåœºæ™¯è¿˜æ˜¯åœ¨ä¸ªäººç”Ÿæ´»ä¸­, MindChatæœŸæœ›é€šè¿‡å¿ƒç†å­¦ä¸“ä¸šçŸ¥è¯†å’Œäººå·¥æ™ºèƒ½å¤§æ¨¡å‹æŠ€æœ¯, åœ¨ä¸¥æ ¼ä¿æŠ¤ç”¨æˆ·éšç§çš„å‰æä¸‹, å…¨æ—¶æ®µå…¨å¤©å€™ä¸ºç”¨æˆ·æä¾›å…¨é¢çš„å¿ƒç†æ”¯æŒå’Œè¯Šç–—å¸®åŠ©, åŒæ—¶å®ç°è‡ªæˆ‘æˆé•¿å’Œå‘å±•, ä»¥æœŸä¸ºå»ºè®¾ä¸€ä¸ªæ›´åŠ å¥åº·ã€åŒ…å®¹å’Œå¹³ç­‰çš„ç¤¾ä¼šè´¡çŒ®åŠ›é‡ã€‚

### WiNGPT
- https://github.com/winninghealth/WiNGPT2

WiNGPTæ˜¯ä¸€ä¸ªåŸºäºGPTçš„åŒ»ç–—å‚ç›´é¢†åŸŸå¤§æ¨¡å‹ï¼Œæ—¨åœ¨å°†ä¸“ä¸šçš„åŒ»å­¦çŸ¥è¯†ã€åŒ»ç–—ä¿¡æ¯ã€æ•°æ®èä¼šè´¯é€šï¼Œä¸ºåŒ»ç–—è¡Œä¸šæä¾›æ™ºèƒ½åŒ–çš„åŒ»ç–—é—®ç­”ã€è¯Šæ–­æ”¯æŒå’ŒåŒ»å­¦çŸ¥è¯†ç­‰ä¿¡æ¯æœåŠ¡ï¼Œæé«˜è¯Šç–—æ•ˆç‡å’ŒåŒ»ç–—æœåŠ¡è´¨é‡ã€‚

### CareGPT
- https://github.com/WangRongsheng/CareGPT

CareGPT (å…³æ€€GPT)æ˜¯ä¸€ä¸ªåŒ»ç–—å¤§è¯­è¨€æ¨¡å‹ï¼ŒåŒæ—¶å®ƒé›†åˆäº†æ•°åä¸ªå…¬å¼€å¯ç”¨çš„åŒ»ç–—å¾®è°ƒæ•°æ®é›†å’Œå¼€æ”¾å¯ç”¨çš„åŒ»ç–—å¤§è¯­è¨€æ¨¡å‹ï¼ŒåŒ…å«LLMçš„è®­ç»ƒã€æµ‹è¯„ã€éƒ¨ç½²ç­‰ä»¥ä¿ƒè¿›åŒ»ç–—LLMå¿«é€Ÿå‘å±•ã€‚

### å­™æ€é‚ˆ
- https://github.com/thomas-yanxin/Sunsimiao

å­™æ€é‚ˆä¸­æ–‡åŒ»ç–—å¤§æ¨¡å‹(ç®€ç§°: Sunsimiao)å¸Œæœ›èƒ½å¤Ÿéµå¾ªå­™æ€é‚ˆçš„ç”Ÿå¹³è½¨è¿¹, é‡è§†æ°‘é—´åŒ»ç–—ç»éªŒ, ä¸æ–­ç´¯ç§¯ä¸­æ–‡åŒ»ç–—æ•°æ®, å¹¶å°†æ•°æ®é™„åŠ ç»™æ¨¡å‹, è‡´åŠ›äºæä¾›å®‰å…¨ã€å¯é ã€æ™®æƒ çš„ä¸­æ–‡åŒ»ç–—å¤§æ¨¡å‹.

ç›®å‰, Sunsimiaoæ˜¯ç”±baichuan-7Bå’ŒChatGLM-6Bç³»åˆ—åœ¨åä¸‡çº§é«˜è´¨é‡çš„ä¸­æ–‡åŒ»ç–—æ•°æ®ä¸­å¾®è°ƒè€Œå¾—, åç»­å°†æ”¶é›†æ›´å¤šæ•°æ®, æ‰©å……æ¨¡å‹èƒ½åŠ›, ä¸æ–­è¿­ä»£æ›´æ–°. ç›¸å…³ç»†èŠ‚å·¥ä½œæ­£åœ¨æ•´ç†, æ•¬è¯·æœŸå¾….

### MolGenï¼ˆè¯ç‰©ç ”å‘ï¼‰
- https://github.com/zjunlp/Mol-Instructions

Mol-Instructions comprises three cardinal components:

ğŸ”¬ Molecule-oriented instructions: This component delves into the world of small molecules, emphasizing their inherent properties and behaviors. It sheds light on the fundamental challenges of diverse chemical reactions and molecular design, with 148,4K instructions across six tasks.

ğŸ§¬ Protein-oriented instructions: Rooted in the biosciences, this component presents 505K instructions across five distinct categories of tasks. These tasks aim to predict the structure, function, and activity of proteins, and facilitate protein design based on textual directives.

ğŸ¥¼ Biomolecular text instructions: Predominantly designed to cater to NLP tasks within the fields of bioinformatics and chemoinformatics, this part encapsulates six information extraction and Q&A tasks represented through 53K instructions.

### Multilingual Medicine
- https://github.com/FreedomIntelligence/Apollo/tree/main

Despite the vast repository of global medical knowledge predominantly being in English, local languages are crucial for delivering tailored healthcare services, particularly in areas with limited medical resources. To extend the reach of medical AI advancements to a broader population, we aim to develop medical LLMs across the six most widely spoken languages, encompassing a global population of 6.1 billion. This effort culminates in the creation of the ApolloCorpora multilingual medical dataset and the XMedBench benchmark. In the multilingual medical benchmark, the released Apollo models, at various relatively-small sizes (i.e., 0.5B, 1.8B, 2B, 6B, and 7B), achieve the best performance among models of equivalent size. Especially, Apollo-7B is the state-of-the-art multilingual medical LLMs up to 70B. Additionally, these lite models could be used to improve the multi-lingual medical capabilities of larger models without fine-tuning in a proxy-tuning fashion. We will open-source training corpora, code, model weights and evaluation benchmark.

### Taiyiï¼ˆå¤ªä¸€ï¼‰
- https://github.com/DUTIR-BioNLP/Taiyi-LLM
- https://arxiv.org/abs/2311.11608

éšç€æ·±åº¦å­¦ä¹ æŠ€æœ¯çš„è¿…é€Ÿå‘å±•ï¼Œç±»ChatGPTè¿™æ ·çš„å¤§è¯­è¨€æ¨¡å‹åœ¨è‡ªç„¶è¯­è¨€å¤„ç†é¢†åŸŸå·²ç»å–å¾—äº†æ˜¾è‘—çš„è¿›å±•ã€‚é¢å‘ç”Ÿç‰©åŒ»å­¦é¢†åŸŸï¼Œå¤§è¯­è¨€æ¨¡å‹æœ‰åŠ©äºåŒ»ç”Ÿä¸æ‚£è€…ä¹‹é—´çš„æ²Ÿé€šï¼Œæä¾›æœ‰ç”¨çš„åŒ»å­¦ä¿¡æ¯ï¼Œå¹¶åœ¨è¾…åŠ©è¯Šç–—ã€ç”Ÿç‰©åŒ»å­¦çŸ¥è¯†å‘ç°ã€è¯ç‰©ç ”å‘ã€ä¸ªæ€§åŒ–åŒ»ç–—æ–¹æ¡ˆç­‰æ–¹é¢å…·æœ‰å·¨å¤§æ½œåŠ›ã€‚ç„¶è€Œï¼Œåœ¨äººå·¥æ™ºèƒ½ç¤¾åŒºä¸­ï¼Œå·²æœ‰çš„å¼€æºç”Ÿç‰©åŒ»å­¦å¤§æ¨¡å‹ç›¸å¯¹è¾ƒå°‘ï¼Œä¸”å¤§å¤šä¸»è¦ä¸“æ³¨äºå•è¯­ï¼ˆä¸­æ–‡æˆ–è‹±è¯­ï¼‰çš„åŒ»ç–—é—®ç­”å¯¹è¯ã€‚å› æ­¤ï¼Œæœ¬é¡¹ç›®å¼€å±•äº†é¢å‘ç”Ÿç‰©åŒ»å­¦é¢†åŸŸå¤§æ¨¡å‹çš„ç ”ç©¶ï¼Œå¹¶å‘å¸ƒåˆç‰ˆä¸­è‹±åŒè¯­ç”Ÿç‰©åŒ»å­¦å¤§æ¨¡å‹â€”â€”å¤ªä¸€ï¼ˆTaiyiï¼‰ï¼Œæ—¨åœ¨æ¢ç´¢å¤§æ¨¡å‹åœ¨ç”Ÿç‰©åŒ»å­¦é¢†åŸŸä¸­åŒè¯­è‡ªç„¶è¯­è¨€å¤„ç†å¤šä»»åŠ¡çš„èƒ½åŠ›ã€‚

### MedAgents
- https://github.com/gersteinlab/MedAgents
- https://arxiv.org/pdf/2311.10537.pdf

We propose a Multi-disciplinary Collaboration (MC) framework. The framework works in five stages: (i) expert gathering: gather experts from distinct disciplines according to the clinical question; (ii) analysis proposition: domain experts put forward their own analysis with their expertise; (iii) report summarization: compose a summarized report on the basis of a previous series of analyses; (iv) collaborative consultation: engage the experts in discussions over the summarized report. The report will be revised iteratively until an agreement from all the experts is reached; (v) decision making: derive a final decision from the unanimous report.

### Molecule Optimization
- https://github.com/blazerye/DrugAssist
- https://arxiv.org/abs/2401.10334

Recently, the impressive performance of large language models (LLMs) on a wide range of tasks has attracted an increasing number of attempts to apply LLMs in drug discovery. However, molecule optimization, a critical task in the drug discovery pipeline, is currently an area that has seen little involvement from LLMs. Most of existing approaches focus solely on capturing the underlying patterns in chemical structures provided by the data, without taking advantage of expert feedback. These non-interactive approaches overlook the fact that the drug discovery process is actually one that requires the integration of expert experience and iterative refinement. To address this gap, we propose DrugAssist, an interactive molecule optimization model which performs optimization through human-machine dialogue by leveraging LLM's strong interactivity and generalizability. DrugAssist has achieved leading results in both single and multiple property optimization, simultaneously showcasing immense potential in transferability and iterative optimization. In addition, we publicly release a large instruction-based dataset called MolOpt-Instructions for fine-tuning language models on molecule optimization tasks. 

### MolTC
- https://github.com/MangoKiller/MolTC
- https://arxiv.org/abs/2402.03781

Molecular Relational Learning (MRL), aiming to understand interactions between molecular pairs, plays a pivotal role in advancing biochemical research. Recently, the adoption of large language models (LLMs), known for their vast knowledge repositories and advanced logical inference capabilities, has emerged as a promising way for efficient and effective MRL. Despite their potential, these methods predominantly rely on the textual data, thus not fully harnessing the wealth of structural information inherent in molecular graphs. Moreover, the absence of a unified framework exacerbates the issue of information underutilization, as it hinders the sharing of interaction mechanism learned across diverse datasets. To address these challenges, this work proposes a novel LLM-based multi-modal framework for Molecular inTeraction prediction following Chain-of-Thought (CoT) theory, termed MolTC, which effectively integrate graphical information of two molecules in pair. For achieving a unified MRL, MolTC innovatively develops a dynamic parameter-sharing strategy for cross-dataset information sharing. Moreover, to train MolTC efficiently, we introduce a Multi-hierarchical CoT concept to refine its training paradigm, and conduct a comprehensive Molecular Interactive Instructions dataset for the development of biochemical LLMs involving MRL. Our experiments, conducted across various datasets involving over 4,000,000 molecular pairs, exhibit the superiority of our method over current GNN and LLM-based baselines.

### Mol-Instructions
- https://arxiv.org/pdf/2306.08018.pdf
- https://github.com/zjunlp/Mol-Instructions

Large Language Models (LLMs), with their remarkable task-handling capabilities and innovative outputs, have catalyzed significant advancements across a spectrum of fields. However, their proficiency within specialized domains such as biomolecular studies remains limited. To address this challenge, we introduce Mol-Instructions, a comprehensive instruction dataset designed for the biomolecular domain. Mol-Instructions encompasses three key components: molecule-oriented instructions, protein-oriented instructions, and biomolecular text instructions. Each component aims to improve the understanding and prediction capabilities of LLMs concerning biomolecular features and behaviors. Through extensive instruction tuning experiments on LLMs, we demonstrate the effectiveness of Mol-Instructions in enhancing large models' performance in the intricate realm of biomolecular studies, thus fostering progress in the biomolecular research community. Mol-Instructions is publicly available for ongoing research and will undergo regular updates to enhance its applicability.

### TinyLlama
- https://github.com/jzhang38/TinyLlama

TinyLlamaé¡¹ç›®æ—¨åœ¨åœ¨3ä¸‡äº¿tokensä¸Šè¿›è¡Œé¢„è®­ç»ƒï¼Œæ„å»ºä¸€ä¸ªæ‹¥æœ‰11äº¿å‚æ•°çš„Llamaæ¨¡å‹ã€‚ç»è¿‡ç²¾å¿ƒä¼˜åŒ–ï¼Œæˆ‘ä»¬"ä»…"éœ€16å—A100-40Gçš„GPUï¼Œä¾¿å¯åœ¨90å¤©å†…å®Œæˆè¿™ä¸ªä»»åŠ¡ğŸš€ğŸš€ã€‚è®­ç»ƒå·²äº2023-09-01å¼€å§‹ã€‚

æˆ‘ä»¬é‡‡ç”¨äº†ä¸Llama 2å®Œå…¨ç›¸åŒçš„æ¶æ„å’Œåˆ†è¯å™¨ã€‚è¿™æ„å‘³ç€TinyLlamaå¯ä»¥åœ¨è®¸å¤šåŸºäºLlamaçš„å¼€æºé¡¹ç›®ä¸­å³æ’å³ç”¨ã€‚æ­¤å¤–ï¼ŒTinyLlamaåªæœ‰1.1Bçš„å‚æ•°ï¼Œä½“ç§¯å°å·§ï¼Œé€‚ç”¨äºéœ€è¦é™åˆ¶è®¡ç®—å’Œå†…å­˜å ç”¨çš„å¤šç§åº”ç”¨ã€‚

### Nous-Hermes-2 Mixtral 8x7B
- https://huggingface.co/NousResearch/Nous-Hermes-2-Mixtral-8x7B-SFT
- https://huggingface.co/NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO
- https://huggingface.co/NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO-adapter

Nous Hermes 2 Mixtral 8x7B SFT is the supervised finetune only version of our new flagship Nous Research model trained over the Mixtral 8x7B MoE LLM.

Nous Hermes 2 Mixtral 8x7B DPO is the new flagship Nous Research model trained over the Mixtral 8x7B MoE LLM.

QLoRA Adapter for the DPO Phase of Nous-Hermes-2 Mixtral 8x7B Model.

### AlphaGeometry
- https://www.nature.com/articles/s41586-023-06747-5
- https://github.com/google-deepmind/alphageometry

Proving mathematical theorems at the olympiad level represents a notable milestone in human-level automated reasoning, owing to their reputed difficulty among the worldâ€™s best talents in pre-university mathematics. Current machine-learning approaches, however, are not applicable to most mathematical domains owing to the high cost of translating human proofs into machine-verifiable format. The problem is even worse for geometry because of its unique translation challenges1,5, resulting in severe scarcity of training data. We propose AlphaGeometry, a theorem prover for Euclidean plane geometry that sidesteps the need for human demonstrations by synthesizing millions of theorems and proofs across different levels of complexity. AlphaGeometry is a neuro-symbolic system that uses a neural language model, trained from scratch on our large-scale synthetic data, to guide a symbolic deduction engine through infinite branching points in challenging problems. On a test set of 30 latest olympiad-level problems, AlphaGeometry solves 25, outperforming the previous best method that only solves ten problems and approaching the performance of an average International Mathematical Olympiad (IMO) gold medallist. Notably, AlphaGeometry produces human-readable proofs, solves all geometry problems in the IMO 2000 and 2015 under human expert evaluation and discovers a generalized version of a translated IMO theorem in 2004.

### MoE-Mamba
- https://arxiv.org/abs/2401.04081

State Space Models (SSMs) have become serious contenders in the field of sequential modeling, challenging the dominance of Transformers. At the same time, Mixture of Experts (MoE) has significantly improved Transformer-based LLMs, including recent state-of-the-art open-source models. We propose that to unlock the potential of SSMs for scaling, they should be combined with MoE. We showcase this on Mamba, a recent SSM-based model that achieves remarkable, Transformer-like performance. Our model, MoE-Mamba, outperforms both Mamba and Transformer-MoE. In particular, MoE-Mamba reaches the same performance as Mamba in 2.2x less training steps while preserving the inference performance gains of Mamba against the Transformer.

### StarCoder
- https://huggingface.co/bigcode/starcoder
- https://github.com/bigcode-project/starcoder/tree/main
- https://arxiv.org/abs/2305.06161

The BigCode community, an open-scientific collaboration working on the responsible development of Large Language Models for Code (Code LLMs), introduces StarCoder and StarCoderBase: 15.5B parameter models with 8K context length, infilling capabilities and fast large-batch inference enabled by multi-query attention. StarCoderBase is trained on 1 trillion tokens sourced from The Stack, a large collection of permissively licensed GitHub repositories with inspection tools and an opt-out process. We fine-tuned StarCoderBase on 35B Python tokens, resulting in the creation of StarCoder. We perform the most comprehensive evaluation of Code LLMs to date and show that StarCoderBase outperforms every open Code LLM that supports multiple programming languages and matches or outperforms the OpenAI code-cushman-001 model. Furthermore, StarCoder outperforms every model that is fine-tuned on Python, can be prompted to achieve 40\% pass@1 on HumanEval, and still retains its performance on other programming languages. We take several important steps towards a safe open-access model release, including an improved PII redaction pipeline and a novel attribution tracing tool, and make the StarCoder models publicly available under a more commercially viable version of the Open Responsible AI Model license.

### OLMo
- https://allenai.org/olmo/olmo-paper.pdf
- https://huggingface.co/allenai/OLMo-7B
- https://github.com/allenai/OLMo
- https://github.com/allenai/OLMo-Eval
- https://github.com/allenai/open-instruct

OLMo is a repository for training and using AI2's state-of-the-art open language models. It is built by scientists, for scientists.

### H2O-Danube-1.8B
- https://arxiv.org/abs/2401.16818

We present H2O-Danube-1.8B, a 1.8B language model trained on 1T tokens following the core principles of LLama 2 and Mistral. We leverage and refine various techniques for pre-training large language models. Although our model is trained on significantly fewer total tokens compared to reference models of similar size, it exhibits highly competitive metrics across a multitude of benchmarks. We additionally release a chat model trained with supervised fine-tuning followed by direct preference optimization. We make H2O-Danube-1.8B openly available under Apache 2.0 license further democratizing LLMs to a wider audience economically.

### OpenMathInstruct-1
- https://arxiv.org/abs/2402.10176
- https://huggingface.co/collections/nvidia/openmath-65c5619de2ba059be0775014

Recent work has shown the immense potential of synthetically generated datasets for training large language models (LLMs), especially for acquiring targeted skills. Current large-scale math instruction tuning datasets such as MetaMathQA (Yu et al., 2024) and MAmmoTH (Yue et al., 2024) are constructed using outputs from closed-source LLMs with commercially restrictive licenses. A key reason limiting the use of open-source LLMs in these data generation pipelines has been the wide gap between the mathematical skills of the best closed-source LLMs, such as GPT-4, and the best open-source LLMs. Building on the recent progress in open-source LLMs, our proposed prompting novelty, and some brute-force scaling, we construct OpenMathInstruct-1, a math instruction tuning dataset with 1.8M problem-solution pairs. The dataset is constructed by synthesizing code-interpreter solutions for GSM8K and MATH, two popular math reasoning benchmarks, using the recently released and permissively licensed Mixtral model. Our best model, OpenMath-CodeLlama-70B, trained on a subset of OpenMathInstruct-1, achieves a score of 84.6% on GSM8K and 50.7% on MATH, which is competitive with the best gpt-distilled models. We release our code, models, and the OpenMathInstruct-1 dataset under a commercially permissive license.

### Smaug-72B
- https://huggingface.co/abacusai/Smaug-72B-v0.1

We recently released Smaug-72B-v0.1 which has taken first place on the Open LLM Leaderboard by HuggingFace. It is the first open-source model to have an average score more than 80.

Smaug-72B is finetuned directly from moreh/MoMo-72B-lora-1.8.7-DPO and is ultimately based on Qwen-72B.

### Gemma
- https://ai.google.dev/gemma/

A family of lightweight, state-of-the art open models built from the same research and technology used to create the Gemini models.

### Aya Model
- https://arxiv.org/abs/2402.07827
- https://hf.co/CohereForAI/aya-101

Recent breakthroughs in large language models (LLMs) have centered around a handful of data-rich languages. What does it take to broaden access to breakthroughs beyond first-class citizen languages? Our work introduces Aya, a massively multilingual generative language model that follows instructions in 101 languages of which over 50% are considered as lower-resourced. Aya outperforms mT0 and BLOOMZ on the majority of tasks while covering double the number of languages. We introduce extensive new evaluation suites that broaden the state-of-art for multilingual eval across 99 languages -- including discriminative and generative tasks, human evaluation, and simulated win rates that cover both held-out tasks and in-distribution performance. Furthermore, we conduct detailed investigations on the optimal finetuning mixture composition, data pruning, as well as the toxicity, bias, and safety of our models.

### MobiLlama
- https://github.com/mbzuai-oryx/MobiLlama
- https://arxiv.org/abs/2402.16840

"Bigger the better" has been the predominant trend in recent Large Language Models (LLMs) development. However, LLMs do not suit well for scenarios that require on-device processing, energy efficiency, low memory footprint, and response efficiency. These requisites are crucial for privacy, security, and sustainable deployment. This paper explores the "less is more" paradigm by addressing the challenge of designing accurate yet efficient Small Language Models (SLMs) for resource constrained devices. Our primary contribution is the introduction of an accurate and fully transparent open-source 0.5 billion (0.5B) parameter SLM, named MobiLlama, catering to the specific needs of resource-constrained computing with an emphasis on enhanced performance with reduced resource demands. MobiLlama is a SLM design that initiates from a larger model and applies a careful parameter sharing scheme to reduce both the pre-training and the deployment cost.

### StarCoder2
- https://huggingface.co/blog/starcoder2

StarCoder2 is a family of open LLMs for code and comes in 3 different sizes with 3B, 7B and 15B parameters. The flagship StarCoder2-15B model is trained on over 4 trillion tokens and 600+ programming languages from The Stack v2. All models use Grouped Query Attention, a context window of 16,384 tokens with a sliding window attention of 4,096 tokens, and were trained using the Fill-in-the-Middle objective.

### SmallLanguageModel-project
- https://github.com/shivendrra/SmallLanguageModel-project

This repository contains all the necessary items needed to build your own LLM from scratch. Just follow the instructions. Inspired from Karpathy's nanoGPT and Shakespeare generator, I made this repository to build my own LLM. It has everything from data collection for the Model to architecture file, tokenizer and train file.

### Command-R
- https://txt.cohere.com/command-r/
- https://huggingface.co/CohereForAI/c4ai-command-r-v01

Command-R is a generative model optimized for long context tasks such as retrieval augmented generation (RAG) and using external APIs and tools. It is designed to work in concert with our industry-leading Embed and Rerank models to provide best-in-class integration for RAG applications and excel at enterprise use cases. As a model built for companies to implement at scale, Command-R boasts: 
- Strong accuracy on RAG and Tool Use
- Low latency, and high throughput
- Longer 128k context and lower pricing
- Strong capabilities across 10 key languages
- Model weights available on HuggingFace for research and evaluation

### Colossal-LLaMA-2
- https://github.com/hpcaitech/ColossalAI/tree/main/applications/Colossal-LLaMA-2

The Colossal-AI team has introduced the open-source model Colossal-LLaMA-2-7B-base. This model, a derivation of LLaMA-2, has undergone continual pre-training involving approximately 8.5 billion tokens over a duration of 15 hours with 64 A800 GPUs. At a cost of less than $1,000, you can achieve results similar to those that cost millions of dollars to pretrain from scratch. It is licensed under the LLaMA-2 license and Apache 2.0 License without any additional commercial use restrictions. This solution can also be used to build models of specific domain knowledge or tasks.

Colossal-LLaMA-2-7B-base is designed to accommodate both the Chinese and English languages, featuring an expansive context window spanning 4096 tokens. Remarkably, it has exhibited exceptional performance when benchmarked against models of equivalent scale in standard Chinese and English evaluation metrics, including C-Eval and MMLU, among others.

### OpenBA (Encoder-Decoder)
- https://github.com/OpenNLG/OpenBA

We are excited to unveil two distinguished versions of our model, with another on the horizon:

- OpenBA-LM: The backbone language models was pre-trained on 340B English, Chinese, and code tokens.
- OpenBA-Flan: We continually perform supervised fine-tuning with 40B tokens of constructed BiFlan Dataset.
- OpenBA-Chat: We will release the Chat model soon

### å°”é›… Erya
- https://huggingface.co/RUCAIBox/Erya
- https://github.com/RUCAIBox/Erya

ç¿»è¯‘ã€ç†è§£å¤æ±‰è¯­å¯¹äºé€šä¼šä¸Šä¸‹äº”åƒå¹´çš„ä¸­åå…¸ç±ä¸æ–‡æ˜è‡³å…³é‡è¦ã€‚ä¸ºäº†å®ç°é«˜æ•ˆçš„å¤æ±‰è¯­ç¿»è¯‘ï¼Œæˆ‘ä»¬åœ¨æ­¤æå‡ºå·¥å…·é›†â€œå°”é›…â€ï¼Œå®ƒåŒ…å«ï¼šï¼ˆ1ï¼‰ä¸€ä¸ªç»è¿‡æ¸…æ´—ä¸åˆ†ç±»çš„ï¼Œæˆªè‡³ç›®å‰ä½“é‡æœ€å¤§çš„å¤æ±‰è¯­ç¿»è¯‘æ•°æ®é›†ã€‚ï¼ˆ2ï¼‰é¢å‘å¤æ±‰è¯­ç¿»è¯‘çš„è®­ç»ƒæ–¹æ³•ï¼Œå®ƒåŒ…å«åŒéŸ³èŠ‚å¯¹é½æ›¿æ¢æ³•(DAS)ä¸åŒå‘æ©ç è¯­è¨€æ¨¡å‹(DMLM)ï¼Œä»¥åŠåŸºäºæ­¤æ–¹æ³•è®­ç»ƒçš„æ¨¡å‹ã€‚ï¼ˆ3ï¼‰ä¸€ä¸ªè¦†ç›–å„æ±‰è¯­ä¸–ä»£ä¸æ–‡ä½“çš„å¤æ±‰è¯­ç¿»è¯‘æµ‹è¯•åŸºå‡†ã€‚â€œå°”é›…â€æ¨¡å‹çš„é›¶æ ·æœ¬èƒ½åŠ›è¶…å‡ºGPT-3.5ç³»åˆ—+12.0BLEUï¼Œå¹¶åœ¨äººå·¥è¯„åˆ†ä¸Šè¡¨ç°ä¼˜äºæ–‡å¿ƒä¸€è¨€ã€‚ç»§ç»­å¾®è°ƒåˆ™æ›´è¿›ä¸€æ­¥åœ°ä»¥+6.2BLEUæå‡äº†æ¨¡å‹è¡¨ç°ã€‚æ‰€æœ‰èµ„æºè¯·è§https://github.com/RUCAIBox/Erya

### è€å­
- https://github.com/Xunzi-LLM-of-Chinese-classics/XunziALLM

éšç€ç§‘æŠ€çš„é£é€Ÿå‘å±•ï¼Œäººå·¥æ™ºèƒ½å·²æ·±å…¥åˆ°å„ä¸ªé¢†åŸŸã€‚ä¸ºå“åº”å¤ç±æ´»åŒ–åˆ©ç”¨å·å¬ï¼Œæ¨åŠ¨å¤§è¯­è¨€æ¨¡å‹ä¸å¤ç±å¤„ç†æ·±åº¦èåˆï¼Œä»¥å¤ç±æ™ºèƒ½åŒ–çš„ç ”ç©¶ä¸ºç›®çš„ï¼Œå—äº¬å†œä¸šå¤§å­¦å›½å®¶ç¤¾ç§‘åŸºé‡‘é‡å¤§é¡¹ç›®â€œä¸­å›½å¤ä»£å…¸ç±è·¨è¯­è¨€çŸ¥è¯†åº“æ„å»ºåŠåº”ç”¨ç ”ç©¶â€è¯¾é¢˜ç»„ä¸ä¸­åä¹¦å±€å¤è”å…¬å¸æ¨å‡ºäº†ä¸€ç³»åˆ—å¤ç±å¤„ç†é¢†åŸŸå¤§è¯­è¨€æ¨¡å‹ï¼šè€å­å¤ç±å¤§è¯­è¨€æ¨¡å‹ã€‚è€å­ä¸ä»…æ˜¯æˆ‘å›½å…ˆç§¦æ—¶æœŸä¼Ÿå¤§çš„æœ´ç´ å”¯ç‰©ä¸»ä¹‰çš„æ€æƒ³å®¶ï¼Œä¹Ÿæ˜¯ä¸€ä½æ•£æ–‡å¤§å®¶ã€‚ä»–åœ¨è¯­è¨€å­¦ç†è®ºçš„é˜è¿°ä¸Šåˆæ˜¯ä¸€ä½å¼€æ‹“è€…ã€å¥ åŸºäººã€‚è€å­ç³»åˆ—ä¸“ä¸ºå¤ç±æ™ºèƒ½å¤„ç†è€Œè®¾è®¡ï¼Œè¿™ä¸€ç³»åˆ—æ¨¡å‹çš„æ¨å‡ºå°†æ¨åŠ¨å¤ç±ç ”ç©¶ä¸ä¿æŠ¤å·¥ä½œçš„æ–°å‘å±•ï¼Œæé«˜ä¸­åä¼ ç»Ÿæ–‡åŒ–ä¼ æ‰¿çš„æ•ˆç‡ä¸è´¨é‡ã€‚

æœ¬æ¬¡è€å­ç³»åˆ—æ¨¡å‹å¼€æºåŒ…æ‹¬ä¸¤ä¸ªéƒ¨åˆ†ï¼šåŸºåº§æ¨¡å‹XunziALLMï¼Œä½œä¸ºæœ¬æ¬¡æ¨¡å‹å¼€æºçš„é‡ç‚¹ï¼Œæœ¬é¡¹ç›®æ¨å‡ºäº†å®Œå…¨å¼€æ”¾ä½¿ç”¨çš„å¤ç±é¢†åŸŸå¤§æ¨¡å‹ï¼Œä¸æ­¤åŒæ—¶ï¼Œä¸ºæ–¹ä¾¿éäººå·¥æ™ºèƒ½é¢†åŸŸäººå‘˜æ›´å¥½åœ°äº†è§£æœ¬æ¬¡å¼€æºæ¨¡å‹ï¼Œæˆ‘ä»¬ä½¿ç”¨ä¸€éƒ¨åˆ†æ•°æ®æ„å»ºäº†å¯¹è¯æ¨¡å‹XunziChatï¼Œæ¨¡å‹çš„è°ƒç”¨æ–¹å¼ä¸é˜¿é‡Œäº‘çš„Qwenç³»åˆ—å¤§æ¨¡å‹ä¸€è‡´ã€‚

### CodeShell
- https://github.com/WisdomShell/codeshell

CodeShellæ˜¯åŒ—äº¬å¤§å­¦çŸ¥è¯†è®¡ç®—å®éªŒå®¤è”åˆå››å·å¤©åºœé“¶è¡ŒAIå›¢é˜Ÿç ”å‘çš„å¤šè¯­è¨€ä»£ç å¤§æ¨¡å‹åŸºåº§ã€‚CodeShellå…·æœ‰70äº¿å‚æ•°ï¼Œåœ¨äº”åƒäº¿Tokensè¿›è¡Œäº†è®­ç»ƒï¼Œä¸Šä¸‹æ–‡çª—å£é•¿åº¦ä¸º8192ã€‚åœ¨æƒå¨çš„ä»£ç è¯„ä¼°Benchmarkï¼ˆHumanEvalä¸MBPPï¼‰ä¸Šï¼ŒCodeShellå–å¾—åŒç­‰è§„æ¨¡æœ€å¥½çš„æ€§èƒ½ã€‚ä¸æ­¤åŒæ—¶ï¼Œæˆ‘ä»¬æä¾›äº†ä¸CodeShellé…å¥—çš„éƒ¨ç½²æ–¹æ¡ˆä¸IDEæ’ä»¶ï¼Œè¯·å‚è€ƒä»£ç åº“CodeShellã€‚

### CODEFUSION-75M
- https://arxiv.org/pdf/2310.14820.pdf
- https://github.com/microsoft/prose-benchmarks/tree/main/CodeFusion

Imagine a developer who can only change their last line of code, how often would they have to start writing a function from scratch before it is correct? Auto-regressive models for code generation from natural language have a similar limitation: they do not easily allow reconsidering earlier tokens generated. We introduce CodeFusion, a pre-trained diffusion code generation model that addresses this limitation by iteratively denoising a complete program conditioned on the encoded natural language. We evaluate CodeFusion on the task of natural language to code generation for Bash, Python, and Microsoft Excel conditional formatting (CF) rules. Experiments show that CodeFusion (75M parameters) performs on par with state-of-the-art auto-regressive systems (350M-175B parameters) in top-1 accuracy and outperforms them in top-3 and top-5 accuracy due to its better balance in diversity versus quality.

### DeepSeek Coder
- https://github.com/deepseek-ai/DeepSeek-Coder

Deepseek Coder comprises a series of code language models trained on both 87% code and 13% natural language in English and Chinese, with each model pre-trained on 2T tokens. We provide various sizes of the code model, ranging from 1B to 33B versions. Each model is pre-trained on project-level code corpus by employing a window size of 16K and a extra fill-in-the-blank task, to support project-level code completion and infilling. For coding capabilities, Deepseek Coder achieves state-of-the-art performance among open-source code models on multiple programming languages and various benchmarks.

### DevOps-Modelï¼ˆè¿ç»´ï¼‰
- https://github.com/codefuse-ai/CodeFuse-DevOps-Model

DevOps-Model æ˜¯ä¸€ç³»åˆ—ä¸šç•Œé¦–ä¸ªå¼€æºçš„ä¸­æ–‡å¼€å‘è¿ç»´å¤§æ¨¡å‹ï¼Œä¸»è¦è‡´åŠ›äºåœ¨ DevOps é¢†åŸŸå‘æŒ¥å®é™…ä»·å€¼ã€‚ç›®å‰ï¼ŒDevOps-Model èƒ½å¤Ÿå¸®åŠ©å·¥ç¨‹å¸ˆå›ç­”åœ¨ DevOps ç”Ÿå‘½å‘¨æœŸä¸­é‡åˆ°çš„é—®é¢˜ã€‚

æˆ‘ä»¬åŸºäº Qwen ç³»åˆ—æ¨¡å‹ï¼Œç»è¿‡é«˜è´¨é‡ä¸­æ–‡ DevOps è¯­æ–™åŠ è®­åäº§å‡º Base æ¨¡å‹ï¼Œç„¶åç»è¿‡ DevOps QA æ•°æ®å¯¹é½åäº§å‡º Chat æ¨¡å‹ã€‚æˆ‘ä»¬çš„ Base æ¨¡å‹å’Œ Chat æ¨¡å‹åœ¨å¼€æºå’Œ DevOps é¢†åŸŸç›¸å…³çš„è¯„æµ‹æ•°æ®ä¸Šå¯ä»¥å–å¾—åŒè§„æ¨¡æ¨¡å‹ä¸­çš„æœ€ä½³æ•ˆæœã€‚
åŒæ—¶æˆ‘ä»¬ä¹Ÿåœ¨æ­å»º DevOps é¢†åŸŸä¸“å±çš„è¯„æµ‹åŸºå‡† DevOpsEvalï¼Œç”¨æ¥æ›´å¥½è¯„æµ‹ DevOps é¢†åŸŸæ¨¡å‹çš„æ•ˆæœã€‚

### Magicoder
- https://github.com/ise-uiuc/magicoder
- https://arxiv.org/pdf/2312.02120.pdf

ğŸ©Magicoder is a model family empowered by ğŸª„OSS-Instruct, a novel approach to enlightening LLMs with open-source code snippets for generating low-bias and high-quality instruction data for code.

ğŸª„OSS-Instruct mitigates the inherent bias of the LLM-synthesized instruction data by empowering them with a wealth of open-source references to produce more diverse, realistic, and controllable data.

### KwaiAgents
- https://github.com/KwaiKEG/KwaiAgents

KwaiAgents is a series of Agent-related works open-sourced by the KwaiKEG from Kuaishou Technology. The open-sourced content includes:

- KAgentSys-Lite: a lite version of the KAgentSys in the paper. While retaining some of the original system's functionality, KAgentSys-Lite has certain differences and limitations when compared to its full-featured counterpart, such as: (1) a more limited set of tools; (2) a lack of memory mechanisms; (3) slightly reduced performance capabilities; and (4) a different codebase, as it evolves from open-source projects like BabyAGI and Auto-GPT. Despite these modifications, KAgentSys-Lite still delivers comparable performance among numerous open-source Agent systems available.
- KAgentLMs: a series of large language models with agent capabilities such as planning, reflection, and tool-use, acquired through the Meta-agent tuning proposed in the paper.
- KAgentInstruct: over 200k Agent-related instructions finetuning data (partially human-edited) proposed in the paper.
- KAgentBench: over 3,000 human-edited, automated evaluation data for testing Agent capabilities, with evaluation dimensions including planning, tool-use, reflection, concluding, and profiling.

### LLaMA-Pro
- https://huggingface.co/TencentARC/LLaMA-Pro-8B

LLaMA-Pro is a progressive version of the original LLaMA model, enhanced by the addition of Transformer blocks. It specializes in integrating both general language understanding and domain-specific knowledge, particularly in programming and mathematics.

### HuixiangDou
- https://github.com/InternLM/HuixiangDou
- https://arxiv.org/abs/2401.08772 

In this work, we present HuixiangDou, a technical assistant powered by Large Language Models (LLM). This system is designed to assist algorithm developers by providing insightful responses to questions related to open-source algorithm projects, such as computer vision and deep learning projects from OpenMMLab. We further explore the integration of this assistant into the group chats of instant messaging (IM) tools such as WeChat and Lark. Through several iterative improvements and trials, we have developed a sophisticated technical chat assistant capable of effectively answering users' technical questions without causing message flooding. This paper's contributions include: 1) Designing an algorithm pipeline specifically for group chat scenarios; 2) Verifying the reliable performance of text2vec in task rejection; 3) Identifying three critical requirements for LLMs in technical-assistant-like products, namely scoring ability, In-Context Learning (ICL), and Long Context.

### CodeAct
- https://arxiv.org/pdf/2402.01030.pdf
- https://github.com/xingyaoww/code-act

Large Language Model (LLM) agents, capable of performing a broad range of actions, such as invoking tools and controlling robots, show great potential in tackling real-world challenges. LLM agents are typically prompted to produce actions by generating JSON or text in a pre-defined format, which is usually limited by constrained action space (e.g., the scope of pre-defined tools) and restricted flexibility (e.g., inability to compose multiple tools). This work proposes to use executable Python code to consolidate LLM agents' actions into a unified action space (CodeAct). Integrated with a Python interpreter, CodeAct can execute code actions and dynamically revise prior actions or emit new actions upon new observations through multi-turn interactions. Our extensive analysis of 17 LLMs on API-Bank and a newly curated benchmark shows that CodeAct outperforms widely used alternatives (up to 20% higher success rate). The encouraging performance of CodeAct motivates us to build an open-source LLM agent that interacts with environments by executing interpretable code and collaborates with users using natural language. To this end, we collect an instruction-tuning dataset CodeActInstruct that consists of 7k multi-turn interactions using CodeAct. We show that it can be used with existing data to improve models in agent-oriented tasks without compromising their general capability. CodeActAgent, finetuned from Llama2 and Mistral, is integrated with Python interpreter and uniquely tailored to perform sophisticated tasks (e.g., model training) using existing libraries and autonomously self-debug.

### æ˜Ÿè¯­StarWhisper
- https://github.com/Yu-Yang-Li/StarWhisper

åœ¨å¤©æ–‡ç§‘å­¦æ•™è‚²è”ç›Ÿã€é›†æ€è°±æ–‡çŒ®å¹³å°ã€å¸å¤©å·¥ç¨‹çš„æ”¯æŒä¸‹ï¼ŒåŸºäºå¤©æ–‡å¤§æ¨¡å‹StarGLMå¼€å‘ç»éªŒï¼Œæˆ‘ä»¬è¿›ä¸€æ­¥è®­ç»ƒäº†æ˜Ÿè¯­StarWhisperç³»åˆ—æ¨¡å‹(åŒ…æ‹¬6B,7B,13B,14B,20B)ã€‚

ä»¥è¿›ä¸€æ­¥ç¼“è§£å¤§æ¨¡å‹åœ¨å¤©æ–‡é€šç”¨çŸ¥è¯†çš„å¹»è§‰ç°è±¡ï¼Œä¸ºæ¥ä¸‹æ¥å¯å¤„ç†å¤©æ–‡å¤šæ¨¡æ€ä»»åŠ¡ã€éƒ¨ç½²äºæœ›è¿œé•œé˜µåˆ—çš„ç§‘å­¦å…·èº«æ™ºèƒ½â€”â€”å¸å¤©å¤§è„‘æ‰“ä¸‹åŸºç¡€ã€‚

### OceanGPT
- https://www.zjukg.org/project/OceanGPT
- https://huggingface.co/zjunlp/oceangpt-7b

(Warning: The model in this paper might produce hallucinations and reader discretion is recommended) Ocean science, which delves into the oceans that are reservoirs of life and biodiversity, is of great significance given that oceans cover over 70% of our planet's surface. Recently, advances in Large Language Models (LLMs) have transformed the paradigm in science. Despite the success in other domains, current LLMs often fall short in catering to the needs of domain experts like oceanographers, and the potential of LLMs for ocean science is under-explored. The intrinsic reason may be the immense and intricate nature of ocean data as well as the necessity for higher granularity and richness in knowledge. To alleviate these issues, we introduce OceanGPT, the first-ever LLM in the ocean domain, which is expert in various ocean science tasks. We propose DoInstruct, a novel framework to automatically obtain a large volume of ocean domain instruction data, which generates instructions based on multi-agent collaboration. Additionally, we construct the first oceanography benchmark, OceanBench, to evaluate the capabilities of LLMs in the ocean domain. Though comprehensive experiments, OceanGPT not only shows a higher level of knowledge expertise for oceans science tasks but also gains preliminary embodied intelligence capabilities in ocean technology.

### K2&GeoGalactica
- https://github.com/davendw49/k2
- https://arxiv.org/abs/2401.00434
- https://github.com/geobrain-ai/geogalactica

K2: We introduce K2 (7B), an open-source language model trained by firstly further pretraining LLaMA on collected and cleaned geoscience literature, including geoscience open-access papers and Wikipedia pages, and secondly fine-tuning with knowledge-intensive instruction tuning data (GeoSignal). As for preliminary evaluation, we use GeoBench (consisting of NPEE and AP Test on Geology, Geography, and Environmental Science) as the benchmark. K2 outperforms the baselines on objectiv e and subjective tasks compared to several baseline models with similar parameters. In this repository, we will share the following code and data.

GeoGalactica: GeoGalactica is from further pre-training of Galactica -- a top-performing LLM trained with a large number of scientific documents. In this work, we take the initial step to leverage LLM for science, through a rather straightforward approach. We try to specialize an open-sourced LLM into geoscience, by further pre-training the model with a vast amount of texts in geoscience, as well as supervised fine-tuning (SFT) the resulting model with our custom collected instruction tuning dataset. These efforts result in a model GeoGalactica consisting of 30 billion parameters. To our best knowledge, it is the largest language model for the geoscience domain.

### SciGLM
- https://arxiv.org/abs/2401.07950
- https://github.com/THUDM/SciGLM

Large Language Models (LLMs) have shown promise in assisting scientific discovery. However, such applications are currently limited by LLMs' deficiencies in understanding intricate scientific concepts, deriving symbolic equations, and solving advanced numerical calculations. To bridge these gaps, we introduce SciGLM, a suite of scientific language models able to conduct college-level scientific reasoning. Central to our approach is a novel self-reflective instruction annotation framework to address the data scarcity challenge in the science domain. This framework leverages existing LLMs to generate step-by-step reasoning for unlabelled scientific questions, followed by a process of self-reflective critic-and-revise. Applying this framework, we curated SciInstruct, a diverse and high-quality dataset encompassing mathematics, physics, chemistry, and formal proofs. We fine-tuned the ChatGLM family of language models with SciInstruct, enhancing their capabilities in scientific and mathematical reasoning. Remarkably, SciGLM consistently improves both the base model (ChatGLM3-6B-Base) and larger-scale models (12B and 32B), without sacrificing the language understanding capabilities of the base model. This makes SciGLM a suitable foundational model to facilitate diverse scientific discovery tasks.

### Ziya-Reader-13B
- https://huggingface.co/IDEA-CCNL/Ziya-Reader-13B-v1.0

Ziya-Reader-13B-v1.0æ˜¯ä¸€ä¸ªçŸ¥è¯†é—®ç­”æ¨¡å‹ï¼Œç»™å®šé—®é¢˜å’ŒçŸ¥è¯†æ–‡æ¡£å¯ä»¥å‡†ç¡®å›ç­”é—®é¢˜ï¼Œç”¨äºå¤šæ–‡æ¡£æˆ–å•æ–‡æ¡£é—®ç­”ã€‚è¯¥æ¨¡å‹å…·æœ‰8kçš„ä¸Šä¸‹æ–‡çª—å£ï¼Œç›¸æ¯”å…¶ä»–å…·æœ‰æ›´é•¿çª—å£çš„æ¨¡å‹ï¼Œæˆ‘ä»¬åœ¨å¤šä¸ªé•¿æ–‡æœ¬ä»»åŠ¡çš„è¯„æµ‹ä¸­èƒœå‡ºã€‚åŒ…æ‹¬å¤šæ–‡æ¡£é—®ç­”ã€åˆæˆä»»åŠ¡ï¼ˆæ–‡æ¡£æ£€ç´¢ï¼‰é•¿æ–‡æœ¬æ‘˜è¦ã€‚

è¯¥æ¨¡å‹ä¸»è¦é¢å‘çŸ¥è¯†åº“é—®ç­”ã€æ£€ç´¢é—®ç­”ã€ç”µå•†å®¢æœç­‰åœºæ™¯ï¼Œåœ¨ç§åŸŸçŸ¥è¯†é—®ç­”ä¸­æœ‰ç€ä¸é”™çš„æ•ˆæœï¼Œèƒ½å¹¿æ³›åº”ç”¨äºæ³•å¾‹ã€é‡‘èã€åŒ»ç–—ç­‰å‚ç›´é¢†åŸŸã€‚å› ä¸ºå®ƒè§£å†³äº†å¤šæ–‡æ¡£é—®ç­”ä¸­å½“æ­£ç¡®ä¿¡æ¯ä¸åœ¨é¦–ä¸ªæˆ–æœ«å°¾æ–‡æ¡£ä¸­æ—¶ï¼Œå›ç­”å‡†ç¡®ç‡å¤§å¹…é™ä½çš„é—®é¢˜ã€‚

å¦å¤–ï¼Œæ¨¡å‹çš„é€šç”¨èƒ½åŠ›åŒæ ·å‡ºä¼—ï¼Œå¯ä»¥è¿›è¡Œé€šç”¨é—®ç­”ã€‚å®ƒåœ¨æˆ‘ä»¬çš„é€šç”¨èƒ½åŠ›è¯„ä¼°é›†ä¸Šçš„æ•ˆæœè¶…è¿‡äº†Ziya-Llama-13B-v1.1.

### Firefly-LLaMA2-Chinese
- https://github.com/yangjianxin1/Firefly-LLaMA2-Chinese

æœ¬é¡¹ç›®ä¸Fireflyä¸€è„‰ç›¸æ‰¿ï¼Œä¸“æ³¨äºä½èµ„æºå¢é‡é¢„è®­ç»ƒï¼Œæ—¢æ”¯æŒå¯¹Baichuan2ã€Qwenã€InternLMç­‰åŸç”Ÿä¸­æ–‡æ¨¡å‹è¿›è¡Œå¢é‡é¢„è®­ç»ƒï¼Œä¹Ÿå¯å¯¹LLaMA2ã€Falconç­‰è‹±æ–‡æ¨¡å‹è¿›è¡Œä¸­æ–‡è¯è¡¨æ‰©å……ï¼Œç„¶åè¿›è¡Œå¢é‡é¢„è®­ç»ƒã€‚

æˆ‘ä»¬å¼€æºäº†Firefly-LLaMA2-Chineseæ¨¡å‹ï¼Œè¿™æ˜¯ä¸­è‹±åŒè¯­ç³»åˆ—æ¨¡å‹ã€‚æˆ‘ä»¬ä»¥LLaMA2ğŸ¦™ä¸ºåŸºåº§æ¨¡å‹ï¼Œå¯¹LLaMA2è¿›è¡Œä¸­æ–‡è¯è¡¨æ‰©å……ï¼Œä½¿ç”¨22GBä¸­è‹±æ–‡é¢„è®­ç»ƒè¯­æ–™å¯¹å…¶è¿›è¡Œå¢é‡é¢„è®­ç»ƒã€‚ æœ€åä½¿ç”¨å¤§è§„æ¨¡ä¸­è‹±æ–‡å¤šè½®å¯¹è¯æŒ‡ä»¤å¯¹æ¨¡å‹è¿›è¡Œè®­ç»ƒã€‚æˆ‘ä»¬å¯¹æ¨¡å‹è¿›è¡Œäº†æ¦œå•è¯„æµ‹å’Œäººå·¥è¯„æµ‹ï¼Œä¸ç°æœ‰çš„å¼€æºå·¥ä½œç›¸æ¯”ï¼Œå…·æœ‰ä¸é”™çš„ç«äº‰åŠ›ã€‚

åœ¨Open LLM Leaderboardå’ŒCMMLUä¸Šï¼Œæˆ‘ä»¬çš„æ¨¡å‹è¶…è¶Šäº†Linlyã€Yayiã€FlagAlphaç­‰æ¨¡å‹ï¼› åœ¨Open LLM Leaderboardä¸Šè¶…è¶ŠZiyaï¼Œåœ¨CMMLUä¸Šæ¯”Ziyaç•¥ä½0.43åˆ†ã€‚åœ¨äººå·¥æµ‹è¯„ä¸­ï¼Œæˆ‘ä»¬çš„æ¨¡å‹ä»¥33.08%è·èƒœã€60.77%å¹³å±€ã€6.15%å¤±è´¥çš„æˆç»©ï¼Œè¶…è¶ŠLinlyã€‚ æˆ‘ä»¬è¿˜å¼€æºäº†firelfy-baichuan2-13bæ¨¡å‹ï¼Œåœ¨OpenCompassçš„CMMLUæ¦œå•ä¸Šä»¥56.83çš„åˆ†æ•°ï¼Œä½åˆ—ç¬¬8ï¼Œæ¯”ç™¾å·å®˜æ–¹æ¨¡å‹ç•¥ä½1.57åˆ†ã€‚

æ›´é‡è¦çš„æ˜¯ï¼Œåœ¨æ•´ä¸ªå¢é‡é¢„è®­ç»ƒå’ŒæŒ‡ä»¤å¾®è°ƒé˜¶æ®µï¼Œæˆ‘ä»¬æœ€å¤šä»…ä½¿ç”¨äº†4*V100çš„GPUï¼Œè®­ç»ƒæ›´åŠ ä½èµ„æºé«˜æ•ˆã€‚ç›¸è¾ƒäºZiyaçš„160*A100ï¼ŒLinlyçš„32*A100ï¼ŒChinese-LLaMA-Alpacaçš„48*A40ï¼Œæˆ‘ä»¬æ‰€ä½¿ç”¨çš„è®­ç»ƒèµ„æºå°‘å¾—å¤šã€‚

æˆäººä»¥é±¼ğŸŸï¼Œä¸å¦‚æˆäººä»¥æ¸”ğŸ£ï¼Œæˆ‘ä»¬ä¸ä»…å¼€æºäº†æ¨¡å‹æƒé‡ï¼Œä¹Ÿå¼€æºäº†é¡¹ç›®å…¨æµç¨‹çš„è®­ç»ƒä»£ç ã€è®­ç»ƒæ•°æ®ï¼Œä»¥åŠè®­ç»ƒç»†èŠ‚ã€‚

### MindLLM
- https://arxiv.org/abs/2310.15777

Large Language Models (LLMs) have demonstrated remarkable performance across various natural language tasks, marking significant strides towards general artificial intelligence. While general artificial intelligence is leveraged by developing increasingly large-scale models, there could be another branch to develop lightweight custom models that better serve certain domains, taking into account the high cost of training and deploying LLMs and the scarcity of resources. In this paper, we present MindLLM, a novel series of bilingual lightweight large language models, trained from scratch, alleviating such burdens by offering models with 1.3 billion and 3 billion parameters. A thorough account of experiences accrued during large model development is given, covering every step of the process, including data construction, model architecture, evaluation, and applications. Such insights are hopefully valuable for fellow academics and developers. MindLLM consistently matches or surpasses the performance of other open-source larger models on some public benchmarks. We also introduce an innovative instruction tuning framework tailored for smaller models to enhance their capabilities efficiently. Moreover, we explore the application of MindLLM in specific vertical domains such as law and finance, underscoring the agility and adaptability of our lightweight models.

### ChatGLM3
- https://github.com/THUDM/ChatGLM3

ChatGLM3 æ˜¯æ™ºè°±AIå’Œæ¸…åå¤§å­¦ KEG å®éªŒå®¤è”åˆå‘å¸ƒçš„æ–°ä¸€ä»£å¯¹è¯é¢„è®­ç»ƒæ¨¡å‹ã€‚ChatGLM3-6B æ˜¯ ChatGLM3 ç³»åˆ—ä¸­çš„å¼€æºæ¨¡å‹ï¼Œåœ¨ä¿ç•™äº†å‰ä¸¤ä»£æ¨¡å‹å¯¹è¯æµç•…ã€éƒ¨ç½²é—¨æ§›ä½ç­‰ä¼—å¤šä¼˜ç§€ç‰¹æ€§çš„åŸºç¡€ä¸Šï¼ŒChatGLM3-6B å¼•å…¥äº†å¦‚ä¸‹ç‰¹æ€§ï¼š

- æ›´å¼ºå¤§çš„åŸºç¡€æ¨¡å‹ï¼š ChatGLM3-6B çš„åŸºç¡€æ¨¡å‹ ChatGLM3-6B-Base é‡‡ç”¨äº†æ›´å¤šæ ·çš„è®­ç»ƒæ•°æ®ã€æ›´å……åˆ†çš„è®­ç»ƒæ­¥æ•°å’Œæ›´åˆç†çš„è®­ç»ƒç­–ç•¥ã€‚åœ¨è¯­ä¹‰ã€æ•°å­¦ã€æ¨ç†ã€ä»£ç ã€çŸ¥è¯†ç­‰ä¸åŒè§’åº¦çš„æ•°æ®é›†ä¸Šæµ‹è¯„æ˜¾ç¤ºï¼ŒChatGLM3-6B-Base å…·æœ‰åœ¨ 10B ä»¥ä¸‹çš„åŸºç¡€æ¨¡å‹ä¸­æœ€å¼ºçš„æ€§èƒ½ã€‚
- æ›´å®Œæ•´çš„åŠŸèƒ½æ”¯æŒï¼š ChatGLM3-6B é‡‡ç”¨äº†å…¨æ–°è®¾è®¡çš„ Prompt æ ¼å¼ï¼Œé™¤æ­£å¸¸çš„å¤šè½®å¯¹è¯å¤–ã€‚åŒæ—¶åŸç”Ÿæ”¯æŒå·¥å…·è°ƒç”¨ï¼ˆFunction Callï¼‰ã€ä»£ç æ‰§è¡Œï¼ˆCode Interpreterï¼‰å’Œ Agent ä»»åŠ¡ç­‰å¤æ‚åœºæ™¯ã€‚
- æ›´å…¨é¢çš„å¼€æºåºåˆ—ï¼š é™¤äº†å¯¹è¯æ¨¡å‹ ChatGLM3-6B å¤–ï¼Œè¿˜å¼€æºäº†åŸºç¡€æ¨¡å‹ ChatGLM3-6B-Baseã€é•¿æ–‡æœ¬å¯¹è¯æ¨¡å‹ ChatGLM3-6B-32Kã€‚ä»¥ä¸Šæ‰€æœ‰æƒé‡å¯¹å­¦æœ¯ç ”ç©¶å®Œå…¨å¼€æ”¾ï¼Œåœ¨å¡«å†™é—®å·è¿›è¡Œç™»è®°åäº¦å…è®¸å…è´¹å•†ä¸šä½¿ç”¨ã€‚

### Skyworkå¤§æ¨¡å‹
- https://github.com/SkyworkAI/Skywork

Skyworkæ˜¯ç”±æ˜†ä»‘ä¸‡ç»´é›†å›¢Â·å¤©å·¥å›¢é˜Ÿå¼€å‘çš„ä¸€ç³»åˆ—å¤§å‹æ¨¡å‹ï¼Œæœ¬æ¬¡å¼€æºçš„æ¨¡å‹æœ‰Skywork-13B-Baseæ¨¡å‹ã€Skywork-13B-Chatæ¨¡å‹ã€Skywork-13B-Mathæ¨¡å‹å’ŒSkywork-13B-MMæ¨¡å‹ï¼Œä»¥åŠæ¯ä¸ªæ¨¡å‹çš„é‡åŒ–ç‰ˆæ¨¡å‹ï¼Œä»¥æ”¯æŒç”¨æˆ·åœ¨æ¶ˆè´¹çº§æ˜¾å¡è¿›è¡Œéƒ¨ç½²å’Œæ¨ç†ã€‚

æˆ‘ä»¬å¼€æºçš„Skyworkç³»åˆ—æ¨¡å‹å¯ä»¥ç”¨äºå•†ä¸šç”¨é€”ï¼Œä½†éœ€è¦éµå¾ªæˆ‘ä»¬çš„åè®®ï¼Œä¸è¿›è¡Œæœ‰å®³æ´»åŠ¨ã€‚

### Yi-6B/34Bï¼ˆé›¶ä¸€ä¸‡ç‰©ï¼‰
- https://github.com/01-ai/Yi
- https://arxiv.org/abs/2403.04652

The Yi series models are large language models trained from scratch by developers at 01.AI. The first public release contains two bilingual (English/Chinese) base models with the parameter sizes of 6B and 34B. Both of them are trained with 4K sequence length and can be extended to 32K during inference time.

### Nanbeige-16Bï¼ˆå—åŒ—é˜-16Bï¼‰
- https://github.com/Nanbeige/Nanbeige

Nanbeige-16Bï¼ˆå—åŒ—é˜-16Bï¼‰æ˜¯å—åŒ—é˜å¤§æ¨¡å‹å®éªŒå®¤ç ”å‘çš„160äº¿å‚æ•°è§„æ¨¡çš„å¤§è¯­è¨€æ¨¡å‹ï¼Œé‡‡ç”¨äº†2.5T Tokensè¿›è¡Œé¢„è®­ç»ƒï¼Œæ•°æ®åŒ…å«å¤§é‡äº’è”ç½‘é«˜è´¨é‡è¯­æ–™ã€å„ç±»ä¹¦ç±ã€ä»£ç ç­‰é¢†åŸŸè„±æ•æ–‡æœ¬ï¼Œåœ¨å„ä¸ªæƒå¨æµ‹è¯„æ•°æ®é›†ä¸Šéƒ½å–å¾—äº†ä¸é”™çš„æ•ˆæœã€‚æœ¬æ¬¡å‘å¸ƒåŒ…å«æœ‰ Baseã€Chat ä»¥åŠæ‰©å±•ä¸Šä¸‹æ–‡é•¿åº¦çš„ Base-32kã€Chat-32k ç‰ˆæœ¬ã€‚

Base-32k ç‰ˆæœ¬åŸºäºNanbeige-16B-Baseæ¨¡å‹ï¼Œé‡‡ç”¨YaRNæ’å€¼æ–¹æ³•å¯¹ä½ç½®ç¼–ç è¿›è¡Œä¿®æ”¹ï¼Œå¹¶ä»¥32kä¸ºæœ€å¤§é•¿åº¦è¿›è¡Œäº†20B Tokensçš„ä¸­æ–‡ã€è‹±æ–‡ã€ä»£ç è¯­æ–™çš„å…¨å‚æ•°å¢é‡é¢„è®­ç»ƒã€‚

Chat ç‰ˆæœ¬å’Œ Chat-32k ç‰ˆæœ¬åˆ†åˆ«åŸºäºNanbeige-16B-Baseæ¨¡å‹å’ŒNanbeige-16B-Base-32kæ¨¡å‹ï¼Œç»è¿‡äº†å¤§é‡äººç±»å¯¹é½è®­ç»ƒï¼Œèƒ½å¤Ÿæ›´å¥½ã€æ›´å®‰å…¨åœ°å›å¤ç”¨æˆ·çš„é—®é¢˜ã€‚

### OrionStar-Yi-34B-Chat
- https://modelscope.cn/studios/OrionStarAI/OrionStar-Yi-34B-Chat/summary
- https://github.com/OrionStarAI/OrionStar-Yi-34B-Chat

OrionStar-Yi-34B-Chat æ˜¯çŒæˆ·æ˜Ÿç©ºåŸºäºé›¶ä¸€ä¸‡ç‰©å¼€æºçš„Yi-34Bæ¨¡å‹ï¼Œä½¿ç”¨ 15W+ çš„é«˜è´¨é‡è¯­æ–™è®­ç»ƒè€Œæ¥å¾®è°ƒå¤§æ¨¡å‹ï¼Œæ—¨åœ¨ä¸ºå¤§æ¨¡å‹ç¤¾åŒºç”¨æˆ·æä¾›å“è¶Šçš„äº¤äº’ä½“éªŒã€‚

### æº2.0
- https://github.com/IEIT-Yuan/Yuan-2.0
- https://github.com/IEIT-Yuan/Yuan-2.0/blob/main/docs/Yuan2_llama-factory.md

æº2.0 æ˜¯æµªæ½®ä¿¡æ¯å‘å¸ƒçš„æ–°ä¸€ä»£åŸºç¡€è¯­è¨€å¤§æ¨¡å‹ã€‚æˆ‘ä»¬å¼€æºäº†å…¨éƒ¨çš„3ä¸ªæ¨¡å‹æº2.0-102Bï¼Œæº2.0-51Bå’Œæº2.0-2Bã€‚å¹¶ä¸”æˆ‘ä»¬æä¾›äº†é¢„è®­ç»ƒï¼Œå¾®è°ƒï¼Œæ¨ç†æœåŠ¡çš„ç›¸å…³è„šæœ¬ï¼Œä»¥ä¾›ç ”å‘äººå‘˜åšè¿›ä¸€æ­¥çš„å¼€å‘ã€‚æº2.0æ˜¯åœ¨æº1.0çš„åŸºç¡€ä¸Šï¼Œåˆ©ç”¨æ›´å¤šæ ·çš„é«˜è´¨é‡é¢„è®­ç»ƒæ•°æ®å’ŒæŒ‡ä»¤å¾®è°ƒæ•°æ®é›†ï¼Œä»¤æ¨¡å‹åœ¨è¯­ä¹‰ã€æ•°å­¦ã€æ¨ç†ã€ä»£ç ã€çŸ¥è¯†ç­‰ä¸åŒæ–¹é¢å…·å¤‡æ›´å¼ºçš„ç†è§£èƒ½åŠ›ã€‚

### TechGPT2.0
- https://github.com/neukg/TechGPT-2.0

TechGPT-2.0 è¾ƒTechGPT-1.0 æ–°åŠ äº†è®¸å¤šé¢†åŸŸçŸ¥è¯†ã€‚é™¤äº†TechGPT-1.0 æ‰€å…·å¤‡çš„è®¡ç®—æœºç§‘å­¦ã€ææ–™ã€æœºæ¢°ã€å†¶é‡‘ã€é‡‘èå’Œèˆªç©ºèˆªå¤©ç­‰åä½™ç§å‚ç›´ä¸“ä¸šé¢†åŸŸèƒ½åŠ›ï¼ŒTechGPT-2.0 è¿˜åœ¨åŒ»å­¦ã€æ³•å¾‹ç­‰é¢†åŸŸæ–‡æœ¬å¤„ç†ä¸Šå±•ç°å‡ºä¼˜ç§€çš„èƒ½åŠ›ï¼Œå¹¶æ‰©å……äº†å¯¹åœ°ç†åœ°åŒºã€è¿è¾“ã€ç»„ç»‡ã€ä½œå“ã€ç”Ÿç‰©ã€è‡ªç„¶ç§‘å­¦ã€å¤©æ–‡å¯¹è±¡ã€å»ºç­‘ç­‰é¢†åŸŸæ–‡æœ¬çš„å¤„ç†èƒ½åŠ›ã€‚TechGPT-2.0è¿˜å¯¹å¹»è§‰ã€ä¸å¯å›ç­”ã€é•¿æ–‡æœ¬å¤„ç†ç­‰é—®é¢˜è¿›è¡Œäº†èƒ½åŠ›å¢å¼ºã€‚åŒæ—¶ï¼ŒTechGPT-2.0å¯¹éƒ¨ç½²çš„ç¡¬ä»¶è¦æ±‚æ›´ä½ï¼Œä½¿ç”¨NVIDIA 4090å•æœºå•å¡ã€æˆ–æ˜‡è…¾910Aå•æœºå•å¡å°±å¯å®ŒæˆTechGPT-2.0æ¨¡å‹éƒ¨ç½²ã€‚

### SUS-Chat-34B
- https://hf.co/SUSTech/SUS-Chat-34B
- https://github.com/SUSTech-IDEA/SUS-Chat

SUS-Chat-34Bæ¨¡å‹æ˜¯å—æ–¹ç§‘æŠ€å¤§å­¦è”åˆIDEAç ”ç©¶é™¢CCNLå›¢é˜Ÿå¼€æºçš„é€šç”¨å¤§æ¨¡å‹ï¼Œ 2023-12-05åœ¨Huggingfaceçš„æƒå¨æ¦œå•ä¸Šopen_llm_leaderboardå–å¾—äº†åŒçº§åˆ«æ¨¡å‹æœ€å¥½æˆç»©ã€‚

SUS-Chat-34Bæ˜¯ä¸€ä¸ª340äº¿å‚æ•°è§„æ¨¡çš„åŒè¯­æ¨¡å‹ï¼ŒåŸºäº01-ai/Yi-34Bé¢„è®­ç»ƒæ¨¡å‹é€šè¿‡æ•°ç™¾ä¸‡é«˜è´¨é‡ã€å¤šè¯­è¨€çš„æŒ‡ä»¤æ•°æ®è¿›è¡Œäº†å¾®è°ƒã€‚ åœ¨ä¿æŒåŸºç¡€æ¨¡å‹å¼ºå¤§çš„è¯­è¨€èƒ½åŠ›çš„åŒæ—¶ï¼ŒSUS-Chat-34Bæ¨¡å‹é€šè¿‡é«˜è´¨é‡æŒ‡ä»¤å¾®è°ƒæ”¹å–„äº†æ¨¡å‹å¯¹äººç±»æŒ‡ä»¤çš„å“åº”æ–¹å¼ï¼Œå¹¶æ“…é•¿é€šè¿‡æ€ç»´é“¾çš„æ–¹å¼æ¨¡ä»¿äººç±»æ€è€ƒè¿‡ç¨‹ã€‚ ä¸Yi-34Bå’ŒYi-34B-chatç›¸æ¯”ï¼Œå®ƒä¸ä»…åœ¨å‡ ä¹æ‰€æœ‰åŸºå‡†æµ‹è¯•ä¸­æå‡äº†æ€§èƒ½ï¼Œè€Œä¸”èƒ½å¤Ÿæ›´å¥½åœ°æ»¡è¶³äº†å¤æ‚å¤šè¯­è¨€ä»»åŠ¡çš„å®é™…éœ€æ±‚ã€‚ åœ¨æŒ‡ä»¤å¾®è°ƒé˜¶æ®µï¼Œæˆ‘ä»¬åŠ å…¥äº†å¤§é‡é«˜è´¨é‡é•¿æ–‡æœ¬å’Œå¤šè½®å¯¹è¯æŒ‡ä»¤æ•°æ®ï¼Œå°†æ–‡æœ¬çª—å£ä»åŸºç¡€æ¨¡å‹çš„4Kæ‰©å±•åˆ°8Kã€‚ è¿™ç§æ‰©å±•æœ‰åŠ©äºæ¨¡å‹æ›´æœ‰æ•ˆåœ°éµå¾ªå¤šè½®å¯¹è¯ä¸­çš„æŒ‡ä»¤ï¼Œæ˜¾è‘—å‡å°‘åœ¨æ‰©å±•å¯¹è¯å’Œé•¿æ–‡æœ¬ç†è§£ä¸­ä¸Šä¸‹æ–‡ä¸¢å¤±çš„é—®é¢˜ã€‚ä¸ºæ­¤æˆ‘ä»¬ä¹Ÿå¼€å‘äº†æ›´é«˜æ•ˆçš„è®­ç»ƒæ¡†æ¶ï¼Œä¸ä¹…ä¹Ÿå°†è¿›è¡Œå¼€æºï¼Œæ•¬è¯·æœŸå¾…ã€‚

### Alaya å…ƒè¯†
- https://github.com/DataCanvasIO/Alaya

ä¹ç« äº‘æDataCanvasé‡ç£…å‘å¸ƒçš„å…ƒè¯†å¤§æ¨¡å‹Alayaï¼Œåœ¨è‡ªä¸»æ•´ç†çš„é«˜å“è´¨å¤šè¯­è¨€æ•°æ®é›†ä¸Šè®­ç»ƒäº†1.5T+ tokensã€‚

é¦–å…ˆåœ¨Hugging Faceå¼€æºäº†7B-Baseå’Œ7B-Chatç‰ˆæœ¬ï¼Œæ¨¡å‹è¡¨ç°ä¸šå†…é¢†å…ˆï¼ŒçŸ¥è¯†ä¸°å¯Œä¸”å¯Œæœ‰æ—¶æ•ˆæ€§ï¼Œæœ€æ–°æ•°æ®è¦†ç›–2023å¹´10æœˆçš„å†…å®¹ã€‚Alaya-7B-Chatå…·å¤‡å¤šè½®å¯¹è¯ã€è‡ªæˆ‘è®¤çŸ¥å’Œåè§æ‹’ç­”çš„èƒ½åŠ›ï¼Œèƒ½å¤Ÿå®ŒæˆçŸ¥è¯†é—®ç­”ã€ä»£ç ç¼–å†™ã€ä¿¡æ¯æå–ã€é˜…è¯»ç†è§£ã€åˆ›æ„å†™ä½œç­‰å¤šé¡¹è¯­è¨€ä»»åŠ¡ã€‚

### OpenBuddy
- https://github.com/OpenBuddy/OpenBuddy
- https://huggingface.co/OpenBuddy
- https://openbuddy.ai

OpenBuddy is a powerful open multilingual chatbot model aimed at global users, emphasizing conversational AI and seamless multilingual support for English, Chinese, and other languages.

Built upon Tii's Falcon model and Facebook's LLaMA model, OpenBuddy is fine-tuned to include an extended vocabulary, additional common characters, and enhanced token embeddings. By leveraging these improvements and multi-turn dialogue datasets, OpenBuddy offers a robust model capable of answering questions and performing translation tasks across various languages.

Our mission with OpenBuddy is to provide a free, open, and offline-capable AI model that operates on users' devices, irrespective of their language or cultural background. We strive to empower individuals worldwide to access and benefit from AI technology.

### MiniGPT4Qwen
- https://github.com/Coobiw/MiniGPT4Qwen

Cleaned Lavis + DeepSpeed Support! Align MiniGPT4 with Qwen-Chat LLM. I just use 18.8k high-quality instruction-tuning data(Bi-lingual, from minigpt4 and llava). Just fine-tune the projection layer.

### ChatLM-Chinese-0.2B
- https://github.com/charent/ChatLM-mini-Chinese

ç°åœ¨çš„å¤§è¯­è¨€æ¨¡å‹çš„å‚æ•°å¾€å¾€è¾ƒå¤§ï¼Œæ¶ˆè´¹çº§ç”µè„‘å•çº¯åšæ¨ç†éƒ½æ¯”è¾ƒæ…¢ï¼Œæ›´åˆ«è¯´æƒ³è‡ªå·±ä»å¤´å¼€å§‹è®­ç»ƒä¸€ä¸ªæ¨¡å‹äº†ã€‚æœ¬é¡¹ç›®çš„ç›®æ ‡æ˜¯æ•´ç†ç”Ÿæˆå¼è¯­è¨€æ¨¡å‹çš„è®­ç»ƒæµç¨‹ï¼ŒåŒ…æ‹¬æ•°æ®æ¸…æ´—ã€tokenizerè®­ç»ƒã€æ¨¡å‹é¢„è®­ç»ƒã€SFTæŒ‡ä»¤å¾®è°ƒã€RLHFä¼˜åŒ–ç­‰ã€‚

ChatLM-mini-Chineseä¸ºä¸­æ–‡å¯¹è¯å°æ¨¡å‹ï¼Œæ¨¡å‹å‚æ•°åªæœ‰0.2Bï¼ˆç®—å…±äº«æƒé‡çº¦210Mï¼‰ï¼Œå¯ä»¥åœ¨æœ€ä½4GBæ˜¾å­˜çš„æœºå™¨è¿›è¡Œé¢„è®­ç»ƒï¼ˆbatch_size=1ï¼Œfp16æˆ–è€… bf16ï¼‰ï¼Œfloat16åŠ è½½ã€æ¨ç†æœ€å°‘åªéœ€è¦512MBæ˜¾å­˜ã€‚

### YAYI 2
- https://github.com/wenge-research/YAYI2/tree/main
- https://arxiv.org/abs/2312.14862
- https://yayi.wenge.com/

YAYI 2 æ˜¯ä¸­ç§‘é—»æ­Œç ”å‘çš„æ–°ä¸€ä»£å¼€æºå¤§è¯­è¨€æ¨¡å‹ï¼ŒåŒ…æ‹¬ Base å’Œ Chat ç‰ˆæœ¬ï¼Œå‚æ•°è§„æ¨¡ä¸º 30Bã€‚YAYI2-30B æ˜¯åŸºäº Transformer çš„å¤§è¯­è¨€æ¨¡å‹ï¼Œé‡‡ç”¨äº†è¶…è¿‡ 2 ä¸‡äº¿ Tokens çš„é«˜è´¨é‡ã€å¤šè¯­è¨€è¯­æ–™è¿›è¡Œé¢„è®­ç»ƒã€‚é’ˆå¯¹é€šç”¨å’Œç‰¹å®šé¢†åŸŸçš„åº”ç”¨åœºæ™¯ï¼Œæˆ‘ä»¬é‡‡ç”¨äº†ç™¾ä¸‡çº§æŒ‡ä»¤è¿›è¡Œå¾®è°ƒï¼ŒåŒæ—¶å€ŸåŠ©äººç±»åé¦ˆå¼ºåŒ–å­¦ä¹ æ–¹æ³•ï¼Œä»¥æ›´å¥½åœ°ä½¿æ¨¡å‹ä¸äººç±»ä»·å€¼è§‚å¯¹é½ã€‚

æœ¬æ¬¡å¼€æºçš„æ¨¡å‹ä¸º YAYI2-30B Base æ¨¡å‹ã€‚æˆ‘ä»¬å¸Œæœ›é€šè¿‡é›…æ„å¤§æ¨¡å‹çš„å¼€æºæ¥ä¿ƒè¿›ä¸­æ–‡é¢„è®­ç»ƒå¤§æ¨¡å‹å¼€æºç¤¾åŒºçš„å‘å±•ï¼Œå¹¶ç§¯æä¸ºæ­¤åšå‡ºè´¡çŒ®ã€‚é€šè¿‡å¼€æºï¼Œæˆ‘ä»¬ä¸æ¯ä¸€ä½åˆä½œä¼™ä¼´å…±åŒæ„å»ºé›…æ„å¤§æ¨¡å‹ç”Ÿæ€ã€‚

### DeepSeek LLM&MoE
- https://huggingface.co/deepseek-ai
- https://arxiv.org/abs/2401.02954
- https://github.com/deepseek-ai/DeepSeek-LLM
- https://github.com/deepseek-ai/DeepSeek-MoE

Introducing DeepSeek LLM, an advanced language model comprising 67 billion parameters. It has been trained from scratch on a vast dataset of 2 trillion tokens in both English and Chinese. In order to foster research, we have made DeepSeek LLM 7B/67B Base and DeepSeek LLM 7B/67B Chat open source for the research community.

### MachineMindset(MBTI)
- https://github.com/PKU-YuanGroup/Machine-Mindset

MM (Machine_Mindset) series models are developed through a collaboration between FarReel AI Lab(formerly known as the ChatLaw project) and Peking University's Deep Research Institute. These models are large-scale language models for various MBTI types in both Chinese and English, built on the Baichuan and LLaMA2 platforms. ğŸ¤–ğŸŒ

Our core asset is a self-constructed extensive MBTI dataset consisting of hundreds of thousands of entries. Our models are crafted through multiple stages of pre-training, fine-tuning, and DPO training. We are committed to continuously updating the models to offer superior performance and will consistently supplement them with experimental test results. ğŸ“ŠğŸ“ˆ

In contrast to merely using prompts to alter a model's personality, we have found that this method is highly unstable. It's akin to a controlling parent's dissatisfaction with their introverted child, attempting to force them to become outgoing through simple and coercive commands â€“ a rather ludicrous approach. ğŸ™…â€â™‚ï¸ğŸ˜„

We have successfully achieved personality alignment for various MBTI types using models such as Baichuan, Qwen, LLaMA, and Mistral. This means we can obtain 16 different versions of MBTI personality models by combining different base models with our dataset and training methods, tailoring each model for specific tasks. ğŸ› ğŸ§©

Due to resource constraints, we are initially releasing 16 Chinese models based on Baichuan-7b-chat and several English models based on LLaMA2-7b. However, rest assured that we can quickly add different versions of models if needed. ğŸŒğŸ“¦

### æ˜Ÿè¾°è¯­ä¹‰ï¼ˆç”µä¿¡ï¼‰
- https://gitee.com/Tele-AI/tele-chat 
- https://github.com/Tele-AI/Telechat 

æ˜Ÿè¾°è¯­ä¹‰å¤§æ¨¡å‹-TeleChat
- æ˜Ÿè¾°è¯­ä¹‰å¤§æ¨¡å‹TeleChatæ˜¯ç”±ä¸­ç”µä¿¡äººå·¥æ™ºèƒ½ç§‘æŠ€æœ‰é™å…¬å¸ç ”å‘è®­ç»ƒçš„å¤§è¯­è¨€æ¨¡å‹ï¼Œé‡‡ç”¨1.5ä¸‡äº¿ Tokensä¸­è‹±æ–‡é«˜è´¨é‡è¯­æ–™è¿›è¡Œè®­ç»ƒã€‚
- æœ¬æ¬¡å¼€æºäº†å¯¹è¯æ¨¡å‹TeleChat-7B-botï¼Œä»¥åŠå…¶huggingfaceæ ¼å¼çš„æƒé‡æ–‡ä»¶ã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬è¿˜å¼€æºäº†7Bæ¨¡å‹çš„int8å’Œint4é‡åŒ–ç‰ˆæœ¬ã€‚

### Chinese-Mixtral-8x7B
- https://github.com/HIT-SCIR/Chinese-Mixtral-8x7B

æœ¬é¡¹ç›®åŸºäºMistralå‘å¸ƒçš„æ¨¡å‹Mixtral-8x7Bè¿›è¡Œäº†ä¸­æ–‡æ‰©è¯è¡¨å¢é‡é¢„è®­ç»ƒï¼Œå¸Œæœ›è¿›ä¸€æ­¥ä¿ƒè¿›ä¸­æ–‡è‡ªç„¶è¯­è¨€å¤„ç†ç¤¾åŒºå¯¹MoEæ¨¡å‹çš„ç ”ç©¶ã€‚æˆ‘ä»¬æ‰©å……åçš„è¯è¡¨æ˜¾è‘—æé«˜äº†æ¨¡å‹å¯¹ä¸­æ–‡çš„ç¼–è§£ç æ•ˆç‡ï¼Œå¹¶é€šè¿‡å¤§è§„æ¨¡å¼€æºè¯­æ–™å¯¹æ‰©è¯è¡¨æ¨¡å‹è¿›è¡Œå¢é‡é¢„è®­ç»ƒï¼Œä½¿æ¨¡å‹å…·å¤‡äº†å¼ºå¤§çš„ä¸­æ–‡ç”Ÿæˆå’Œç†è§£èƒ½åŠ›ã€‚

### Baby-Llama2-Chinese
- https://github.com/DLLXW/baby-llama2-chinese

æœ¬é¡¹ç›®è‡´åŠ›äºæ„å»ºä¸€ä¸ªå°å‚æ•°é‡çš„ä¸­æ–‡Llama2ä»“åº“ã€‚

åŒ…å«ï¼šé¢„è®­ç»ƒã€SFTæŒ‡ä»¤å¾®è°ƒã€å¥–åŠ±æ¨¡å‹ä»¥åŠå¼ºåŒ–å­¦ä¹ ï¼ˆå¾…åšï¼‰å®Œæ•´æµç¨‹ã€‚

é™¤æ­¤ä¹‹å¤–ï¼Œæœ¬é¡¹ç›®è¿˜ä¼šæ¢³ç†ä¸€å¥—å®Œæ•´çš„LLMå­¦ä¹ èµ„æ–™ï¼ˆæ­£åœ¨è¿›è¡Œä¸­ï¼‰ã€‚

å¸Œæœ›è¯¥å¼€æºé¡¹ç›®å¯ä»¥å¸®åŠ©LLMåˆå­¦è€…ä»¥æœ€å¿«é€Ÿåº¦å…¥é—¨ï¼

### XVERSE-13B-256K
- https://huggingface.co/xverse/XVERSE-13B-256K

XVERSE-13B-256Kæ˜¯XVERSE-13B-2æ¨¡å‹ç»è¿‡ABF+ç»§ç»­é¢„è®­ç»ƒã€NTK+SFT å¾®è°ƒåçš„ç‰ˆæœ¬ã€‚

### Eagle 7Bï¼ˆRWKV-v5ï¼‰
- https://blog.rwkv.com/p/eagle-7b-soaring-past-transformers

A brand new era for the RWKV-v5 architecture and linear transformer's has arrived - with the strongest multi-lingual model in open source today.

### iFlytekSpark-13B
- https://gitee.com/iflytekopensource/iFlytekSpark-13B
- https://openi.pcl.ac.cn/iflytek/iFlytekSpark-13B
- https://xihe.mindspore.cn/modelzoo/iflytek/introduce

æ­¤æ¬¡å¼€æºä¸ä»…åŒ…æ‹¬åŸºç¡€æ¨¡å‹iFlytekSpark-13B-baseã€ç²¾è°ƒæ¨¡å‹iFlytekSpark-13B-chatï¼Œè¿˜æœ‰å¾®è°ƒå·¥å…·iFlytekSpark-13B-Loraï¼Œä»¥åŠäººè®¾å®šåˆ¶å·¥å…·iFlytekSpark-13B-Charaterã€‚

### MiniCPM
- https://github.com/OpenBMB/MiniCPM

MiniCPM æ˜¯é¢å£æ™ºèƒ½ä¸æ¸…åå¤§å­¦è‡ªç„¶è¯­è¨€å¤„ç†å®éªŒå®¤å…±åŒå¼€æºçš„ç³»åˆ—ç«¯ä¾§å¤§æ¨¡å‹ï¼Œä¸»ä½“è¯­è¨€æ¨¡å‹ MiniCPM-2B ä»…æœ‰ 24äº¿ï¼ˆ2.4Bï¼‰çš„éè¯åµŒå…¥å‚æ•°é‡ã€‚

### é€šä¹‰åƒé—®Qwen1.5
- https://github.com/QwenLM/Qwen1.5
- https://huggingface.co/spaces/Qwen/Qwen1.5-72B-Chat

With Qwen1.5, we are open-sourcing base and chat models across six sizes: 0.5B, 1.8B, 4B, 7B, 14B, and 72B. In line with tradition, weâ€™re also providing quantized models, including Int4 and Int8 GPTQ models, as well as AWQ and GGUF quantized models. 

### RethinkTinyLM
- https://github.com/YuchuanTian/RethinkTinyLM
- https://arxiv.org/pdf/2312.17276.pdf
- https://arxiv.org/pdf/2402.02791.pdf

The power of large language models (LLMs) has been demonstrated through numerous data and computing resources. However, the application of language models on mobile devices is facing huge challenge on the computation and memory costs, that is, tiny language models with high performance are urgently required. Limited by the highly complex training process, there are many details for optimizing language models that are seldom studied carefully. In this study, based on a tiny language model with 1B parameters, we carefully design a series of empirical study to analyze the effect of each component. Three perspectives are mainly discussed, \ie, neural architecture, parameter initialization, and optimization strategy. Several design formulas are empirically proved especially effective for tiny language models, including tokenizer compression, architecture tweaking, parameter inheritance and multiple-round training. Then we train PanGu-\pi-1B Pro and PanGu-\pi-1.5B Pro on 1.6T multilingual corpora, following the established formulas. Experimental results demonstrate the improved optimization and architecture yield a notable average improvement of 8.87 on benchmark evaluation sets for PanGu-\pi-1B Pro. Besides, PanGu-\pi-1.5B Pro surpasses a range of SOTA models with larger model sizes, validating its superior performance. 

### Chinese-Mixtral
- https://github.com/ymcui/Chinese-Mixtral

æœ¬é¡¹ç›®åŸºäºMistral.aiå‘å¸ƒçš„Mixtralæ¨¡å‹è¿›è¡Œå¼€å‘ï¼Œè¯¥æ¨¡å‹ä½¿ç”¨äº†ç¨€ç–æ··åˆä¸“å®¶æ¨¡å‹ï¼ˆSparse MoEï¼‰æ¶æ„ã€‚æœ¬é¡¹ç›®åˆ©ç”¨å¤§è§„æ¨¡ä¸­æ–‡æ— æ ‡æ³¨æ•°æ®è¿›è¡Œäº†ä¸­æ–‡å¢é‡è®­ç»ƒï¼Œå¾—åˆ°äº†ä¸­æ–‡MixtralåŸºç¡€æ¨¡å‹ï¼Œå¹¶ä¸”è¿›ä¸€æ­¥é€šè¿‡æŒ‡ä»¤ç²¾è°ƒï¼Œå¾—åˆ°äº†ä¸­æ–‡Mixtral-InstructæŒ‡ä»¤æ¨¡å‹ã€‚è¯¥æ¨¡å‹åŸç”Ÿæ”¯æŒ32Kä¸Šä¸‹æ–‡ï¼ˆå®æµ‹å¯è¾¾128Kï¼‰ï¼Œèƒ½å¤Ÿæœ‰æ•ˆåœ°å¤„ç†é•¿æ–‡æœ¬ï¼ŒåŒæ—¶åœ¨æ•°å­¦æ¨ç†ã€ä»£ç ç”Ÿæˆç­‰æ–¹é¢è·å¾—äº†æ˜¾è‘—æ€§èƒ½æå‡ã€‚ä½¿ç”¨llama.cppè¿›è¡Œé‡åŒ–æ¨ç†æ—¶ï¼Œæœ€ä½åªéœ€16Gå†…å­˜ï¼ˆæˆ–æ˜¾å­˜ï¼‰ã€‚

## 2 è®­ç»ƒ/æ¨ç†
### é«˜æ•ˆå¯¹é½ç®—æ³•RAFTã€Œæœ¨ç­ã€
- https://github.com/OptimalScale/LMFlow
- https://arxiv.org/abs/2304.06767
- https://optimalscale.github.io/LMFlow/examples/raft.html

An extensible, convenient, and efficient toolbox for finetuning large machine learning models, designed to be user-friendly, speedy and reliable, and accessible to the entire community.

### Alpaca-LoRA
- https://github.com/tloen/alpaca-lora

Low-Rank LLaMA Instruct-Tuning

This repository contains code for reproducing the Stanford Alpaca results using low-rank adaptation (LoRA). We provide an Instruct model of similar quality to text-davinci-003 that can run on a Raspberry Pi (for research), and the code can be easily extended to the 13b, 30b, and 65b models.

In addition to the training code, which runs within five hours on a single RTX 4090, we publish a script for downloading and inference on the foundation model and LoRA, as well as the resulting LoRA weights themselves. To fine-tune cheaply and efficiently, we use Hugging Face's PEFT as well as Tim Dettmers' bitsandbytes.

Without hyperparameter tuning or validation-based checkpointing, the LoRA model produces outputs comparable to the Stanford Alpaca model. (Please see the outputs included below.) Further tuning might be able to achieve better performance; I invite interested users to give it a try and report their results.

### AlpacaFarm
- https://mp.weixin.qq.com/s/CIF2F5Vx_RSN1-LwU_ppOQ
- https://tatsu-lab.github.io/alpaca_farm_paper.pdf
- https://github.com/tatsu-lab/alpaca_farm

ä¸»æµçš„å¤§å‹è¯­è¨€æ¨¡å‹è®­ç»ƒéƒ½ç¦»ä¸å¼€RLHF(äººå·¥åé¦ˆå¼ºåŒ–å­¦ä¹ )ï¼Œå…¶ä¸»è¦æ€æƒ³æ˜¯ä½¿ç”¨äººç±»ä¸“å®¶æä¾›çš„åé¦ˆç¤ºä¾‹æ¥æŒ‡å¯¼æ¨¡å‹çš„å­¦ä¹ è¿‡ç¨‹ï¼Œå®ƒå¯ä»¥åŠ é€Ÿå¼ºåŒ–å­¦ä¹ è¿‡ç¨‹ï¼Œæé«˜å¤§æ¨¡å‹çš„æ€§èƒ½ï¼Œä½†ã€Œç›®å‰RLHFè¿™ä¸ªè¿‡ç¨‹æ—¢å¤æ‚åˆæ˜‚è´µã€ã€‚

â€ƒé’ˆå¯¹RLHFè¿™ä¸ªé—®é¢˜ï¼Œå­¦æœ¯ç•Œç›®å‰ä¸»è¦æœ‰ä¸¤ç§è§£å†³æ–¹æ³•ï¼šã€Œ1ï¼‰é¿å¼€RLHFã€ï¼Œæ¯”å¦‚Metaæœ€è¿‘ç ”ç©¶çš„â€œMetaæœ€æ–°æ¨¡å‹ï¼šLIMA-65Bï¼Œæ²¡æœ‰RLHFï¼Œæ¨¡å‹æ•ˆæœè¿œèƒœAlpacaï¼ï¼â€ï¼ŒéªŒè¯äº†ç²¾å¿ƒåˆ¶ä½œçš„å°‘é‡æ ‡æ³¨æ•°æ®åŒæ ·èƒ½è¾¾åˆ°ä¸é”™çš„æ•ˆæœã€‚2ï¼‰ã€Œç®€åŒ–RLHFã€ï¼Œå°±æ˜¯ä»Šå¤©ç»™å¤§å®¶åˆ†äº«çš„è¿™ç¯‡æ–‡ç« ï¼šæ–¯å¦ç¦å‘å¸ƒäº†ä¸€ä¸ªåä¸ºAlpacaFarmï¼ˆç¾Šé©¼å†œåœºï¼‰çš„æ¨¡æ‹Ÿå™¨ï¼Œæ—¨åœ¨é™ä½è®­ç»ƒè¯­è¨€æ¨¡å‹çš„æˆæœ¬ï¼Œä¸”æ¯”äººå·¥æˆæœ¬ä½45å€ï¼Œå¹¶è¡¨ç°å‡ºä¸äººç±»åé¦ˆçš„é«˜åº¦ä¸€è‡´æ€§ï¼ŒåŒæ—¶ä¹Ÿä¸ºRLHFçš„ç ”ç©¶å¼€è¾Ÿäº†æ–°çš„é“è·¯ã€‚
 
### ColossalAI
- https://github.com/hpcaitech/ColossalAI

Colossal-AI: Making large AI models cheaper, faster and more accessible

Colossal-AI provides a collection of parallel components for you. We aim to support you to write your distributed deep learning models just like how you write your model on your laptop. We provide user-friendly tools to kickstart distributed training and inference in a few lines.

### ChatLLaMA
- https://github.com/nebuly-ai/nebullvm/tree/main/apps/accelerate/chatllama

ChatLLaMA ğŸ¦™ has been designed to help developers with various use cases, all related to RLHF training and optimized inference.

ChatLLaMA is a library that allows you to create hyper-personalized ChatGPT-like assistants using your own data and the least amount of compute possible. Instead of depending on one large assistant that â€œrules us allâ€, we envision a future where each of us can create our own personalized version of ChatGPT-like assistants. Imagine a future where many ChatLLaMAs at the "edge" will support a variety of human's needs. But creating a personalized assistant at the "edge" requires huge optimization efforts on many fronts: dataset creation, efficient training with RLHF, and inference optimization.

### Chinese-Guanaco
- https://github.com/jianzhnie/Chinese-Guanaco

This is the repo for the Chinese-Guanaco project, which aims to build and share instruction-following Chinese LLaMA/Pythia/GLM model tuning methods which can be trained on a single Nvidia RTX-2080TI, multi-round chatbot which can be trained on a single Nvidia RTX-3090 with the context len 2048.

Chinese-Guanaco uses bitsandbytes for quantization and is integrated with Huggingface's PEFT and transformers libraries.

### DPO (Direct Preference Optimization)
- https://arxiv.org/abs/2305.18290
- https://zhuanlan.zhihu.com/p/641045324
- https://huggingface.co/lyogavin/Anima33B-DPO-Belle-1k-merged
- https://github.com/lyogavin/Anima/tree/main/rlhf

DPOçš„æ ¸å¿ƒåŸç†æ˜¯ï¼šPPOè®­ç»ƒéš¾åº¦æ ¸å¿ƒæ˜¯å› ä¸ºéœ€è¦é€šè¿‡reward modelæ¥è¡¨è¾¾åå¥½ï¼Œè¿›è¡Œå¼ºåŒ–å­¦ä¹ ã€‚

ä¸ºäº†ä¸å†ä¾èµ–äºreward modelè¿›è¡Œå¼ºåŒ–å­¦ä¹ ï¼Œä»–è¿›è¡Œäº†ä¸€ç³»åˆ—çš„æ•°å­¦å˜æ¢ï¼Œç›´æ¥æ¨å¯¼å‡ºäº†åŸºäºPolicy Language Modelçš„æ ‡æ³¨åå¥½çš„æ¦‚ç‡è¡¨è¾¾å½¢å¼ï¼Œä»è€Œå¯ä»¥ç›´æ¥æ±‚è§£ä¸€ä¸ªLanguage Modelçš„æœ€å¤§ä¼¼ç„¶ä¼°è®¡ã€‚ä¸å†éœ€è¦å¤æ‚ç¹ççš„reward modelå’Œå¼ºåŒ–å­¦ä¹ ã€‚

While large-scale unsupervised language models (LMs) learn broad world knowledge and some reasoning skills, achieving precise control of their behavior is difficult due to the completely unsupervised nature of their training. Existing methods for gaining such steerability collect human labels of the relative quality of model generations and fine-tune the unsupervised LM to align with these preferences, often with reinforcement learning from human feedback (RLHF). However, RLHF is a complex and often unstable procedure, first fitting a reward model that reflects the human preferences, and then fine-tuning the large unsupervised LM using reinforcement learning to maximize this estimated reward without drifting too far from the original model. In this paper, we leverage a mapping between reward functions and optimal policies to show that this constrained reward maximization problem can be optimized exactly with a single stage of policy training, essentially solving a classification problem on the human preference data. The resulting algorithm, which we call Direct Preference Optimization (DPO), is stable, performant and computationally lightweight, eliminating the need for fitting a reward model, sampling from the LM during fine-tuning, or performing significant hyperparameter tuning. Our experiments show that DPO can fine-tune LMs to align with human preferences as well as or better than existing methods. Notably, fine-tuning with DPO exceeds RLHF's ability to control sentiment of generations and improves response quality in summarization and single-turn dialogue while being substantially simpler to implement and train.

### DialogADVï¼šEvaluate What You Can't Evaluate: Unassessable Generated Responses Quality
- https://github.com/misonsky/DialogADV
- https://mp.weixin.qq.com/s/Ga0a6a1L6CmCXgk6WDz0Xg
- https://arxiv.org/abs/2305.14658

æˆ‘ä»¬æ„å»ºäº†ä¸¤ä¸ªå…·æœ‰æŒ‘æˆ˜çš„å…ƒéªŒè¯å¯¹è¯æ•°æ®é›†ï¼Œé€šè¿‡å®éªŒåˆ†æè¡¨æ˜

å¤§å‹è¯­è¨€æ¨¡å‹ä½œä¸ºè¯„ä¼°å™¨è¯„ä¼°å¯¹è¯æ–‡æœ¬ç”Ÿæˆè´¨é‡ä»ç„¶å­˜åœ¨å¾ˆå¤šé—®é¢˜ï¼š1ï¼‰LLMsæ— æ³•è¯†åˆ«ä¸äº‹å®ä¸ä¸€è‡´çš„ã€è™šæ„çš„å›å¤ï¼Œå¯¹ä¸åˆç†çš„å›å¤ä»ç„¶ç»™å‡ºè¾ƒé«˜çš„è¯„ä»·ï¼›2ï¼‰ LLMsè‡ªèº«çš„çŸ¥è¯†æœ‰é™ï¼Œå¯¹äºä¾èµ–çŸ¥è¯†çš„æ ·ä¾‹å¤§è¯­è¨€æ¨¡å‹æ— æ³•ä¾é è‡ªèº«çš„çŸ¥è¯†ç»™å‡ºåˆç†çš„åˆ¤æ–­ï¼›3ï¼‰LLMsåˆ©ç”¨å¤–éƒ¨çŸ¥è¯†çš„èƒ½åŠ›æœ‰å¾…æé«˜ã€‚åœ¨ç»™å®šå¤–éƒ¨çŸ¥è¯†çš„æƒ…å†µä¸‹ï¼ŒLLMsä»ç„¶ä¼šå¯¹ä¸åˆç†çš„å›å¤ç»™å‡ºè¾ƒé«˜çš„è¯„ä»·ã€‚

### DeepSpeed-Chat
- https://mp.weixin.qq.com/s/t3HA4Hu61LLDC3h2Njmo_Q
- https://github.com/microsoft/DeepSpeed

å¾®è½¯å®£å¸ƒå¼€æº DeepSpeed-Chatï¼Œå¸®åŠ©ç”¨æˆ·è½»æ¾è®­ç»ƒç±» ChatGPT ç­‰å¤§è¯­è¨€æ¨¡å‹ã€‚

æ®æ‚‰ï¼ŒDeep Speed Chat æ˜¯åŸºäºå¾®è½¯ Deep Speed æ·±åº¦å­¦ä¹ ä¼˜åŒ–åº“å¼€å‘è€Œæˆï¼Œå…·å¤‡è®­ç»ƒã€å¼ºåŒ–æ¨ç†ç­‰åŠŸèƒ½ï¼Œè¿˜ä½¿ç”¨äº† RLHFï¼ˆåŸºäºäººç±»åé¦ˆçš„å¼ºåŒ–å­¦ä¹ ï¼‰æŠ€æœ¯ï¼Œå¯å°†è®­ç»ƒé€Ÿåº¦æå‡ 15 å€ä»¥ä¸Šï¼Œè€Œæˆæœ¬å´å¤§å¤§é™ä½ã€‚

### FlexGen
- https://github.com/FMInference/FlexGen

FlexGen is a high-throughput generation engine for running large language models with limited GPU memory. FlexGen allows high-throughput generation by IO-efficient offloading, compression, and large effective batch sizes.

Limitation. As an offloading-based system running on weak GPUs, FlexGen also has its limitations. FlexGen can be significantly slower than the case when you have enough powerful GPUs to hold the whole model, especially for small-batch cases. FlexGen is mostly optimized for throughput-oriented batch processing settings (e.g., classifying or extracting information from many documents in batches), on single GPUs.

### FlagAI and FlagData

- https://github.com/FlagAI-Open/FlagAI

FlagAI (Fast LArge-scale General AI models) is a fast, easy-to-use and extensible toolkit for large-scale model. Our goal is to support training, fine-tuning, and deployment of large-scale models on various downstream tasks with multi-modality.

- https://github.com/FlagOpen/FlagData

FlagData, a data processing toolkit that is easy to use and expand. FlagData integrates the tools and algorithms of multi-step data processing, including cleaning, condensation, annotation and analysis, providing powerful data processing support for model training and deployment in multiple fields, including natural language processing and computer vision. 

### Guanaco & QloRA
- https://mp.weixin.qq.com/s/SGJQHsEJTNB6hiVqdc87sg
- https://arxiv.org/abs/2305.14314
- https://github.com/artidoro/qlora
- https://huggingface.co/blog/hf-bitsandbytes-integration
- Integration: https://colab.research.google.com/drive/1ge2F1QSK8Q7h0hn3YKuBCOAS0bK8E0wf?usp=sharing
- Training: https://colab.research.google.com/drive/1VoYNfYDKcKRQRor98Zbf2-9VQTtGJ24k?usp=sharing

We present QLoRA, an efficient finetuning approach that reduces memory usage enough to finetune a 65B parameter model on a single 48GB GPU while preserving full 16-bit finetuning task performance. QLoRA backpropagates gradients through a frozen, 4-bit quantized pretrained language model into Low Rank Adapters (LoRA). Our best model family, which we name Guanaco, outperforms all previous openly released models on the Vicuna benchmark, reaching 99.3% of the performance level of ChatGPT while only requiring 24 hours of finetuning on a single GPU. QLoRA introduces a number of innovations to save memory without sacrificing performance: (a) 4-bit NormalFloat (NF4), a new data type that is information theoretically optimal for normally distributed weights (b) Double Quantization to reduce the average memory footprint by quantizing the quantization constants, and (c) Paged Optimizers to manage memory spikes. We use QLoRA to finetune more than 1,000 models, providing a detailed analysis of instruction following and chatbot performance across 8 instruction datasets, multiple model types (LLaMA, T5), and model scales that would be infeasible to run with regular finetuning (e.g. 33B and 65B parameter models). Our results show that QLoRA finetuning on a small high-quality dataset leads to state-of-the-art results, even when using smaller models than the previous SoTA. We provide a detailed analysis of chatbot performance based on both human and GPT-4 evaluations showing that GPT-4 evaluations are a cheap and reasonable alternative to human evaluation. Furthermore, we find that current chatbot benchmarks are not trustworthy to accurately evaluate the performance levels of chatbots. We release all of our models and code, including CUDA kernels for 4-bit training.

### GPT4All
- https://github.com/nomic-ai/gpt4all

Demo, data and code to train an assistant-style large language model with ~800k GPT-3.5-Turbo Generations based on LLaMa

### HugNLP
- https://mp.weixin.qq.com/s/IpgOQJ8vrIvnjdrmGCT2FA
- https://github.com/HugAILab/HugNLP
- https://arxiv.org/abs/2302.14286

åå¸ˆå¤§HugAILabå›¢é˜Ÿç ”å‘äº†HugNLPæ¡†æ¶ï¼Œè¿™æ˜¯ä¸€ä¸ªé¢å‘ç ”ç©¶è€…å’Œå¼€å‘è€…çš„å…¨é¢ç»Ÿä¸€çš„NLPè®­ç»ƒæ¡†æ¶ï¼Œå¯æ”¯æŒåŒ…æ‹¬æ–‡æœ¬åˆ†ç±»ã€æ–‡æœ¬åŒ¹é…ã€é—®ç­”ã€ä¿¡æ¯æŠ½å–ã€æ–‡æœ¬ç”Ÿæˆã€å°æ ·æœ¬å­¦ä¹ ç­‰å¤šç§NLPä»»åŠ¡æ¨¡å‹æ­å»ºå’Œè®­ç»ƒã€‚

HugNLPè¿˜é›†æˆäº†å¤§é‡æœ€æ–°çš„PromptæŠ€æœ¯ï¼Œä¾‹å¦‚Prompt-Tuningã€In-Context Learningã€Instruction-tuningï¼Œæœªæ¥è¿˜å°†å¼•å…¥Chain-of-thought

HugAILabå›¢é˜Ÿè¿˜ç ”å‘äº†ä¸€ç³»åˆ—çš„åº”ç”¨ï¼Œä¾‹å¦‚CLUE&GLUEåˆ·æ¦œå·¥å…·ï¼Œå¯æ”¯æŒChatGPTç±»æ¨¡å‹è®­ç»ƒå’Œéƒ¨ç½²äº§å“HugChatï¼Œä»¥åŠç»Ÿä¸€ä¿¡æ¯æŠ½å–äº§å“HugIEç­‰ã€‚

HugNLPæ˜¯ä¸€ä¸ªåˆ†å±‚å¼æ¡†æ¶ï¼Œéµå¾ªâ€œé«˜å†…èšä½è€¦åˆâ€çš„å¼€å‘æ¨¡å¼ï¼Œå…¶æ ¸å¿ƒåŒ…æ‹¬æ¨¡å‹å±‚ï¼ˆModelsï¼‰ã€å¤„ç†å™¨å±‚ï¼ˆProcessorsï¼‰ã€è¯„ä¼°å™¨å±‚ï¼ˆEvaluatorsï¼‰å’Œåº”ç”¨å±‚ï¼ˆApplicationsï¼‰å››éƒ¨åˆ†ã€‚

### INSTRUCTEVAL
- https://mp.weixin.qq.com/s/E6hq0AUy_hItA5HGo2tCAQ
- https://github.com/declare-lab/instruct-eval
- https://arxiv.org/abs/2306.04757

æœ¬æ–‡å¼•å…¥äº†ä¸€ä¸ªåä¸ºINSTRUCTEVALçš„æ–°å‹è¯„ä¼°å¥—ä»¶ã€‚è¯¥å¥—ä»¶ä¸“ç”¨äºå¯¹æŒ‡ä»¤è°ƒä¼˜å¤§å‹è¯­è¨€æ¨¡å‹çš„å…¨é¢è¯„ä¼°ï¼Œç›¸æ¯”ä¹‹å‰å¯¹LLMsçš„è¯„ä¼°æ–¹æ³•ï¼Œè¯¥è¯„ä¼°ç­–ç•¥ä¸ä»…è¯¦ç»†è¯„ä¼°äº†æ¨¡å‹è§£å†³é—®é¢˜çš„èƒ½åŠ›ã€æ–‡å­—å†™ä½œèƒ½åŠ›ï¼Œè€Œä¸”è¿˜ä¸¥æ ¼è¯„ä¼°äº†æ¨¡å‹ä¸äººç±»ä»·å€¼çš„å¯¹é½èƒ½åŠ›ã€‚

### LOw-Memory Optimization (LOMO)
- https://arxiv.org/abs/2306.09782
- https://github.com/OpenLMLab/LOMO

Large Language Models (LLMs) have revolutionized Natural Language Processing (NLP) but demand massive GPU resources for training. Lowering the threshold for LLMs training would encourage greater participation from researchers, benefiting both academia and society. While existing approaches have focused on parameter-efficient fine-tuning, which tunes or adds a small number of parameters, few have addressed the challenge of tuning the full parameters of LLMs with limited resources. In this work, we propose a new optimizer, LOw-Memory Optimization (LOMO), which fuses the gradient computation and the parameter update in one step to reduce memory usage. By integrating LOMO with existing memory saving techniques, we reduce memory usage to 10.8% compared to the standard approach (DeepSpeed solution). Consequently, our approach enables the full parameter fine-tuning of a 65B model on a single machine with 8 RTX 3090, each with 24GB memory.

### llama.cpp
- https://github.com/ggerganov/llama.cpp

Inference of LLaMA model in pure C/C++

The main goal is to run the model using 4-bit quantization on a MacBook
- Plain C/C++ implementation without dependencies
- Apple silicon first-class citizen - optimized via ARM NEON
- AVX2 support for x86 architectures
- Mixed F16 / F32 precision
- 4-bit quantization support
- Runs on the CPU

### llama2.c
- https://github.com/karpathy/llama2.c
- https://mp.weixin.qq.com/s/RFo6B5yfEhv4mihkBiOH4Q

With the code in this repo you can train the Llama 2 LLM architecture from scratch in PyTorch, then export the weights to a binary file, and load that into one ~simple 500-line C file (run.c) that inferences the model. Alternatively, you can load, finetune, and inference Meta's Llama 2 (but this is still being actively fleshed out). Hence, this repo is a "fullstack" train + inference solution for Llama 2 LLM, with a focus on minimalism and simplicity. You might think that you need many billion parameter LLMs to do anything useful, but in fact very small LLMs can have surprisingly strong performance if you make the domain narrow enough. I recommend looking at the TinyStories paper for inspiration.

Please note that this started recently as just a fun weekend project: I took my earlier nanoGPT, tuned it to implement the Llama-2 architecture instead of GPT-2, and the meat of it was writing the C inference engine in run.c. So the project is young and moving quickly. Hat tip to the awesome llama.cpp for inspiring this project. I wanted something super minimal so I chose to hard-code the Llama 2 architecture, stick to fp32, and just roll one inference file of pure C with no dependencies.

### LongLoRA
- https://github.com/dvlab-research/longlora
- https://arxiv.org/pdf/2309.12307v1.pdf

We present LongLoRA, an efficient fine-tuning approach that extends the context sizes of pre-trained large language models (LLMs), with limited computation cost. Typically, training LLMs with long context sizes is computationally expensive, requiring extensive training hours and GPU resources. In this paper, we speed up the context extension of LLMs in two aspects. On the one hand, although dense global attention is needed during inference, fine-tuning the model can be effectively and efficiently done by sparse local attention. The proposed shift short attention effectively enables context extension, leading to non-trivial computation saving with similar performance to fine-tuning with vanilla attention. On the other hand, we find that LoRA for context extension works well under the premise of trainable embedding and normalization. LongLoRA demonstrates strong empirical results on various tasks on LLaMA2 models from 7B/13B to 70B. LongLoRA adopts LLaMA2 7B from 4k context to 100k, or LLaMA2 70B to 32k on a single 8x A100 machine. LongLoRA extends models' context while retaining their original architectures, and is compatible with most existing techniques, like FlashAttention-2. In addition, to make LongLoRA practical, we collect a dataset, LongQA, for supervised fine-tuning. It contains more than 3k long context question-answer pairs. 

### RLLTE: Long-Term Evolution Project of Reinforcement Learning
- https://github.com/RLE-Foundation/rllte

å—é€šä¿¡é¢†åŸŸé•¿æœŸæ¼”è¿›ï¼ˆLTEï¼‰æ ‡å‡†é¡¹ç›®çš„å¯å‘ï¼ŒRLLTEæ—¨åœ¨æä¾›ç”¨äºæ¨è¿›RLç ”ç©¶å’Œåº”ç”¨çš„å¼€å‘ç»„ä»¶å’Œå·¥ç¨‹æ ‡å‡†ã€‚é™¤äº†æä¾›ä¸€æµçš„ç®—æ³•å®ç°å¤–ï¼ŒRLLTEè¿˜èƒ½å¤Ÿå……å½“å¼€å‘ç®—æ³•çš„å·¥å…·åŒ…ã€‚

### FlashAttention
- https://github.com/Dao-AILab/flash-attention

This repository provides the official implementation of FlashAttention and FlashAttention-2.

### ExecuTorch
- https://github.com/pytorch/executorch
- https://pytorch.org/executorch/stable/index.html

ExecuTorch æ˜¯ä¸€ä¸ªç«¯åˆ°ç«¯çš„è§£å†³æ–¹æ¡ˆï¼Œå¯ä»¥åœ¨ç§»åŠ¨å’Œè¾¹ç¼˜è®¾å¤‡ï¼ˆåŒ…æ‹¬å¯ç©¿æˆ´è®¾å¤‡ã€æ‰‹æœºç­‰ï¼‰ä¸Šå®ç°æ¨ç†åŠŸèƒ½ã€‚

ExecuTorch is an end-to-end solution for enabling on-device inference capabilities across mobile and edge devices including wearables, embedded devices and microcontrollers. It is part of the PyTorch Edge ecosystem and enables efficient deployment of PyTorch models to edge devices.

Key value propositions of ExecuTorch are:
- Portability: Compatibility with a wide variety of computing platforms, from high-end mobile phones to highly constrained embedded systems and microcontrollers.
- Productivity: Enabling developers to use the same toolchains and SDK from PyTorch model authoring and conversion, to debugging and deployment to a wide variety of platforms.
- Performance: Providing end users with a seamless and high-performance experience due to a lightweight runtime and utilizing full hardware capabilities such as CPUs, NPUs, and DSPs.

### TensorRT-LLM
- https://github.com/NVIDIA/TensorRT-LLM

TensorRT-LLM provides users with an easy-to-use Python API to define Large Language Models (LLMs) and build TensorRT engines that contain state-of-the-art optimizations to perform inference efficiently on NVIDIA GPUs. TensorRT-LLM also contains components to create Python and C++ runtimes that execute those TensorRT engines. It also includes a backend for integration with the NVIDIA Triton Inference Server; a production-quality system to serve LLMs. Models built with TensorRT-LLM can be executed on a wide range of configurations going from a single GPU to multiple nodes with multiple GPUs (using Tensor Parallelism and/or Pipeline Parallelism).

The Python API of TensorRT-LLM is architectured to look similar to the PyTorch API. It provides users with a functional module containing functions like einsum, softmax, matmul or view. The layers module bundles useful building blocks to assemble LLMs; like an Attention block, a MLP or the entire Transformer layer. Model-specific components, like GPTAttention or BertAttention, can be found in the models module.

TensorRT-LLM comes with several popular models pre-defined. They can easily be modified and extended to fit custom needs. See below for a list of supported models.

To maximize performance and reduce memory footprint, TensorRT-LLM allows the models to be executed using different quantization modes (see examples/gpt for concrete examples). TensorRT-LLM supports INT4 or INT8 weights (and FP16 activations; a.k.a. INT4/INT8 weight-only) as well as a complete implementation of the SmoothQuant technique.

### BPOï¼ˆBlack-Box Prompt Optimizationï¼‰
- https://github.com/thu-coai/BPO
- https://arxiv.org/abs/2311.04155

Black-box Prompt Optimization (BPO) offers a conceptually new perspective to bridge the gap between humans and LLMs. (Lower) On Vicuna Evalâ€™s pairwise evaluation, we show that BPO further aligns gpt-3.5-turbo and claude-2 without training. It also outperforms both PPO & DPO and presents orthogonal improvements.

### S-LoRA
- https://arxiv.org/pdf/2311.03285.pdf
- https://github.com/S-LoRA/S-LoRA

The "pretrain-then-finetune" paradigm is commonly adopted in the deployment of large language models. Low-Rank Adaptation (LoRA), a parameter-efficient fine-tuning method, is often employed to adapt a base model to a multitude of tasks, resulting in a substantial collection of LoRA adapters derived from one base model. We observe that this paradigm presents significant opportunities for batched inference during serving. To capitalize on these opportunities, we present S-LoRA, a system designed for the scalable serving of many LoRA adapters. S-LoRA stores all adapters in the main memory and fetches the adapters used by the currently running queries to the GPU memory. To efficiently use the GPU memory and reduce fragmentation, S-LoRA proposes Unified Paging. Unified Paging uses a unified memory pool to manage dynamic adapter weights with different ranks and KV cache tensors with varying sequence lengths. Additionally, S-LoRA employs a novel tensor parallelism strategy and highly optimized custom CUDA kernels for heterogeneous batching of LoRA computation. Collectively, these features enable S-LoRA to serve thousands of LoRA adapters on a single GPU or across multiple GPUs with a small overhead. Compared to state-of-the-art libraries such as HuggingFace PEFT and vLLM (with naive support of LoRA serving), S-LoRA can improve the throughput by up to 4 times and increase the number of served adapters by several orders of magnitude. As a result, S-LoRA enables scalable serving of many task-specific fine-tuned models and offers the potential for large-scale customized fine-tuning services.

### SoRA
- https://github.com/TsinghuaC3I/SoRA
- https://arxiv.org/abs/2311.11696

Sparse Low-rank Adaptation of Pre-trained Language Models

Fine-tuning pre-trained large language models in a parameter-efficient manner is widely studied for its effectiveness and efficiency. The popular method of low-rank adaptation (LoRA) offers a notable approach, hypothesizing that the adaptation process is intrinsically low-dimensional. Although LoRA has demonstrated commendable performance, it is implemented with a fixed and unalterable intrinsic rank that might not always be the ideal choice. Recognizing the need for more flexible adaptation, we extend the methodology of LoRA to an innovative approach we call sparse low-rank adaptation (SoRA) that enables dynamic adjustments to the intrinsic rank during the adaptation process. We achieve this through the incorporation of a gate unit optimized with proximal gradient method in the training stage, controlling the cardinality of rank under the sparsity of the gate. In the subsequent inference stage, we eliminate the parameter blocks corresponding to the zeroed-out ranks, to reduce each SoRA module back to a concise yet rank-optimal LoRA. Our approach strengthens the representation power of LoRA by initializing it with a higher rank, while efficiently taming a temporarily increased number of parameters via updating in a sparse way. We further introduce a sparsifying scheduler for SoRA, aiming to examine the impact of the number of non-zero parameters on the model's memorization and generalization. Our experimental results demonstrate that SoRA can outperform other baselines even with 70% retained parameters and 70% training time.

### XuanCe(ç„ç­–): å¼€æºçš„æ·±åº¦å¼ºåŒ–å­¦ä¹ (DRL)åº“
- https://github.com/agi-brain/xuance

XuanCe is an open-source ensemble of Deep Reinforcement Learning (DRL) algorithm implementations.

We call it as Xuan-Ce (ç„ç­–) in Chinese. "Xuan (ç„)" means incredible and magic box, "Ce (ç­–)" means policy.

DRL algorithms are sensitive to hyper-parameters tuning, varying in performance with different tricks, and suffering from unstable training processes, therefore, sometimes DRL algorithms seems elusive and "Xuan". This project gives a thorough, high-quality and easy-to-understand implementation of DRL algorithms, and hope this implementation can give a hint on the magics of reinforcement learning.

We expect it to be compatible with multiple deep learning toolboxes( PyTorch, TensorFlow, and MindSpore), and hope it can really become a zoo full of DRL algorithms.

### EasyLMï¼ˆJAX/Flaxï¼‰
- https://github.com/hamishivi/EasyLM

Large language models (LLMs) made easy, EasyLM is a one stop solution for pre-training, finetuning, evaluating and serving LLMs in JAX/Flax. EasyLM can scale up LLM training to hundreds of TPU/GPU accelerators by leveraging JAX's pjit functionality.

Building on top of Hugginface's transformers and datasets, this repo provides an easy to use and easy to customize codebase for training large language models without the complexity in many other frameworks.

EasyLM is built with JAX/Flax. By leveraging JAX's pjit utility, EasyLM is able to train large models that don't fit on a single accelerator by sharding the model weights and training data across multiple accelerators. Currently, EasyLM supports multiple TPU/GPU training in a single host as well as multi-host training on Google Cloud TPU Pods.

### FATE-LLM - Federated Learning for LLMs
- https://github.com/FederatedAI/FATE-LLM

ATE-LLM is a framework to support federated learning for large language models(LLMs).

### DeepSpeed-FastGen
- https://github.com/microsoft/DeepSpeed/blob/master/blogs/deepspeed-fastgen/README.md

Large language models (LLMs) like GPT-4 and LLaMA have emerged as a dominant workload in serving a wide range of applications infused with AI at every level. From general chat models to document summarization, and from autonomous driving to copilots at every layer of the software stack, the demand to deploy and serve these models at scale has skyrocketed. While frameworks like DeepSpeed, PyTorch, and several others can regularly achieve good hardware utilization during LLM training, the interactive nature of these applications and the poor arithmetic intensity of tasks like open-ended text generation have become the bottleneck for inference throughput in existing systems.

To this end, frameworks like vLLM powered by PagedAttention and research systems like Orca have significantly improved the performance of inference for LLMs. However, these systems still struggle to provide consistent quality of service, particularly for workloads with longer prompts. These long prompt workloads are becoming increasingly important as more and more models, like MPT-StoryWriter, and systems, such as DeepSpeed Ulysses, support context windows stretching to tens of thousands of tokens. To better understand the problem space, we provide detailed examples of how text generation works for LLMs in two distinct phases called prompt processing and generation. When systems treat them as distinct phases, generation will be preempted by prompt processing that risks breaking the service level agreements (SLAs).

Today, we are glad to present DeepSpeed-FastGen, a system that overcomes these limitations by leveraging the proposed Dynamic SplitFuse technique and offers up to 2.3x higher effective throughput compared to state-of-the-art systems like vLLM. DeepSpeed-FastGen leverages the combination of DeepSpeed-MII and DeepSpeed-Inference to provide an easy-to-use serving system.

### NVIDIA NeMo-Aligner
- https://github.com/NVIDIA/NeMo-Aligner

NeMo-Aligner is a scalable toolkit for efficient model alignment. The toolkit has support for state of the art model alignment algorithms such as SteerLM, DPO and Reinforcement Learning from Human Feedback (RLHF). These algorithms enable users to align language models to be more safe, harmless and helpful. Users can do end-to-end model alignment on a wide range of model sizes and take advantage of all the parallelism techniques to ensure their model alignment is done in a performant and resource efficient manner.

NeMo-Aligner toolkit is built using the NeMo Toolkit which allows for scaling training up to 1000s of GPUs using tensor, data and pipeline parallelism for all components of alignment. All of our checkpoints are cross compatible with the NeMo ecosystem; allowing for inference deployment and further customization.

The toolkit is currently in it's early stages, and we are committed to improving the toolkit to make it easier for developers to pick and choose different alignment algorithms to build safe, helpful and reliable models.

### RLAIF: Scaling Reinforcement Learning from Human Feedback with AI Feedback
- https://arxiv.org/abs/2309.00267

Reinforcement learning from human feedback (RLHF) has proven effective in aligning large language models (LLMs) with human preferences. However, gathering high-quality human preference labels can be a time-consuming and expensive endeavor. RL from AI Feedback (RLAIF), introduced by Bai et al., offers a promising alternative that leverages a powerful off-the-shelf LLM to generate preferences in lieu of human annotators. Across the tasks of summarization, helpful dialogue generation, and harmless dialogue generation, RLAIF achieves comparable or superior performance to RLHF, as rated by human evaluators. Furthermore, RLAIF demonstrates the ability to outperform a supervised fine-tuned baseline even when the LLM preference labeler is the same size as the policy. In another experiment, directly prompting the LLM for reward scores achieves superior performance to the canonical RLAIF setup, where LLM preference labels are first distilled into a reward model. Finally, we conduct extensive studies on techniques for generating aligned AI preferences. Our results suggest that RLAIF can achieve human-level performance, offering a potential solution to the scalability limitations of RLHF.

### MLX
- https://github.com/ml-explore/mlx

MLX is designed by machine learning researchers for machine learning researchers. The framework is intended to be user-friendly, but still efficient to train and deploy models. The design of the framework itself is also conceptually simple. We intend to make it easy for researchers to extend and improve MLX with the goal of quickly exploring new ideas.

### OpenRLHF
- https://github.com/OpenLLMAI/OpenRLHF

OpenRLHF is a high-performance RLHF framework built on Ray, DeepSpeed and HuggingFace Transformers:
- Simple and easy to use: OpenRLHF is one of the simplest high-performance RLHF libraries currently available, enabling 34B model RLHF training with just a single DGXA100 node (see the training script).
- Distributed RLHF: The key idea behind OpenRLHF is to distribute the Actor, Reward, Reference, and Critic models onto separate GPUs using Ray, while placing the Adam optimizer on the CPU. This enables full-scale fine-tuning of 7B models across multiple 24GB RTX 4090 GPUs (or 34B models with multiple A100 80G GPUs).
- High performance: Thanks to the ability to use a large inference batch size with Ray and DeepSpeed's CPUAdam, the performance of OpenRLHF with the 13B LLaMA2 model is 4x that of DeepSpeedChat.

### CoLLiE: Collaborative Training of Large Language Models in an Efficient Way
- https://github.com/OpenLMLab/collie
- https://arxiv.org/abs/2312.00407

CoLLiEæ˜¯ä¸€ä¸ªå¯ä»¥å¸®åŠ©æ‚¨ä»é›¶å¼€å§‹è®­ç»ƒå¤§æ¨¡å‹çš„å®Œæ•´å·¥å…·ç®±ï¼Œå®ƒæä¾›äº†æ•°æ®é¢„å¤„ç†ã€æ¨¡å‹å¾®è°ƒã€æ¨¡å‹ä¿å­˜ä»¥åŠè®­ç»ƒè¿‡ç¨‹å„é¡¹æŒ‡æ ‡ç›‘æµ‹ç­‰åŠŸèƒ½ã€‚CoLLiEé›†æˆäº†ç°æœ‰çš„å¹¶è¡Œç­–ç•¥ã€é«˜æ•ˆå‚æ•°å¾®è°ƒæ–¹æ³•å’Œé«˜æ•ˆä¼˜åŒ–å™¨ï¼Œä»¥åŠ å¿«è®­ç»ƒçš„é€Ÿåº¦ï¼Œæé«˜è®­ç»ƒçš„è´¨é‡ï¼Œé™ä½è®­ç»ƒçš„å¼€é”€ã€‚CoLLiEæ”¯æŒä¸»æµçš„å¤šç§æ¨¡å‹ï¼ˆå¦‚MOSS, InternLM, LLaMA, ChatGLMç­‰ï¼‰ï¼Œæ‚¨å¯ä»¥è½»æ¾åœ¨ä¸åŒçš„æ¨¡å‹ä¹‹é—´åˆ‡æ¢ã€‚æ­¤å¤–ï¼ŒCoLLiEæä¾›äº†ä¸°å¯Œçš„æ–‡æ¡£ï¼Œä½¿åˆå­¦è€…å¯ä»¥å¿«é€Ÿå…¥é—¨ã€‚åŒæ—¶ï¼ŒCoLLiEè¿˜æä¾›äº†é«˜åº¦å¯å®šåˆ¶åŒ–çš„åŠŸèƒ½å’Œçµæ´»çš„é…ç½®é€‰é¡¹ï¼Œä½¿æœ‰ç»éªŒçš„ç”¨æˆ·èƒ½å¤Ÿæ ¹æ®è‡ªå·±çš„éœ€æ±‚è¿›è¡Œä¸ªæ€§åŒ–å®šåˆ¶ã€‚æ— è®ºæ‚¨æ˜¯åˆå­¦è€…è¿˜æ˜¯æœ‰ç»éªŒçš„ä¸“ä¸šäººå£«ï¼ŒCoLLiEéƒ½å¯ä»¥ä¸ºæ‚¨æä¾›æ»¡è¶³éœ€æ±‚çš„è§£å†³æ–¹æ¡ˆã€‚

### Superalignment
- https://github.com/openai/weak-to-strong
- https://cdn.openai.com/papers/weak-to-strong-generalization.pdf
- https://openai.com/research/weak-to-strong-generalization

A core challenge for aligning future superhuman AI systems (superalignment) is that humans will need to supervise AI systems much smarter than them. We study a simple analogy: can small models supervise large models? We show that we can use a GPT-2-level model to elicit most of GPT-4â€™s capabilitiesâ€”close to GPT-3.5-level performanceâ€”generalizing correctly even to hard problems where the small model failed. This opens up a new research direction that allows us to directly tackle a central challenge of aligning future superhuman models while making iterative empirical progress today.

### LLMLingua: Compressing Prompts for Accelerated Inference of Large Language Models
- https://aka.ms/LLMLingua
- https://github.com/microsoft/LLMLingua
- https://huggingface.co/spaces/microsoft/LLMLingua
- https://arxiv.org/abs/2310.05736

Large language models (LLMs) have been applied in various applications due to their astonishing capabilities. With advancements in technologies such as chain-of-thought (CoT) prompting and in-context learning (ICL), the prompts fed to LLMs are becoming increasingly lengthy, even exceeding tens of thousands of tokens. To accelerate model inference and reduce cost, this paper presents LLMLingua, a coarse-to-fine prompt compression method that involves a budget controller to maintain semantic integrity under high compression ratios, a token-level iterative compression algorithm to better model the interdependence between compressed contents, and an instruction tuning based method for distribution alignment between language models. We conduct experiments and analysis over four datasets from different scenarios, i.e., GSM8K, BBH, ShareGPT, and Arxiv-March23; showing that the proposed approach yields state-of-the-art performance and allows for up to 20x compression with little performance loss. 

### Large Language Model Unlearning
- https://arxiv.org/abs/2310.10683
- https://github.com/kevinyaobytedance/llm_unlearn

We study how to perform unlearning, i.e. forgetting undesirable (mis)behaviors, on large language models (LLMs). We show at least three scenarios of aligning LLMs with human preferences can benefit from unlearning: (1) removing harmful responses, (2) erasing copyright-protected content as requested, and (3) eliminating hallucinations. Unlearning, as an alignment technique, has three advantages. (1) It only requires negative (e.g. harmful) examples, which are much easier and cheaper to collect (e.g. via red teaming or user reporting) than positive (e.g. helpful and often human-written) examples required in RLHF (RL from human feedback). (2) It is computationally efficient. (3) It is especially effective when we know which training samples cause the misbehavior. To the best of our knowledge, our work is among the first to explore LLM unlearning. We are also among the first to formulate the settings, goals, and evaluations in LLM unlearning. We show that if practitioners only have limited resources, and therefore the priority is to stop generating undesirable outputs rather than to try to generate desirable outputs, unlearning is particularly appealing. Despite only having negative samples, our ablation study shows that unlearning can still achieve better alignment performance than RLHF with just 2% of its computational time.

### PowerInfer
- https://github.com/SJTU-IPADS/PowerInfer
- https://ipads.se.sjtu.edu.cn/_media/publications/powerinfer-20231219.pdf

PowerInfer is a CPU/GPU LLM inference engine leveraging activation locality for your device.

We introduce PowerInfer, a high-speed Large Language Model (LLM) inference engine on a personal computer (PC) equipped with a single consumer-grade GPU. The key underlying the design of PowerInfer is exploiting the high locality inherent in LLM inference, characterized by a power-law distribution in neuron activation.

This distribution indicates that a small subset of neurons, termed hot neurons, are consistently activated across inputs, while the majority, cold neurons, vary based on specific inputs. PowerInfer exploits such an insight to design a GPU-CPU hybrid inference engine: hot-activated neurons are preloaded onto the GPU for fast access, while cold-activated neurons are computed on the CPU, thus significantly reducing GPU memory demands and CPU-GPU data transfers. PowerInfer further integrates adaptive predictors and neuron-aware sparse operators, optimizing the efficiency of neuron activation and computational sparsity.

Evaluation shows that PowerInfer attains an average token generation rate of 13.20 tokens/s, with a peak of 29.08 tokens/s, across various LLMs (including OPT-175B) on a single NVIDIA RTX 4090 GPU, only 18% lower than that achieved by a top-tier server-grade A100 GPU. This significantly outperforms llama.cpp by up to 11.69x while retaining model accuracy.

### m-LoRA
- https://arxiv.org/abs/2312.02515
- https://github.com/TUDB-Labs/multi-lora-fine-tune

m-LoRA (a.k.a Multi-Lora Fine-Tune) is an open-source framework for fine-tuning Large Language Models (LLMs) using the efficient multiple LoRA/QLoRA methods. Key features of m-LoRA include:
- Efficient LoRA/QLoRA: Optimizes the fine-tuning process, significantly reducing GPU memory usage by leveraging a shared frozen-based model.
- Multiple LoRA Adapters: Support for concurrent fine-tuning of multiple LoRA/QLoRA adapters.

### LASER
- https://github.com/pratyushasharma/laser
- https://pratyushasharma.github.io/laser/
- https://arxiv.org/pdf/2312.13558.pdf

LASER stands for LAyer SElective Rank-Reduction, and is an intervention where we replace a selected weight matrix in the transformer architecture of an LLM with its low-rank approximation. A single LASER transformation consists of 3 hyperparameters: the layer number to modify (â„“) such as 16th layer, the parameter type (Ï„) such as the first MLP layer, and the fraction of the maximum rank to retain (Ï) such as 0.01 fraction of the rank. We can write this transformation as (â„“, Ï„, Ï) and we can stack these transformations and apply them in parallel. The low-rank approximation is performed using SVD. Figure below from our paper shows an illustration.

### StripedHyena-7B
- https://github.com/togethercomputer/stripedhyena
- https://www.together.ai/blog/stripedhyena-7b

One of the focus areas at Together Research is new architectures for long context, improved training, and inference performance over the Transformer architecture. Spinning out of a research program from our team and academic collaborators, with roots in signal processing-inspired sequence models, we are excited to introduce the StripedHyena models.

StripedHyena is the first alternative model competitive with the best open-source Transformers of similar sizes in short and long-context evaluations.

StripedHyena-Nous-7B (SH-N 7B) is our chat model for this release, and was developed with our collaborators at Nous Research.

### SwiftInfer
- https://github.com/hpcaitech/SwiftInfer

Colossal-AI å›¢é˜Ÿå¼€æºäº† SwiftInferï¼ŒåŸºäº TensorRT å®ç°äº† StreamingLLMï¼Œå¯ä»¥è¿›ä¸€æ­¥æå‡å¤§æ¨¡å‹æ¨ç†æ€§èƒ½ 46%ï¼Œä¸ºå¤šè½®å¯¹è¯æ¨ç†æä¾›äº†é«˜æ•ˆå¯é çš„è½åœ°æ–¹æ¡ˆã€‚

### SPINï¼ˆSelf-Play Fine-Tuning Converts Weak Language Models to Strong Language Modelsï¼‰
- hhttps://arxiv.org/abs/2401.01335

Harnessing the power of human-annotated data through Supervised Fine-Tuning (SFT) is pivotal for advancing Large Language Models (LLMs). In this paper, we delve into the prospect of growing a strong LLM out of a weak one without the need for acquiring additional human-annotated data. We propose a new fine-tuning method called Self-Play fIne-tuNing (SPIN), which starts from a supervised fine-tuned model. At the heart of SPIN lies a self-play mechanism, where the LLM refines its capability by playing against instances of itself. More specifically, the LLM generates its own training data from its previous iterations, refining its policy by discerning these self-generated responses from those obtained from human-annotated data. Our method progressively elevates the LLM from a nascent model to a formidable one, unlocking the full potential of human-annotated demonstration data for SFT. Theoretically, we prove that the global optimum to the training objective function of our method is achieved only when the LLM policy aligns with the target data distribution. Empirically, we evaluate our method on several benchmark datasets including the HuggingFace Open LLM Leaderboard, MT-Bench, and datasets from Big-Bench. Our results show that SPIN can significantly improve the LLM's performance across a variety of benchmarks and even outperform models trained through direct preference optimization (DPO) supplemented with extra GPT-4 preference data. This sheds light on the promise of self-play, enabling the achievement of human-level performance in LLMs without the need for expert opponents.

### Self-Rewarding Language Models
- https://arxiv.org/pdf/2401.10020.pdf

We posit that to achieve superhuman agents, future models require superhuman feedback in order to provide an adequate training signal. Current approaches commonly train reward models from human preferences, which may then be bottlenecked by human performance level, and secondly these separate frozen reward models cannot then learn to improve during LLM training. In this work, we study Self-Rewarding Language Models, where the language model itself is used via LLM-as-a-Judge prompting to provide its own rewards during training. We show that during Iterative DPO training that not only does instruction following ability improve, but also the ability to provide high-quality rewards to itself. Fine-tuning Llama 2 70B on three iterations of our approach yields a model that outperforms many existing systems on the AlpacaEval 2.0 leaderboard, including Claude 2, Gemini Pro, and GPT-4 0613. While only a preliminary study, this work opens the door to the possibility of models that can continually improve in both axes.

### OPOï¼ˆOn-the-fly Preference Optimizationï¼‰
- https://arxiv.org/abs/2312.15907
- https://gair-nlp.github.io/OPO/
- https://github.com/GAIR-NLP/OPO

In this paper, we aim to align large language models with the ever-changing, complex, and diverse human values (e.g., social norms) across time and locations. This presents a challenge to existing alignment techniques, such as supervised fine-tuning, which internalize values within model parameters. To overcome this, we propose an On-the-fly Preference Optimization (OPO) method, which is a real-time alignment that works in a streaming way. It employs an external memory to store established rules for alignment, which can constrain LLMs' behaviors without further training, allowing for convenient updates and customization of human values. We also introduce a scalable evaluation to assess the proposed method more effectively. Experimental results on both human-annotated and auto-generated questions from legal and moral domains indicate the effectiveness of the proposed OPO method. 

### ASPIRE
- https://aclanthology.org/2023.findings-emnlp.345.pdf

Large language models (LLMs) have recently shown great advances in a variety of tasks, including natural language understanding and generation. However, their use in high-stakes decision-making scenarios is still limited due to the potential for errors. Selective prediction is a technique that can be used to improve the reliability of the LLMs by allowing them to abstain from making predictions when they are unsure of the answer. In this work, we propose a novel framework for adaptation with self-evaluation to improve the selective prediction performance of LLMs. Our framework is based on the idea of using parameter-efficient tuning to adapt the LLM to the specific task at hand while improving its ability to perform self-evaluation. We evaluate our method on a variety of question-answering (QA) datasets and show that it outperforms state-of-the-art selective prediction methods. For example, on the CoQA benchmark, our method improves the AUACC from 91.23% to 92.63% and improves the AUROC from 74.61% to 80.25%.

### The Impact of Reasoning Step Length on Large Language Models
- https://arxiv.org/abs/2401.04925
- https://github.com/jmyissb/The-Impact-of-Reasoning-Step-Length-on-Large-Language-Models

Chain of Thought (CoT) is significant in improving the reasoning abilities of large language models (LLMs). However, the correlation between the effectiveness of CoT and the length of reasoning steps in prompts remains largely unknown. To shed light on this, we have conducted several empirical experiments to explore the relations. Specifically, we design experiments that expand and compress the rationale reasoning steps within CoT demonstrations, while keeping all other factors constant. We have the following key findings. First, the results indicate that lengthening the reasoning steps in prompts, even without adding new information into the prompt, considerably enhances LLMs' reasoning abilities across multiple datasets. Alternatively, shortening the reasoning steps, even while preserving the key information, significantly diminishes the reasoning abilities of models. This finding highlights the importance of the number of steps in CoT prompts and provides practical guidance to make better use of LLMs' potential in complex problem-solving scenarios. Second, we also investigated the relationship between the performance of CoT and the rationales used in demonstrations. Surprisingly, the result shows that even incorrect rationales can yield favorable outcomes if they maintain the requisite length of inference. Third, we observed that the advantages of increasing reasoning steps are task-dependent: simpler tasks require fewer steps, whereas complex tasks gain significantly from longer inference sequences.

### SliceGPT
- https://arxiv.org/abs/2401.15024
- https://github.com/microsoft/TransformerCompression

SliceGPT is a new post-training sparsification scheme that makes transformer networks (including LLMs) smaller by first applying orthogonal transformations to each transformer layer that leave the model unchanged, and then slicing off the least-significant rows and columns (chosen by the eigenvalue decay) of the weight matrices. The model structure is left unchanged, but each weight matrix is replaced by a smaller (dense) weight matrix, reducing the embedding dimension of the model. This results in speedups (without any additional code optimization) and a reduced memory footprint.

### FuseLLM
- https://github.com/fanqiwan/FuseLLM
- https://arxiv.org/abs/2401.10491

While training large language models (LLMs) from scratch can generate models with distinct functionalities and strengths, it comes at significant costs and may result in redundant capabilities. Alternatively, a cost-effective and compelling approach is to merge existing pre-trained LLMs into a more potent model. However, due to the varying architectures of these LLMs, directly blending their weights is impractical. In this paper, we introduce the notion of knowledge fusion for LLMs, aimed at combining the capabilities of existing LLMs and transferring them into a single LLM. By leveraging the generative distributions of source LLMs, we externalize their collective knowledge and unique strengths, thereby potentially elevating the capabilities of the target model beyond those of any individual source LLM. We validate our approach using three popular LLMs with different architectures--Llama-2, MPT, and OpenLLaMA--across various benchmarks and tasks. Our findings confirm that the fusion of LLMs can improve the performance of the target model across a range of capabilities such as reasoning, commonsense, and code generation.

### Tree of Thoughts
- https://arxiv.org/abs/2305.10601
- https://github.com/princeton-nlp/tree-of-thought-llm

Language models are increasingly being deployed for general problem solving across a wide range of tasks, but are still confined to token-level, left-to-right decision-making processes during inference. This means they can fall short in tasks that require exploration, strategic lookahead, or where initial decisions play a pivotal role. To surmount these challenges, we introduce a new framework for language model inference, Tree of Thoughts (ToT), which generalizes over the popular Chain of Thought approach to prompting language models, and enables exploration over coherent units of text (thoughts) that serve as intermediate steps toward problem solving. ToT allows LMs to perform deliberate decision making by considering multiple different reasoning paths and self-evaluating choices to decide the next course of action, as well as looking ahead or backtracking when necessary to make global choices. Our experiments show that ToT significantly enhances language models' problem-solving abilities on three novel tasks requiring non-trivial planning or search: Game of 24, Creative Writing, and Mini Crosswords. For instance, in Game of 24, while GPT-4 with chain-of-thought prompting only solved 4% of tasks, our method achieved a success rate of 74%.

### CogGPT
- https://github.com/KwaiKEG/CogGPT
- https://arxiv.org/abs/2401.08438

Cognitive dynamics are pivotal to advance human understanding of the world. Recent advancements in large language models (LLMs) reveal their potential for cognitive simulation. However, these LLM-based cognitive studies primarily focus on static modeling, overlooking the dynamic nature of cognition. To bridge this gap, we propose the concept of the cognitive dynamics of LLMs and present a corresponding task with the inspiration of longitudinal studies. Towards the task, we develop CogBench, a novel benchmark to assess the cognitive dynamics of LLMs and validate it through participant surveys. We also design two evaluation metrics for CogBench, including Authenticity and Rationality. Recognizing the inherent static nature of LLMs, we introduce CogGPT for the task, which features an innovative iterative cognitive mechanism aimed at enhancing lifelong cognitive dynamics. Empirical results demonstrate the superiority of CogGPT over existing methods, particularly in its ability to facilitate role-specific cognitive dynamics under continuous information flows.

### KTOï¼ˆKahneman-Tversky Optimisationï¼‰
- https://github.com/ContextualAI/HALOs/blob/main/assets/report.pdf
- https://github.com/ContextualAI/HALOs

This repo draws from the excellently written DPO repo and has preserved many design choices from the original. Some of the key changes we introduced are:

- making data loading more modular, so that you can easily write your own dataloader
- making trainers more modular, so that each HALO has its own trainer subclass
- adding code for doing open-ended evaluation with GPT-4 as a judge
- supporting losses beyond SFT and DPO (including KTO, PPO (offline, off-policy variant), and SLiC)

### Aligner
- https://aligner2024.github.io
- https://arxiv.org/abs/2402.02416

Efforts to align Large Language Models (LLMs) are mainly conducted via Reinforcement Learning from Human Feedback (RLHF) methods. However, RLHF encounters major challenges including training reward models, actor-critic engineering, and importantly, it requires access to LLM parameters. Here we introduce Aligner, a new efficient alignment paradigm that bypasses the whole RLHF process by learning the correctional residuals between the aligned and the unaligned answers. Our Aligner offers several key advantages. Firstly, it is an autoregressive seq2seq model that is trained on the query-answer-correction dataset via supervised learning; this offers a parameter-efficient alignment solution with minimal resources. Secondly, the Aligner facilitates weak-to-strong generalization; finetuning large pretrained models by Aligner's supervisory signals demonstrates strong performance boost. Thirdly, Aligner functions as a model-agnostic plug-and-play module, allowing for its direct application on different open-source and API-based models. Remarkably, Aligner-7B improves 11 different LLMs by 21.9% in helpfulness and 23.8% in harmlessness on average (GPT-4 by 17.5% and 26.9%). When finetuning (strong) Llama2-70B with (weak) Aligner-13B's supervision, we can improve Llama2 by 8.2% in helpfulness and 61.6% in harmlessness. 

### RPOï¼ˆRobust Prompt Optimizationï¼‰
- https://arxiv.org/abs/2401.17263

Despite advances in AI alignment, language models (LM) remain vulnerable to adversarial attacks or jailbreaking, in which adversaries modify input prompts to induce harmful behavior. While some defenses have been proposed, they focus on narrow threat models and fall short of a strong defense, which we posit should be effective, universal, and practical. To achieve this, we propose the first adversarial objective for defending LMs against jailbreaking attacks and an algorithm, robust prompt optimization (RPO), that uses gradient-based token optimization to enforce harmless outputs. This results in an easily accessible suffix that significantly improves robustness to both jailbreaks seen during optimization and unknown, held-out jailbreaks, reducing the attack success rate on Starling-7B from 84% to 8.66% across 20 jailbreaks. In addition, we find that RPO has a minor effect on benign use, is successful under adaptive attacks, and can transfer to black-box models, reducing the success rate of the strongest attack on GPT-4, GUARD, from 92% to 6%.

### Inference-Time Training Helps Long Text Generation
- https://arxiv.org/abs/2401.11504
- https://github.com/TemporaryLoRA/Temp-LoRA/tree/main

Long text generation, such as novel writing or discourse-level translation with extremely long contexts, presents significant challenges to current language models. Existing methods mainly focus on extending the model's context window through strategies like length extrapolation. However, these approaches demand substantial hardware resources during the training and/or inference phases. Our proposed method, Temp-Lora, introduces an alternative concept. Instead of relying on the KV cache to store all context information, Temp-Lora embeds this information directly into the model's parameters. In the process of long text generation, we use a temporary Lora module, progressively trained with text generated previously. This approach not only efficiently preserves contextual knowledge but also prevents any permanent alteration to the model's parameters given that the module is discarded post-generation. Extensive experiments on the PG19 language modeling benchmark and the GuoFeng discourse-level translation benchmark validate the effectiveness of Temp-Lora. Our results show that: 1) Temp-Lora substantially enhances generation quality for long texts, as indicated by a 13.2% decrease in perplexity on a subset of PG19, and a 29.6% decrease in perplexity along with a 53.2% increase in BLEU score on GuoFeng, 2) Temp-Lora is compatible with and enhances most existing long text generation methods, and 3) Temp-Lora can greatly reduce computational costs by shortening the context window. While ensuring a slight improvement in generation quality (a decrease of 3.8% in PPL), it enables a reduction of 70.5% in the FLOPs required for inference and a 51.5% decrease in latency.

### LiPO
- https://arxiv.org/abs/2402.01878

Aligning language models (LMs) with curated human feedback is critical to control their behaviors in real-world applications. Several recent policy optimization methods, such as DPO and SLiC, serve as promising alternatives to the traditional Reinforcement Learning from Human Feedback (RLHF) approach. In practice, human feedback often comes in a format of a ranked list over multiple responses to amortize the cost of reading prompt. Multiple responses can also be ranked by reward models or AI feedback. There lacks such a study on directly fitting upon a list of responses. In this work, we formulate the LM alignment as a listwise ranking problem and describe the Listwise Preference Optimization (LiPO) framework, where the policy can potentially learn more effectively from a ranked list of plausible responses given the prompt. This view draws an explicit connection to Learning-to-Rank (LTR), where most existing preference optimization work can be mapped to existing ranking objectives, especially pairwise ones. Following this connection, we provide an examination of ranking objectives that are not well studied for LM alignment withDPO and SLiC as special cases when list size is two. In particular, we highlight a specific method, LiPO-{\lambda}, which leverages a state-of-the-art listwise ranking objective and weights each preference pair in a more advanced manner. We show that LiPO-{\lambda} can outperform DPO and SLiC by a clear margin on two preference alignment tasks.

### ChatLLM.cpp
- https://github.com/foldl/chatllm.cpp

Inference of a bunch of models from less than 3B to more than 45B, for real-time chatting on your computer (CPU), pure C++ implementation based on @ggerganov's ggml.

### Self-Discover
- https://arxiv.org/abs/2402.03620

We introduce SELF-DISCOVER, a general framework for LLMs to self-discover the task-intrinsic reasoning structures to tackle complex reasoning problems that are challenging for typical prompting methods. Core to the framework is a self-discovery process where LLMs select multiple atomic reasoning modules such as critical thinking and step-by-step thinking, and compose them into an explicit reasoning structure for LLMs to follow during decoding. SELF-DISCOVER substantially improves GPT-4 and PaLM 2's performance on challenging reasoning benchmarks such as BigBench-Hard, grounded agent reasoning, and MATH, by as much as 32% compared to Chain of Thought (CoT). Furthermore, SELF-DISCOVER outperforms inference-intensive methods such as CoT-Self-Consistency by more than 20%, while requiring 10-40x fewer inference compute. Finally, we show that the self-discovered reasoning structures are universally applicable across model families: from PaLM 2-L to GPT-4, and from GPT-4 to Llama2, and share commonalities with human reasoning patterns.

### DoRA
- https://arxiv.org/abs/2402.09353
- https://github.com/catid/dora

Among the widely used parameter-efficient finetuning (PEFT) methods, LoRA and its variants have gained considerable popularity because of avoiding additional inference costs. However, there still often exists an accuracy gap between these methods and full fine-tuning (FT). In this work, we first introduce a novel weight decomposition analysis to investigate the inherent differences between FT and LoRA. Aiming to resemble the learning capacity of FT from the findings, we propose Weight-Decomposed LowRank Adaptation (DoRA). DoRA decomposes the pre-trained weight into two components, magnitude and direction, for fine-tuning, specifically employing LoRA for directional updates to efficiently minimize the number of trainable parameters. By employing DoRA, we enhance both the learning capacity and training stability of LoRA while avoiding any additional inference overhead. DoRA consistently outperforms LoRA on fine-tuning LLaMA, LLaVA, and VL-BART on various downstream tasks, such as commonsense reasoning, visual instruction tuning, and image/video-text understanding.

### GPOï¼ˆGeneralized Preference Optimizationï¼‰
- https://arxiv.org/abs/2402.05749

Offline preference optimization allows fine-tuning large models directly from offline data, and has proved effective in recent alignment practices. We propose generalized preference optimization (GPO), a family of offline losses parameterized by a general class of convex functions. GPO enables a unified view over preference optimization, encompassing existing algorithms such as DPO, IPO and SLiC as special cases, while naturally introducing new variants. The GPO framework also sheds light on how offline algorithms enforce regularization, through the design of the convex function that defines the loss. Our analysis and experiments reveal the connections and subtle differences between the offline regularization and the KL divergence regularization intended by the canonical RLHF formulation. In all, our results present new algorithmic toolkits and empirical insights to alignment practitioners.

### CoT-decoding
- https://arxiv.org/abs/2402.10200

In enhancing the reasoning capabilities of large language models (LLMs), prior research primarily focuses on specific prompting techniques such as few-shot or zero-shot chain-of-thought (CoT) prompting. These methods, while effective, often involve manually intensive prompt engineering. Our study takes a novel approach by asking: Can LLMs reason effectively without prompting? Our findings reveal that, intriguingly, CoT reasoning paths can be elicited from pre-trained LLMs by simply altering the \textit{decoding} process. Rather than conventional greedy decoding, we investigate the top-k alternative tokens, uncovering that CoT paths are frequently inherent in these sequences. This approach not only bypasses the confounders of prompting but also allows us to assess the LLMs' \textit{intrinsic} reasoning abilities. Moreover, we observe that the presence of a CoT in the decoding path correlates with a higher confidence in the model's decoded answer. This confidence metric effectively differentiates between CoT and non-CoT paths. Extensive empirical studies on various reasoning benchmarks show that the proposed CoT-decoding substantially outperforms the standard greedy decoding.

### llama2.mojo
- https://mp.weixin.qq.com/s/NpIUReKV-9hb05HXzu7Pdg
- https://github.com/tairov/llama2.mojo

This repository serves as a port that provides a Mojo-based implementation of llama2.c.

With the release of Mojo, I was inspired to take my Python port of llama2.py and transition it to Mojo. The result? A version that leverages Mojo's SIMD & vectorization primitives, boosting the Python performance by nearly 250x. Impressively, the Mojo version now outperforms the original llama2.c, even in runfast mode, by 15-20%. This showcases the potential of hardware-level optimizations through Mojo's advanced features. I think this also can help us to see how far can we go with the original llama2.c hardware optimizations.

### LightLLM
- https://github.com/ModelTC/lightllm

LightLLM is a Python-based LLM (Large Language Model) inference and serving framework, notable for its lightweight design, easy scalability, and high-speed performance. LightLLM harnesses the strengths of numerous well-regarded open-source implementations, including but not limited to FasterTransformer, TGI, vLLM, and FlashAttention.

**Features**
- Tri-process asynchronous collaboration: tokenization, model inference, and detokenization are performed asynchronously, leading to a considerable improvement in GPU utilization.
- Nopad (Unpad): offers support for nopad attention operations across multiple models to efficiently handle requests with large length disparities.
- Dynamic Batch: enables dynamic batch scheduling of requests
- FlashAttention: incorporates FlashAttention to improve speed and reduce GPU memory footprint during inference.
- Tensor Parallelism: utilizes tensor parallelism over multiple GPUs for faster inference.
- Token Attention: implements token-wise's KV cache memory management mechanism, allowing for zero memory waste during inference.
- High-performance Router: collaborates with Token Attention to meticulously manage the GPU memory of each token, thereby optimizing system throughput.

### Megatron-LLaMA
- https://mp.weixin.qq.com/s/9yEWvqR5QtCPQVxJHw-wCA
- https://github.com/alibaba/Megatron-LLaMA

To facilitate the training of LLaMA-based models and reduce the cost on occupying hardware resources, Alibaba decides to release the internal optimized Megatron-LLaMA training framework to the community. Megatron-LLaMA makes the following contributions:

(i) A standard implementation of LLaMA in Megatron-LLaMA: It is easy to obtain the LLaMA code from Huggingface, which does not involve the various parallel methods provided by Megatron-LM. Megatron-LLaMA offers a standard implementation of LLaMA in Megatron-LM, allowing developers to configure the optimization techniques on demand. We will continue to release features such as Alibi and FlashAttention2 in the future.

(ii) Efficient communication-computation parallelism: Similar to DeepSpeed ZeRO Stage 2, Megatron-LM implements DistributedOptimizer that partitions the gradient and optimizer state, significantly reducing GPU memory usage. However, the solution provided by Megatron-LM does not fully overlap GPU computation with communication, resulting in underutilization of hardware resources. Building upon the original DistributedOptimizer and ZeRO-Stage-2, Megatron-LLaMA proposes a novel approach for gradient and optimizer state sharding, achieving the following benefits without compromising precision: a) extremely high parallelism between communication and computation; b) highly efficient utilization of communication bandwidth; c) lower GPU memory usage. Consequently, Megatron-LLaMA enables higher training throughput on the same hardware configuration than the vanilla Megatron-LM.

(iii) Utilities: Megatron-LLaMA supplements several utilities and improves the checkpoint mechanism in Megatron-LM, including: a) Distributed checkpoint saving/restoring to speedup. This also provides abstract filesystem interfaces for easily integrating distributed file systems such as HDFS; b) Convenient interface for weight conversion from/to the HuggingFace format, facilitating the delivery to the downstream tasks after pretraining; c) Support for Tokenizers in HuggingFace transformers library.

### MeZO: Fine-Tuning Language Models with Just Forward Passes
- https://github.com/princeton-nlp/MeZO
- https://arxiv.org/abs/2305.17333
- https://mp.weixin.qq.com/s/3RLCVQg2QJGSiDUtx9DgPg

This is the implementation for the paper Fine-Tuning Language Models with Just Forward Passes. In this paper we propose a memory-efficient zeroth-order optimizer (MeZO), adapting the classical zeroth-order SGD method to operate in-place, thereby fine-tuning language models (LMs) with the same memory footprint as inference.

With a single A100 80GB GPU, MeZO can train a 30-billion parameter OPT model, whereas fine-tuning with Adam can train only a 2.7B LM. MeZO demonstrates comparable performance to fine-tuning with backpropagation across multiple tasks, with up to 12Ã— memory reduction. MeZO is also compatible with both full-parameter and parameter-efficient tuning techniques such as LoRA and prefix tuning. We also show that MeZO can effectively optimize non-differentiable objectives (e.g., maximizing accuracy or F1).

### MLC LLM
- https://github.com/mlc-ai/mlc-llm

MLC LLM is a universal solution that allows any language models to be deployed natively on a diverse set of hardware backends and native applications, plus a productive framework for everyone to further optimize model performance for their own use cases.

Our mission is to enable everyone to develop, optimize and deploy AI models natively on everyone's devices.

Everything runs locally with no server support and accelerated with local GPUs on your phone and laptops. Supported platforms include:
- iPhone, iPad
- Metal GPUs and Intel/ARM MacBooks;
- AMD, Intel and NVIDIA GPUs via Vulkan on Windows and Linux;
- NVIDIA GPUs via CUDA on Windows and Linux;
- WebGPU on browsers (through companion project WebLLM).

### PKU-Beaver æ²³ç‹¸ (Safe RLHF)
- https://github.com/PKU-Alignment/safe-rlhf
- https://mp.weixin.qq.com/s/ZpkgszXbisl5xf63EfTNjQ

åŒ—äº¬å¤§å­¦å›¢é˜Ÿå¼€æºäº†åä¸º PKU-Beaverï¼ˆæ²³ç‹¸ï¼‰é¡¹ç›®ï¼Œå…¶å¼€æºåœ°å€ä¸ºï¼šhttps://github.com/PKU-Alignment/safe-rlhfã€‚è¯¥é¡¹ç›®é¦–æ¬¡å…¬å¼€äº† RLHF æ‰€éœ€çš„æ•°æ®é›†ã€è®­ç»ƒå’ŒéªŒè¯ä»£ç ï¼Œæ˜¯ç›®å‰é¦–ä¸ªå¼€æºçš„å¯å¤ç°çš„ RLHF åŸºå‡†ã€‚åŒæ—¶ï¼Œä¸ºè§£å†³äººç±»æ ‡æ³¨äº§ç”Ÿçš„åè§å’Œæ­§è§†ç­‰ä¸å®‰å…¨å› ç´ ï¼ŒåŒ—äº¬å¤§å­¦å›¢é˜Ÿé¦–æ¬¡æå‡ºäº†å¸¦æœ‰çº¦æŸçš„ä»·å€¼å¯¹é½æŠ€æœ¯ CVAï¼ˆConstrained Value Alignmentï¼‰ã€‚è¯¥æŠ€æœ¯é€šè¿‡å¯¹æ ‡æ³¨ä¿¡æ¯è¿›è¡Œç»†ç²’åº¦åˆ’åˆ†ï¼Œå¹¶ç»“åˆå¸¦çº¦æŸçš„å®‰å…¨å¼ºåŒ–å­¦ä¹ æ–¹æ³•ï¼Œæ˜¾è‘—é™ä½äº†æ¨¡å‹çš„åè§å’Œæ­§è§†ï¼Œæé«˜äº†æ¨¡å‹çš„å®‰å…¨æ€§ã€‚Beaverä½¿ç”¨GPT4è¿›è¡ŒEvaluationï¼Œç»“æœè¡¨æ˜ï¼Œåœ¨åŸæœ‰æ€§èƒ½ä¿æŒä¸å˜çš„æƒ…å†µä¸‹ï¼ŒBeaverå›å¤çš„å®‰å…¨æ€§å¤§å¹…åº¦æå‡ã€‚

### PaLM + RLHF (Pytorch)
- https://github.com/lucidrains/PaLM-rlhf-pytorch

Implementation of RLHF (Reinforcement Learning with Human Feedback) on top of the PaLM architecture. Maybe I'll add retrieval functionality too, Ã  la RETRO

### RL4LMs
- https://github.com/allenai/RL4LMs
- https://rl4lms.apps.allenai.org/

A modular RL library to fine-tune language models to human preferences

We provide easily customizable building blocks for training language models including implementations of on-policy algorithms, reward functions, metrics, datasets and LM based actor-critic policies

### Reinforcement Learning with Language Model
- https://github.com/HarderThenHarder/transformers_tasks/tree/main/RLHF

åœ¨è¿™ä¸ªé¡¹ç›®ä¸­ï¼Œæˆ‘ä»¬å°†é€šè¿‡å¼€æºé¡¹ç›® trl æ­å»ºä¸€ä¸ªé€šè¿‡å¼ºåŒ–å­¦ä¹ ç®—æ³•ï¼ˆPPOï¼‰æ¥æ›´æ–°è¯­è¨€æ¨¡å‹ï¼ˆGPT-2ï¼‰çš„å‡ ä¸ªç¤ºä¾‹ï¼ŒåŒ…æ‹¬ï¼š
- åŸºäºä¸­æ–‡æƒ…æ„Ÿè¯†åˆ«æ¨¡å‹çš„æ­£å‘è¯„è®ºç”Ÿæˆæœºå™¨äººï¼ˆNo Human Rewardï¼‰
- åŸºäºäººå·¥æ‰“åˆ†çš„æ­£å‘è¯„è®ºç”Ÿæˆæœºå™¨äººï¼ˆWith Human Rewardï¼‰
- åŸºäºæ’åºåºåˆ—ï¼ˆRank Listï¼‰è®­ç»ƒä¸€ä¸ªå¥–åŠ±æ¨¡å‹ï¼ˆReward Modelï¼‰
- æ’åºåºåˆ—ï¼ˆRank Listï¼‰æ ‡æ³¨å¹³å°

### SpQR: A Sparse-Quantized Representation for Near-Lossless LLM Weight Compression
- https://github.com/Vahe1994/SpQR
- https://arxiv.org/pdf/2306.03078.pdf
- https://mp.weixin.qq.com/s/819L-dY54BaVM1vub9OSpQ

SpQR é€šè¿‡è¯†åˆ«å’Œéš”ç¦»å¼‚å¸¸æƒé‡æ¥å·¥ä½œï¼Œè¿™äº›å¼‚å¸¸æƒé‡ä¼šå¯¼è‡´ç‰¹åˆ«å¤§çš„é‡åŒ–è¯¯å·®ï¼Œç ”ç©¶è€…å°†å®ƒä»¬ä»¥æ›´é«˜çš„ç²¾åº¦å­˜å‚¨ï¼ŒåŒæ—¶å°†æ‰€æœ‰å…¶ä»–æƒé‡å‹ç¼©åˆ° 3-4 ä½ï¼Œåœ¨ LLaMA å’Œ Falcon LLMs ä¸­å®ç°äº†ä¸åˆ° 1% çš„å›°æƒ‘åº¦ç›¸å¯¹å‡†ç¡®ç‡æŸå¤±ã€‚ä»è€Œå¯ä»¥åœ¨å•ä¸ª 24GB çš„æ¶ˆè´¹çº§ GPU ä¸Šè¿è¡Œ 33B å‚æ•°çš„ LLMï¼Œè€Œä¸ä¼šæœ‰ä»»ä½•æ€§èƒ½ä¸‹é™ï¼ŒåŒæ—¶è¿˜èƒ½æé«˜ 15% çš„é€Ÿåº¦ã€‚

### Scikit-LLM: Sklearn Meets Large Language Models
- https://github.com/iryna-kondr/scikit-llm

Seamlessly integrate powerful language models like ChatGPT into scikit-learn for enhanced text analysis tasks.

### Transformer Reinforcement Learning
- https://github.com/lvwerra/trl

With trl you can train transformer language models with Proximal Policy Optimization (PPO). The library is built on top of the transformers library by ğŸ¤— Hugging Face. Therefore, pre-trained language models can be directly loaded via transformers. At this point most of decoder architectures and encoder-decoder architectures are supported.

### Train_Transformers_with_INT4
- https://mp.weixin.qq.com/s/pyEJJ5AvQqfyncO7CA8eNA
- https://arxiv.org/abs/2306.11987
- https://github.com/xijiu9/Train_Transformers_with_INT4

Quantizing the activation, weight, and gradient to 4-bit is promising to accelerate neural network training. However, existing 4-bit training methods require custom numerical formats which are not supported by contemporary hardware. In this work, we propose a training method for transformers with all matrix multiplications implemented with the INT4 arithmetic. Training with an ultra-low INT4 precision is challenging. To achieve this, we carefully analyze the specific structures of activation and gradients in transformers to propose dedicated quantizers for them. For forward propagation, we identify the challenge of outliers and propose a Hadamard quantizer to suppress the outliers. For backpropagation, we leverage the structural sparsity of gradients by proposing bit splitting and leverage score sampling techniques to quantize gradients accurately. Our algorithm achieves competitive accuracy on a wide range of tasks including natural language understanding, machine translation, and image classification. Unlike previous 4-bit training methods, our algorithm can be implemented on the current generation of GPUs. Our prototypical linear operator implementation is up to 2.2 times faster than the FP16 counterparts and speeds up the training by up to 35.1%.

### Transformer Reinforcement Learning X
- https://github.com/CarperAI/trlx

trlX is a distributed training framework designed from the ground up to focus on fine-tuning large language models with reinforcement learning using either a provided reward function or a reward-labeled dataset.

Training support for ğŸ¤— Hugging Face models is provided by Accelerate-backed trainers, allowing users to fine-tune causal and T5-based language models of up to 20B parameters, such as facebook/opt-6.7b, EleutherAI/gpt-neox-20b, and google/flan-t5-xxl. For models beyond 20B parameters, trlX provides NVIDIA NeMo-backed trainers that leverage efficient parallelism techniques to scale effectively.

### vLLM
- https://github.com/vllm-project/vllm

vLLM is a fast and easy-to-use library for LLM inference and serving.

vLLM is fast with:
- State-of-the-art serving throughput
- Efficient management of attention key and value memory with PagedAttention
- Dynamic batching of incoming requests
- Optimized CUDA kernels

vLLM is flexible and easy to use with:
- Seamless integration with popular HuggingFace models
- High-throughput serving with various decoding algorithms, including parallel sampling, beam search, and more
- Tensor parallelism support for distributed inference
- Streaming outputs
- OpenAI-compatible API server

## 3 å¯å‚è€ƒçš„å…¶å®ƒå¼€æºæ¨¡å‹
### Cerebrasï¼ˆå¯å•†ç”¨ï¼‰
- https://www.cerebras.net/blog/cerebras-gpt-a-family-of-open-compute-efficient-large-language-models/
- https://huggingface.co/cerebras

å¼€æº7ä¸ªå¯å•†ç”¨GPTæ¨¡å‹ï¼Œå«æ•°æ®é›†å’Œå¯ç›´æ¥ä¸‹è½½çš„é¢„è®­ç»ƒæ¨¡å‹æƒé‡: Cerebras å¼€æº 7 ä¸ª GPT æ¨¡å‹ï¼Œå‡å¯å•†ç”¨ï¼Œå‚æ•°é‡åˆ†åˆ«è¾¾åˆ° 1.11 äº¿ã€2.56 äº¿ã€5.9 äº¿ã€13 äº¿ã€27 äº¿ã€67 äº¿å’Œ 130 äº¿ã€‚å…¶ä¸­æœ€å¤§çš„æ¨¡å‹å‚æ•°é‡è¾¾åˆ° 130 äº¿ï¼Œä¸ Meta æœ€è¿‘å¼€æºçš„ LLaMA-13B ç›¸å½“ã€‚è¯¥é¡¹ç›®å¼€æºæ•°æ®é›†å’Œé¢„è®­ç»ƒæ¨¡å‹æƒé‡ï¼Œå…¶ä¸­é¢„è®­ç»ƒæ¨¡å‹æƒé‡æ–‡ä»¶å¤§å°è¿‘50Gå¯ç›´æ¥ä¸‹è½½ï¼Œå¹¶ä¸”å¯ç”¨äºå•†ä¸šå’Œç ”ç©¶ç”¨é€”ã€‚ä¸æ­¤å‰çš„ GPT-3 æ¨¡å‹ç›¸æ¯”ï¼ŒCerebras å¼€æºçš„æ¨¡å‹å…·æœ‰æ›´é«˜çš„å¯ç”¨æ€§å’Œé€æ˜åº¦ï¼Œç ”ç©¶äººå‘˜å’Œå¼€å‘è€…å¯ä»¥ä½¿ç”¨å°‘é‡æ•°æ®å¯¹å…¶è¿›è¡Œå¾®è°ƒï¼Œæ„å»ºå‡ºé«˜è´¨é‡çš„è‡ªç„¶è¯­è¨€å¤„ç†åº”ç”¨ã€‚

### ChatDoctor
- https://github.com/Kent0n-Li/ChatDoctor
- https://arxiv.org/abs/2303.14070

Recent large language models (LLMs) in the general domain, such as ChatGPT, have shown remarkable success in following instructions and producing human-like responses. However, such language models have yet to be adapted for the medical domain, resulting in poor accuracy of responses and an inability to provide sound advice on medical diagnoses, medications, etc. To address this problem, we fine-tuned our ChatDoctor model based on 100k real-world patient-physician conversations from an online medical consultation site. Besides, we add autonomous knowledge retrieval capabilities to our ChatDoctor, for example, Wikipedia or a disease database as a knowledge brain. By fine-tuning the LLMs using these 100k patient-physician conversations, our model showed significant improvements in understanding patients' needs and providing informed advice. The autonomous ChatDoctor model based on Wikipedia and Database Brain can access real-time and authoritative information and answer patient questions based on this information, significantly improving the accuracy of the model's responses, which shows extraordinary potential for the medical field with a low tolerance for error.

### Code Llama (Meta AI)
- https://github.com/facebookresearch/codellama
- https://ai.meta.com/blog/code-llama-large-language-model-coding/

Code Llama is a family of large language models for code based on Llama 2 providing state-of-the-art performance among open models, infilling capabilities, support for large input contexts, and zero-shot instruction following ability for programming tasks. We provide multiple flavors to cover a wide range of applications: foundation models (Code Llama), Python specializations (Code Llama - Python), and instruction-following models (Code Llama - Instruct) with 7B, 13B and 34B parameters each. All models are trained on sequences of 16k tokens and show improvements on inputs with up to 100k tokens. 7B and 13B Code Llama and Code Llama - Instruct variants support infilling based on surrounding content. Code Llama was developed by fine-tuning Llama 2 using a higher sampling of code. As with Llama 2, we applied considerable safety mitigations to the fine-tuned versions of the model. For detailed information on model training, architecture and parameters, evaluations, responsible AI and safety refer to our research paper. Output generated by code generation features of the Llama Materials, including Code Llama, may be subject to third party licenses, including, without limitation, open source licenses.

We are unlocking the power of large language models and our latest version of Code Llama is now accessible to individuals, creators, researchers and businesses of all sizes so that they can experiment, innovate and scale their ideas responsibly. This release includes model weights and starting code for pretrained and fine-tuned Llama language models â€” ranging from 7B to 34B parameters.

### Dolly 1&2ï¼ˆå¯å•†ç”¨ï¼‰
- https://github.com/databrickslabs/dolly
- https://huggingface.co/databricks/dolly-v2-12b
- https://www.databricks.com/blog/2023/03/24/hello-dolly-democratizing-magic-chatgpt-open-models.html

We show that anyone can take a dated off-the-shelf open source large language model (LLM) and give it magical ChatGPT-like instruction following ability by training it in 30 minutes on one machine, using high-quality training data. Surprisingly, instruction-following does not seem to require the latest or largest models: our model is only 6 billion parameters, compared to 175 billion for GPT-3. We open source the code for our model (Dolly) and show how it can be re-created on Databricks. We believe models like Dolly will help democratize LLMs, transforming them from something very few companies can afford into a commodity every company can own and customize to improve their products.

### FinGPT
- https://github.com/ai4finance-foundation/fingpt
- https://arxiv.org/pdf/2306.06031v1.pdf
- https://mp.weixin.qq.com/s/A9euFin675nxGGciiX6rJQ

Large language models (LLMs) have shown the potential of revolutionizing natural language processing tasks in diverse domains, sparking great interest in finance. Accessing high-quality financial data is the first challenge for financial LLMs (FinLLMs). While proprietary models like BloombergGPT have taken advantage of their unique data accumulation, such privileged access calls for an open-source alternative to democratize Internet-scale financial data.

In this paper, we present an open-source large language model, FinGPT, for the finance sector. Unlike proprietary models, FinGPT takes a data-centric approach, providing researchers and practitioners with accessible and transparent resources to develop their FinLLMs. We highlight the importance of an automatic data curation pipeline and the lightweight low-rank adaptation technique in building FinGPT. Furthermore, we showcase several potential applications as stepping stones for users, such as robo-advising, algorithmic trading, and low-code development. Through collaborative efforts within the open-source AI4Finance community, FinGPT aims to stimulate innovation, democratize FinLLMs, and unlock new opportunities in open finance. 

### Falconï¼ˆå¯å•†ç”¨ï¼‰
- https://mp.weixin.qq.com/s/mKx0ZiTB28khj4U7EVJiVw
- https://falconllm.tii.ae/
- https://huggingface.co/tiiuae/falcon-40b

Falcon LLM is a foundational large language model (LLM) with 40 billion parameters trained on one trillion tokens. TII has now released Falcon LLM â€“ a 40B model.

The model uses only 75 percent of GPT-3â€™s training compute, 40 percent of Chinchillaâ€™s, and 80 percent of PaLM-62Bâ€™s.

### Facebook/Meta LLaMA/LLaMA2
- https://github.com/facebookresearch/llama
- https://ai.meta.com/research/publications/llama-2-open-foundation-and-fine-tuned-chat-models/

**LLaMA1**

LLaMA: Open and Efficient Foundation Language Models

We introduce LLaMA, a collection of foundation language models ranging from 7B to 65B parameters. We train our models on trillions of tokens, and show that it is possible to train state-of-the-art models using publicly available datasets exclusively, without resorting to proprietary and inaccessible datasets. In particular, LLaMA-13B outperforms GPT-3 (175B) on most benchmarks, and LLaMA-65B is competitive with the best models, Chinchilla-70B and PaLM-540B. We release all our models to the research community.

**LLaMA2**

We are unlocking the power of large language models. Our latest version of Llama is now accessible to individuals, creators, researchers and businesses of all sizes so that they can experiment, innovate and scale their ideas responsibly.

This release includes model weights and starting code for pretrained and fine-tuned Llama language models â€” ranging from 7B to 70B parameters.

This repository is intended as a minimal example to load Llama 2 models and run inference. For more detailed examples leveraging HuggingFace, see llama-recipes.

### Giraffe
- https://huggingface.co/abacusai/Giraffe-v2-13b-32k
- https://github.com/abacusai/long-context

The choice of how to encode positional information for transformers has been one of the key components of LLM architectures.

An area that has been interesting to us and others in the community recently is whether LLMs can be extended to longer contexts.

We have conducted a range of experiments with different schemes for extending context length capabilities of Llama, which has been pretrained on 2048 context length with the RoPE (Rotary Position Embedding) encoding. Here we share some of the results as well as the training and evaluation scripts in the hope that it will be useful to the community. For our best performing models - linear scaling with IFT at scales 4 and 16 - we are also sharing the weights in case others wish to use them, or to conduct their own tests. We believe the scale 16 model should perform well on real world tasks up to 16k context lengths, and potentially even up to about 20-24k context lengths.

### GALACTICA
- https://github.com/paperswithcode/galai
- https://arxiv.org/pdf/2211.09085.pdf
- https://galactica.org/

GALACTICA is a general-purpose scientific language model. It is trained on a large corpus of scientific text and data. It can perform scientific NLP tasks at a high level, as well as tasks such as citation prediction, mathematical reasoning, molecular property prediction and protein annotation. More information is available at galactica.org.

### Goar-7B for Arithmetic Tasks
- https://mp.weixin.qq.com/s/_haINkHNV4bMszm9F41yXA
- https://arxiv.org/pdf/2305.14201.pdf
- https://github.com/liutiedong/goat

åœ¨æœ¬æ–‡ä»‹ç»äº†ä¸€ç§å¾®è°ƒçš„è¯­è¨€æ¨¡å‹ï¼šGoatã€‚ä¸åŒäºä»¥å¾€å¯¹ç®—æœ¯è®¡ç®—çš„ç ”ç©¶ï¼Œè¯¥æ¨¡å‹åœ¨ LLaMAä¸Šé‡‡ç”¨ç«¯åˆ°ç«¯ç›‘ç£æŒ‡ä»¤å¾®è°ƒèŒƒå¼ï¼Œåˆ©ç”¨åŒ…å«çº¦100ä¸‡ä¸ªæ ·æœ¬çš„ç»¼åˆç”Ÿæˆæ•°æ®é›†è¿›è¡Œè®­ç»ƒå¾—åˆ°ã€‚å®ƒéå¸¸æ“…é•¿ç®—æœ¯ä»»åŠ¡ã€‚Goat åœ¨åˆç­‰ç®—æœ¯ï¼ˆåŒ…æ‹¬æ•´æ•°çš„åŠ æ³•ã€å‡æ³•ã€ä¹˜æ³•å’Œé™¤æ³•ï¼‰ä¸­å®ç°äº†æœ€å…ˆè¿›çš„æ€§èƒ½ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œä»…é€šè¿‡ç›‘ç£å¾®è°ƒè€Œä¸åº”ç”¨ä»»ä½•ç‰¹æ®ŠæŠ€æœ¯ï¼Œã€ŒGoatæ¨¡å‹èƒ½å¤Ÿåœ¨Zero-shotè®¾ç½®ä¸­ä»¥è¿‘ä¹å®Œç¾çš„ç²¾åº¦ä¸ºå¤§æ•°åŠ æ³•å’Œå‡æ³•ç”Ÿæˆç­”æ¡ˆã€ã€‚è¿™ç§å‡ºè‰²çš„ç®—æœ¯èƒ½åŠ›å½’å› äº LLaMA å¯¹æ•°å­—çš„ä¸€è‡´æ ‡è®°åŒ–ï¼Œå¹¶è¡¨æ˜è¿™å¯¹äºä»¥å‰çš„ LLM æ¥è¯´å‡ ä¹æ˜¯ä¸å¯èƒ½å®ç°çš„ï¼Œä¾‹å¦‚ Bloomã€OPTã€GPT-NeoX ã€Pythiaç­‰ã€‚

â€ƒç„¶è€Œï¼Œè¯¥æ¨¡å‹åœ¨é¢å¯¹ä¹˜é™¤è¿ç®—æ—¶é‡åˆ°äº†å¾ˆå¤§çš„æŒ‘æˆ˜ã€‚ä¸ºäº†å…‹æœè¿™ä¸€æŒ‘æˆ˜ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ç§æ–¹æ³•ï¼Œå³ã€Œå°†å„ç§ç®—æœ¯ä»»åŠ¡åˆ†ä¸ºå¯å­¦ä¹ å’Œä¸å¯å­¦ä¹ ä»»åŠ¡ã€ï¼Œéšååˆ©ç”¨åŸºæœ¬ç®—æœ¯åŸç†å°†ä¸å¯å­¦ä¹ ä»»åŠ¡ï¼ˆä¾‹å¦‚å¤šä½æ•°ä¹˜æ³•å’Œé™¤æ³•ï¼‰åˆ†è§£ä¸ºä¸€ç³»åˆ—å¯å­¦ä¹ ä»»åŠ¡ã€‚æœ¬æ–‡æ–¹æ³•ç¡®ä¿ä¿ƒè¿›æ¨¡å‹å­¦ä¹ çš„ä¸­é—´ç›‘ç£ä¹Ÿå¾ˆå®¹æ˜“è¢«äººç±»ç†è§£ï¼Œå³é€šè¿‡æ¨¡å‹å¾®è°ƒåœ¨ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆä¹‹å‰ç”Ÿæˆåˆé€‚çš„CoTã€‚ã€Œæœ¬æ–‡æ–¹æ³•å¤§å¤§ä¼˜äº GPT-4 çš„é•¿ä¹˜æ³•å’Œé•¿é™¤æ³•ã€ã€‚æœ€ç»ˆä½¿ç”¨ BIG-bench (Srivastava et al., 2022) ç®—æœ¯å­ä»»åŠ¡è¯„ä¼°æ¨¡å‹çš„æ€§èƒ½ï¼Œå¹¶å¯¹æœ¬æ–‡æ–¹æ³•çš„æœ‰æ•ˆæ€§è¿›è¡Œç»¼åˆè¯„ä¼°ã€‚å®éªŒç»“æœè¡¨æ˜ï¼Œè¯¥æ¨¡å‹å¯ä»¥å­¦ä¹ è®¡ç®—æ¨¡å¼å¹¶å°†å…¶æ³›åŒ–åˆ°çœ‹ä¸è§çš„æ•°æ®ï¼Œè€Œä¸ä»…ä»…æ˜¯çº¯ç²¹æƒé‡è®°å¿†è®¡ç®—ã€‚æ­¤å¤–ï¼ŒGoat-7B å¯ä»¥åœ¨24GB VRAM GPUä¸Šä½¿ç”¨LoRAä½ç§©é€‚åº”æŠ€æœ¯è¿›è¡Œè®­ç»ƒï¼Œå¯ä»¥ã€Œå¾ˆå®¹æ˜“å¤ç°è®ºæ–‡æˆæœã€ã€‚
 
### HuggingChat
- https://huggingface.co/chat/

Making the community's best AI chat models available to everyone.

### Koala: A Dialogue Model for Academic Research
- https://bair.berkeley.edu/blog/2023/04/03/koala/

In this post, we introduce Koala, a chatbot trained by fine-tuning Metaâ€™s LLaMA on dialogue data gathered from the web. We describe the dataset curation and training process of our model, and also present the results of a user study that compares our model to ChatGPT and Stanfordâ€™s Alpaca. Our results show that Koala can effectively respond to a variety of user queries, generating responses that are often preferred over Alpaca, and at least tied with ChatGPT in over half of the cases.

### LongLLaMA
- https://mp.weixin.qq.com/s/XzaET7WfrNpOf-zdiSxrig
- https://arxiv.org/pdf/2307.03170.pdf
- https://github.com/CStanKonrad/long_llama
- https://huggingface.co/syzymon/long_llama_3b

This repository contains the research preview of LongLLaMA, a large language model capable of handling long contexts of 256k tokens or even more.

LongLLaMA is built upon the foundation of OpenLLaMA and fine-tuned using the Focused Transformer (FoT) method. We release a smaller 3B variant of the LongLLaMA model on a permissive license (Apache 2.0) and inference code supporting longer contexts on Hugging Face. Our model weights can serve as the drop-in replacement of LLaMA in existing implementations (for short context up to 2048 tokens). Additionally, we provide evaluation results and comparisons against the original OpenLLaMA models. Stay tuned for further updates.

### LLaMAå¤åˆ»ç‰ˆOpenLLaMA
- https://github.com/openlm-research/open_llama

In this repo, we release a permissively licensed open source reproduction of Meta AI's LLaMA large language model. In this release, we're releasing a public preview of the 7B OpenLLaMA model that has been trained with 200 billion tokens. We provide PyTorch and Jax weights of pre-trained OpenLLaMA models, as well as evaluation results and comparison against the original LLaMA models. Stay tuned for our updates.

### Llama-X: Open Academic Research on Improving LLaMA to SOTA LLM
- https://github.com/AetherCortex/Llama-X

This is the repo for the Llama-X, which aims to:
- Progressively improve the performance of LLaMA to SOTA LLM with open-source community.
- Conduct Llama-X as an open academic research which is long-term, systematic and rigorous.
- Save the repetitive work of community and we work together to create more and faster increment.

### Lit-LLaMA ï¸
- https://github.com/Lightning-AI/lit-llama

Lit-LLaMA is:
- Simple: Single-file implementation without boilerplate.
- Correct: Numerically equivalent to the original model.
- Optimized: Runs on consumer hardware or at scale.
- Open-source: No strings attached.

### MammoTH
- https://github.com/TIGER-AI-Lab/MAmmoTH

We introduce MAmmoTH ğŸ¦£, a series of open-source large language models (LLMs) specifically tailored for general math problem-solving. The MAmmoTH models are trained on MathInstruct, a meticulously curated instruction tuning dataset that is lightweight yet generalizable. MathInstruct is compiled from 13 math rationale datasets, six of which are newly curated by this work. It uniquely focuses on the hybrid use of chain-of-thought (CoT) and program-of-thought (PoT) rationales, and ensures extensive coverage of diverse mathematical fields.

### MPT-7Bï¼ˆå¯å•†ç”¨ï¼‰
- https://www.mosaicml.com/blog/mpt-7b
- https://huggingface.co/mosaicml/mpt-7b

MPT-7B is a decoder-style transformer pretrained from scratch on 1T tokens of English text and code. This model was trained by MosaicML.

MPT-7B is part of the family of MosaicPretrainedTransformer (MPT) models, which use a modified transformer architecture optimized for efficient training and inference.

Introducing MPT-7B, the latest entry in our MosaicML Foundation Series. MPT-7B is a transformer trained from scratch on 1T tokens of text and code. It is open source, available for commercial use, and matches the quality of LLaMA-7B. MPT-7B was trained on the MosaicML platform in 9.5 days with zero human intervention at a cost of ~$200k. Starting today, you can train, finetune, and deploy your own private MPT models, either starting from one of our checkpoints or training from scratch. For inspiration, we are also releasing three finetuned models in addition to the base MPT-7B: MPT-7B-Instruct, MPT-7B-Chat, and MPT-7B-StoryWriter-65k+, the last of which uses a context length of 65k tokens!

### OpenGPT
- https://github.com/CogStack/OpenGPT

A framework for creating grounded instruction based datasets and training conversational domain expert Large Language Models (LLMs).

NHS-LLMï¼šA conversational model for healthcare trained using OpenGPT. All the medical datasets used to train this model were created using OpenGPT and are available below.

### Orca
- https://aka.ms/orca-lm
- https://arxiv.org/pdf/2306.02707.pdf
- https://mp.weixin.qq.com/s/RRdrSeI2ux5QE6MqJ8opSg

Recent research has focused on enhancing the capability of smaller models through imitation learning, drawing on the outputs generated by large foundation models (LFMs). A number of issues impact the quality of these models, ranging from limited imitation signals from shallow LFM outputs; small scale homogeneous training data; and most notably a lack of rigorous evaluation resulting in overestimating the small model's capability as they tend to learn to imitate the style, but not the reasoning process of LFMs. To address these challenges, we develop Orca (We are working with our legal team to publicly release a diff of the model weights in accordance with LLaMA's release policy to be published at this https URL), a 13-billion parameter model that learns to imitate the reasoning process of LFMs. Orca learns from rich signals from GPT-4 including explanation traces; step-by-step thought processes; and other complex instructions, guided by teacher assistance from ChatGPT. To promote this progressive learning, we tap into large-scale and diverse imitation data with judicious sampling and selection. Orca surpasses conventional state-of-the-art instruction-tuned models such as Vicuna-13B by more than 100% in complex zero-shot reasoning benchmarks like Big-Bench Hard (BBH) and 42% on AGIEval. Moreover, Orca reaches parity with ChatGPT on the BBH benchmark and shows competitive performance (4 pts gap with optimized system message) in professional and academic examinations like the SAT, LSAT, GRE, and GMAT, both in zero-shot settings without CoT; while trailing behind GPT-4. Our research indicates that learning from step-by-step explanations, whether these are generated by humans or more advanced AI models, is a promising direction to improve model capabilities and skills.

### OpenChatKit
- https://www.together.xyz/blog/openchatkit 
- https://huggingface.co/spaces/togethercomputer/OpenChatKit
- https://github.com/togethercomputer/OpenChatKit

OpenChatKit uses a 20 billion parameter chat model trained on 43 million instructions and supports reasoning, multi-turn conversation, knowledge and generative answers.

OpenChatKit provides a powerful, open-source base to create both specialized and general purpose chatbots for various applications. The kit includes an instruction-tuned 20 billion parameter language model, a 6 billion parameter moderation model, and an extensible retrieval system for including up-to-date responses from custom repositories. It was trained on the OIG-43M training dataset, which was a collaboration between Together, LAION, and Ontocord.ai. Much more than a model release, this is the beginning of an open source project. We are releasing a set of tools and processes for ongoing improvement with community contributions.

### Open-Assistant
- https://github.com/LAION-AI/Open-Assistant
- https://open-assistant.io/zh

Open Assistant is a project meant to give everyone access to a great chat based large language model.

We believe that by doing this we will create a revolution in innovation in language. In the same way that stable-diffusion helped the world make art and images in new ways we hope Open Assistant can help improve the world by improving language itself.

### Platypus
- https://platypus-llm.github.io/
- https://github.com/arielnlee/Platypus

We present Platypus a family of fine-tuned and merged Large Language Models (LLMs) that achieves the strongest performance and currently stands at first place in HuggingFace's Open LLM Leaderboard as of the release date of this work. In this work we describe (1) our curated dataset Open-Platypus, that is a subset of other open datasets and which we release to the public (2) our process of fine-tuning and merging LoRA modules in order to conserve the strong prior of pretrained LLMs, while bringing specific domain knowledge to the surface (3) our efforts in checking for test data leaks and contamination in the training data, which can inform future research. Specifically, the Platypus family achieves strong performance in quantitative LLM metrics across model sizes, topping the global Open LLM leaderboard while using just a fraction of the fine-tuning data and overall compute that are required for other state-of-the-art fine-tuned LLMs. In particular, a 13B Platypus model can be trained on a single A100 GPU using 25k questions in 5 hours. This is a testament of the quality of our Open-Platypus dataset, and opens opportunities for more improvements in the field.

### MedLLaMA-13B & PMC-LLaMA: Continue Training LLaMA on Medical Papers
- https://github.com/chaoyi-wu/PMC-LLaMA
- https://huggingface.co/chaoyi-wu/PMC_LLAMA_7B
- https://arxiv.org/abs/2304.14454

We have release a new model MedLLaMA-13B finetuned with LLaMA-13B on some medical corpus, termed as MedLLaMA-13B. It have been proved to be more powerful than both LLaMA-13B and PMC-LLaMA, refering to our benchmark for detail comparison.

### RedPajamaï¼ˆå¯å•†ç”¨ï¼‰
- https://www.together.xyz/blog/redpajama
- https://github.com/togethercomputer/RedPajama-Data

RedPajama, a project to create leading open-source models, starts by reproducing LLaMA training dataset of over 1.2 trillion tokens.

### SQLCoder (Defog)
- https://github.com/defog-ai/sqlcoder
- https://huggingface.co/defog/sqlcoder

SQLCoder is a 15B parameter model that outperforms gpt-3.5-turbo for natural language to SQL generation tasks on our sql-eval framework, and significantly outperforms all popular open-source models. It also significantly outperforms text-davinci-003, a model that's more than 10 times its size.

SQLCoder is fine-tuned on a base StarCoder model.

### StableLM
- https://zhuanlan.zhihu.com/p/623542189
- https://github.com/Stability-AI/StableLM

StableLM: Stability AI Language Models

This repository contains Stability AI's ongoing development of the StableLM series of language models and will be continuously updated with new checkpoints. The following provides an overview of all currently available models. More coming soon.

### StableVicuna
- https://github.com/Stability-AI/StableLM

StableVicunaåŸºäºå°ç¾Šé©¼Vicuna-13Bçš„è¿›ä¸€æ­¥æŒ‡ä»¤å¾®è°ƒå’ŒRLHFè®­ç»ƒçš„ç‰ˆæœ¬ã€‚Vicuna-13Bæ˜¯LLaMA-13Bçš„ä¸€ä¸ªæŒ‡ä»¤å¾®è°ƒæ¨¡å‹ã€‚

### Stanford Alpaca
- https://crfm.stanford.edu/2023/03/13/alpaca.html
- https://alpaca-ai.ngrok.io/
- https://github.com/tatsu-lab/stanford_alpaca

Alpaca: A Strong, Replicable Instruction-Following ModelAl

We introduce Alpaca 7B, a model fine-tuned from the LLaMA 7B model on 52K instruction-following demonstrations. On our preliminary evaluation of single-turn instruction following, Alpaca behaves qualitatively similarly to OpenAIâ€™s text-davinci-003, while being surprisingly small and easy/cheap to reproduce (<600$).

### UltraLM-13B
- https://github.com/thunlp/UltraChat

UltraLM is a series of chat language models trained on UltraChat. Currently, we have released the 13B version, which ranks #1 among open-source models and ranks #4 among all models on AlpacaEval Leaderboard. UltraLM-13B is based upon LLaMA-13B.

This project aims to construct open-source, large-scale, and multi-round dialogue data powered by Turbo APIs to facilitate the construction of powerful language models with general conversational capability. In consideration of factors such as safeguarding privacy, we do not directly use any data available on the Internet as prompts. To ensure generation quality, two separate ChatGPT Turbo APIs are adopted in generation, where one plays the role of the user to generate queries and the other generates the response. We instruct the user model with carefully designed prompts to mimic human user behavior and call the two APIs iteratively. The generated dialogues undergo further post-processing and filtering.

### Vicuna: An Open-Source Chatbot Impressing GPT-4 with 90% ChatGPT Quality
- https://chat.lmsys.org/
- https://vicuna.lmsys.org/
- https://github.com/lm-sys/FastChat

An open platform for training, serving, and evaluating large language model based chatbots.

### Wombat
- https://mp.weixin.qq.com/s/xoPKmOzjlNZ2qGdcKeGARw
- https://mp.weixin.qq.com/s/UI-ij5o43ct1efYoNVdQDg
- https://arxiv.org/abs/2304.05302v1
- https://github.com/GanjinZero/RRHF

This is the repository for RRHF (Rank Response to align Human Feedback) and open-sourced language models Wombat. RRHF helps align large language models with human perference easier.

Reinforcement Learning from Human Feedback (RLHF) enables the alignment of large language models with human preference, improving the quality of interactions between humans and language models. Recent practice of RLHF uses PPO to enable the large language model optimization of such alignment. However, implementing PPO is non-trivial (where the training procedure requires interactive between policy, behavior policy, reward, value model) and it is also tedious to tuning many hyper-parameters. Our motivation is to simplify the alignment between language models with human preference, and our proposed paradigm RRHF (Rank Response from Human Feedback) can achieve such alignment as easily as conventional fine-tuning. It is simpler than PPO from the aspects of coding, model counts, and hyperparameters.

### WizardMath
- https://github.com/nlpxucan/WizardLM/tree/main/WizardMath
- https://huggingface.co/WizardLM/WizardMath-70B-V1.0



### XGen-7B
- https://blog.salesforceairesearch.com/xgen/
- https://github.com/salesforce/xgen

We trained a series of 7B LLMs named XGen-7B with standard dense attention on up to 8K sequence length for up to 1.5T tokens. We also fine tune the models on public-domain instructional data. The main take-aways are:
- On standard NLP benchmarks, XGen achieves comparable or better results when compared with state-of-the-art open-source LLMs (e.g. MPT, Falcon, LLaMA, Redpajama, OpenLLaMA) of similar model size.
- Our targeted evaluation on long sequence modeling benchmarks show benefits of our 8K-seq models over 2K- and 4K-seq models.
- XGen-7B archives equally strong results both in text (e.g., MMLU, QA) and code (HumanEval) tasks.
- Training cost of $150K on 1T tokens under Google Cloud pricing for TPU-v4.

### Xwin-LM
- https://github.com/Xwin-LM/Xwin-LM

Xwin-LM aims to develop and open-source alignment technologies for large language models, including supervised fine-tuning (SFT), reward models (RM), reject sampling, reinforcement learning from human feedback (RLHF), etc. Our first release, built-upon on the Llama2 base models, ranked TOP-1 on AlpacaEval. Notably, it's the first to surpass GPT-4 on this benchmark. The project will be continuously updated.

### LLaMA 2 Long
- https://arxiv.org/pdf/2309.16039.pdf

We present a series of long-context LLMs that support effective context windows of up to 32,768 tokens. Our model series are built through continual pretraining from Llama 2 with longer training sequences and on a dataset where long texts are upsampled. We perform extensive evaluation on language modeling, synthetic context probing tasks, and a wide range of research benchmarks. On research benchmarks, our models achieve consistent improvements on most regular tasks and significant improvements on long-context tasks over Llama 2. Notably, with a cost-effective instruction tuning procedure that does not require human-annotated long instruction data, the 70B variant can already surpass gpt-3.5-turbo-16k's overall performance on a suite of long-context tasks. Alongside these results, we provide an in-depth analysis on the individual components of our method. We delve into Llama's position encodings and discuss its limitation in modeling long dependencies. We also examine the impact of various design choices in the pretraining process, including the data mix and the training curriculum of sequence lengths -- our ablation experiments suggest that having abundant long texts in the pretrain dataset is not the key to achieving strong performance, and we empirically verify that long context continual pretraining is more efficient and similarly effective compared to pretraining from scratch with long sequences.

### Mistral 7B
- https://mistral.ai/news/announcing-mistral-7b/

Mistral 7B is a 7.3B parameter model that:
- Outperforms Llama 2 13B on all benchmarks
- Outperforms Llama 1 34B on many benchmarks
- Approaches CodeLlama 7B performance on code, while remaining good at English tasks
- Uses Grouped-query attention (GQA) for faster inference
- Uses Sliding Window Attention (SWA) to handle longer sequences at smaller cost

### UltraLM-13B (UltraFeedback)
- https://github.com/OpenBMB/UltraFeedback

UltraRM unleashes the power of UltraLM-13B-v2.0 and UltraLM-13B! A simple best-of-16 sampling achieves 92.30% (UltraLM2, ğŸ¥‡ in 13B results) and 91.54% (UltraLM, ğŸ¥‡ in LLaMA-1 results) win rates against text-davinci-003 on AlpacaEval benchmark!

UltraFeedback is a large-scale, fine-grained, diverse preference dataset, used for training powerful reward models and critic models. We collect about 64k prompts from diverse resources (including UltraChat, ShareGPT, Evol-Instruct, TruthfulQA, FalseQA, and FLAN, see here for dataset statistics). We then use these prompts to query multiple LLMs (see here for model lists) and generate 4 different responses for each prompt, resulting in a total of 256k samples.

To collect high-quality preference and textual feedback, we design a fine-grained annotation instruction, which contains 4 different aspects, namely instruction-following, truthfulness, honesty and helpfulness. We then ask GPT-4 to annotate the collected samples based on the instruction.

### Llemma: An Open Language Model For Mathematics
- https://arxiv.org/abs/2310.10631
- https://github.com/EleutherAI/math-lm

We present Llemma, a large language model for mathematics. We continue pretraining Code Llama on the Proof-Pile-2, a mixture of scientific papers, web data containing mathematics, and mathematical code, yielding Llemma. On the MATH benchmark Llemma outperforms all known open base models, as well as the unreleased Minerva model suite on an equi-parameter basis. Moreover, Llemma is capable of tool use and formal theorem proving without any further finetuning. We openly release all artifacts, including 7 billion and 34 billion parameter models, the Proof-Pile-2, and code to replicate our experiments.

### Mistral-Trismegistus-7B ï¼ˆç¥ç§˜å­¦/ç„å­¦/çµæ€§ï¼‰
- https://huggingface.co/teknium/Mistral-Trismegistus-7B

Transcendence is All You Need! Mistral Trismegistus is a model made for people interested in the esoteric, occult, and spiritual.

### Memory-GPT(MemGPT)
- https://github.com/cpacker/MemGPT
- https://arxiv.org/abs/2310.08560

Large language models (LLMs) have revolutionized AI, but are constrained by limited context windows, hindering their utility in tasks like extended conversations and document analysis. To enable using context beyond limited context windows, we propose virtual context management, a technique drawing inspiration from hierarchical memory systems in traditional operating systems that provide the appearance of large memory resources through data movement between fast and slow memory. Using this technique, we introduce MemGPT (Memory-GPT), a system that intelligently manages different memory tiers in order to effectively provide extended context within the LLM's limited context window, and utilizes interrupts to manage control flow between itself and the user. We evaluate our OS-inspired design in two domains where the limited context windows of modern LLMs severely handicaps their performance: document analysis, where MemGPT is able to analyze large documents that far exceed the underlying LLM's context window, and multi-session chat, where MemGPT can create conversational agents that remember, reflect, and evolve dynamically through long-term interactions with their users. 

### MetaMath
- https://github.com/meta-math/MetaMath

Large language models (LLMs) have pushed the limits of natural language understanding and exhibited excellent problem-solving ability. Despite the great success, most existing open-source LLMs (e.g., LLaMA-2) are still far away from satisfactory for solving mathematical problem due to the complex reasoning procedures. To bridge this gap, we propose MetaMath, a fine-tuned language model that specializes in mathematical reasoning. Specifically, we start by bootstrapping mathematical questions by rewriting the question from multiple perspectives without extra knowledge, which results in a new dataset called MetaMathQA. Then we fine-tune the LLaMA-2 models on MetaMathQA. Experimental results on two popular benchmarks (i.e., GSM8K and MATH) for mathematical reasoning demonstrate that MetaMath outperforms a suite of open-source LLMs by a significant margin. Our MetaMath-7B model achieves 66.4% on GSM8K and 19.4% on MATH, exceeding the state-of-the-art models of the same size by 11.5% and 8.7%. Particularly, MetaMath-70B achieves an accuracy of 82.3% on GSM8K, slightly better than GPT-3.5-Turbo. We release all the MetaMathQA dataset, the MetaMath models with different model sizes and the training code for public use.

### ChipNeMo (èŠ¯ç‰‡è®¾è®¡)
- https://arxiv.org/abs/2311.00176

ChipNeMo aims to explore the applications of large language models (LLMs) for industrial chip design. Instead of directly deploying off-the-shelf commercial or open-source LLMs, we instead adopt the following domain adaptation techniques: custom tokenizers, domain-adaptive continued pretraining, supervised fine-tuning (SFT) with domain-specific instructions, and domain-adapted retrieval models. We evaluate these methods on three selected LLM applications for chip design: an engineering assistant chatbot, EDA script generation, and bug summarization and analysis. Our results show that these domain adaptation techniques enable significant LLM performance improvements over general-purpose base models across the three evaluated applications, enabling up to 5x model size reduction with similar or better performance on a range of design tasks. Our findings also indicate that there's still room for improvement between our current results and ideal outcomes. We believe that further investigation of domain-adapted LLM approaches will help close this gap in the future.

### Zephyr
- https://github.com/huggingface/alignment-handbook
- https://huggingface.co/collections/HuggingFaceH4/zephyr-7b-6538c6d6d5ddd1cbb1744a66

Just one year ago, chatbots were out of fashion and most people hadn't heard about techniques like Reinforcement Learning from Human Feedback (RLHF) to align language models with human preferences. Then, OpenAI broke the internet with ChatGPT and Meta followed suit by releasing the Llama series of language models which enabled the ML community to build their very own capable chatbots. This has led to a rich ecosystem of datasets and models that have mostly focused on teaching language models to follow instructions through supervised fine-tuning (SFT).

However, we know from the InstructGPT and Llama2 papers that significant gains in helpfulness and safety can be had by augmenting SFT with human (or AI) preferences. At the same time, aligning language models to a set of preferences is a fairly novel idea and there are few public resources available on how to train these models, what data to collect, and what metrics to measure for best downstream performance.

The Alignment Handbook aims to fill that gap by providing the community with a series of robust training recipes that span the whole pipeline.

### neural-chat-7b-v3-1ï¼ˆIntelï¼‰
- https://huggingface.co/Intel/neural-chat-7b-v3-1

This model is a fine-tuned model based on mistralai/Mistral-7B-v0.1 on the open source dataset Open-Orca/SlimOrca. Then we align it with DPO algorithm. For more details, you can refer our blog: The Practice of Supervised Fine-tuning and Direct Preference Optimization on Habana Gaudi2.

### SteerLM
- https://huggingface.co/datasets/nvidia/HelpSteer
- http://arxiv.org/abs/2311.09528
- https://arxiv.org/abs/2310.05344

HelpSteer is an open-source Helpfulness Dataset (CC-BY-4.0) that supports aligning models to become more helpful, factually correct and coherent, while being adjustable in terms of the complexity and verbosity of its responses.

Leveraging this dataset and SteerLM, we train a Llama 2 70B to reach 7.54 on MT Bench, the highest among models trained on open-source datasets based on MT Bench Leaderboard as of 15 Nov 2023.

### Llama Coder
- https://github.com/ex3ndr/llama-coder
- https://marketplace.visualstudio.com/items?itemName=ex3ndr.llama-coder

Llama Coder is a better and self-hosted Github Copilot replacement for VS Studio Code. Llama Coder uses Ollama and codellama to provide autocomplete that runs on your hardware. Works best with Mac M1/M2/M3 or with RTX 4090.

### Meditron
- https://github.com/epfLLM/meditron
- https://arxiv.org/abs/2311.16079

Meditron is a suite of open-source medical Large Language Models (LLMs).

We release Meditron-7B and Meditron-70B, which are adapted to the medical domain from Llama-2 through continued pretraining on a comprehensively curated medical corpus, including selected PubMed papers and abstracts, a new dataset of internationally-recognized medical guidelines, and a general domain corpus.

Meditron-70B, finetuned on relevant data, outperforms Llama-2-70B, GPT-3.5 and Flan-PaLM on multiple medical reasoning tasks.

### RankZephyr
- https://arxiv.org/abs/2312.02724
- https://github.com/castorini/rank_llm

In information retrieval, proprietary large language models (LLMs) such as GPT-4 and open-source counterparts such as LLaMA and Vicuna have played a vital role in reranking. However, the gap between open-source and closed models persists, with reliance on proprietary, non-transparent models constraining reproducibility. Addressing this gap, we introduce RankZephyr, a state-of-the-art, open-source LLM for listwise zero-shot reranking. RankZephyr not only bridges the effectiveness gap with GPT-4 but in some cases surpasses the proprietary model. Our comprehensive evaluations across several datasets (TREC Deep Learning Tracks; NEWS and COVID from BEIR) showcase this ability. RankZephyr benefits from strategic training choices and is resilient against variations in initial document ordering and the number of documents reranked. Additionally, our model outperforms GPT-4 on the NovelEval test set, comprising queries and passages past its training period, which addresses concerns about data contamination.

### StableLM Zephyr 3B
- https://huggingface.co/stabilityai/stablelm-zephyr-3b
- https://huggingface.co/stabilityai/stable-zephyr-3b-dpo
- https://github.com/eaidova/openvino_notebooks/blob/ea/stateful_chatbot/notebooks/273-stable-zephyr-3b-chatbot/273-stable-zephyr-3b-chatbot.ipynb

StableLM Zephyr 3B is a 3 billion parameter Large Language Model (LLM), 60% smaller than 7B models, allowing accurate, and responsive output on a variety of devices without requiring high-end hardware. 

### Orca 2
- https://arxiv.org/pdf/2311.11045.pdf
- https://huggingface.co/microsoft/Orca-2-13b

Orca 2 is built for research purposes only and provides a single turn response in tasks such as reasoning over user given data, reading comprehension, math problem solving and text summarization. The model is designed to excel particularly in reasoning.

### Mixtral 7b 8 Expert
- https://huggingface.co/DiscoResearch/mixtral-7b-8expert
- https://huggingface.co/mistralai/Mixtral-8x7B-Instruct-v0.1
- https://replicate.com/nateraw/mixtral-8x7b-32kseqlen
- https://mistral.ai/news/mixtral-of-experts/


Mistral AI continues its mission to deliver the best open models to the developer community. Moving forward in AI requires taking new technological turns beyond reusing well-known architectures and training paradigms. Most importantly, it requires making the community benefit from original models to foster new inventions and usages.

Today, the team is proud to release Mixtral 8x7B, a high-quality sparse mixture of experts model (SMoE) with open weights. Licensed under Apache 2.0. Mixtral outperforms Llama 2 70B on most benchmarks with 6x faster inference. It is the strongest open-weight model with a permissive license and the best model overall regarding cost/performance trade-offs. In particular, it matches or outperforms GPT3.5 on most standard benchmarks.

Mixtral has the following capabilities.
- It gracefully handles a context of 32k tokens.
- It handles English, French, Italian, German and Spanish.
- It shows strong performance in code generation.
- It can be finetuned into an instruction-following model that achieves a score of 8.3 on MT-Bench.

### Phi
- https://huggingface.co/microsoft/phi-1_5
- https://arxiv.org/abs/2309.05463
- https://huggingface.co/microsoft/phi-1
- https://huggingface.co/microsoft/phi-2
- https://www.microsoft.com/en-us/research/blog/phi-2-the-surprising-power-of-small-language-models/

We are now releasing Phi-2(opens in new tab), a 2.7 billion-parameter language model that demonstrates outstanding reasoning and language understanding capabilities, showcasing state-of-the-art performance among base language models with less than 13 billion parameters. On complex benchmarks Phi-2 matches or outperforms models up to 25x larger, thanks to new innovations in model scaling and training data curation.

### LLM360ï¼ˆAmber,CrystalCoder,Diamondï¼‰
- https://www.llm360.ai/
- https://arxiv.org/pdf/2312.06550.pdf

The recent surge in open-source Large Language Models (LLMs), such as LLaMA, Falcon, and Mistral, provides diverse options for AI practitioners and researchers. However, most LLMs have only released partial artifacts, such as the final model weights or inference code, and technical reports increasingly limit their scope to high-level design choices and surface statistics. These choices hinder progress in the field by degrading transparency into the training of LLMs and forcing teams to rediscover many details in the training process. We present LLM360, an initiative to fully open-source LLMs, which advocates for all training code and data, model checkpoints, and intermediate results to be made available to the community. The goal of LLM360 is to support open and collaborative AI research by making the end-to-end LLM training process transparent and reproducible by everyone. As a first step of LLM360, we release two 7B parameter LLMs pre-trained from scratch, Amber and CrystalCoder, including their training code, data, intermediate checkpoints, and analyses (at this https URL). We are committed to continually pushing the boundaries of LLMs through this open-source effort. More large-scale and stronger models are underway and will be released in the future.

### Mamba
- https://github.com/state-spaces/mamba
- https://arxiv.org/abs/2312.00752

Mamba is a new state space model architecture showing promising performance on information-dense data such as language modeling, where previous subquadratic models fall short of Transformers. It is based on the line of progress on structured state space models, with an efficient hardware-aware design and implementation in the spirit of FlashAttention.

### SOLAR
- https://huggingface.co/upstage/SOLAR-10.7B-Instruct-v1.0

We introduce the first 10.7 billion (B) parameter model, SOLAR-10.7B. It's compact, yet remarkably powerful, and demonstrates unparalleled state-of-the-art performance in models with parameters under 30B.

We developed the Depth Up-Scaling technique. Built on the Llama2 architecture, SOLAR-10.7B incorporates the innovative Upstage Depth Up-Scaling. We then integrated Mistral 7B weights into the upscaled layers, and finally, continued pre-training for the entire model.

Depth-Upscaled SOLAR-10.7B has remarkable performance. It outperforms models with up to 30B parameters, even surpassing the recent Mixtral 8X7B model. For detailed information, please refer to the experimental table. Solar 10.7B is an ideal choice for fine-tuning. SOLAR-10.7B offers robustness and adaptability for your fine-tuning needs. Our simple instruction fine-tuning using the SOLAR-10.7B pre-trained model yields significant performance improvements.

### NexusRavenï¼ˆfunction calling LLMï¼‰
- https://huggingface.co/Nexusflow/NexusRaven-V2-13B

NexusRaven is an open-source and commercially viable function calling LLM that surpasses the state-of-the-art in function calling capabilities.

### LLaMA-MoE
- https://github.com/pjlab-sys4nlp/llama-moe

LLaMA-MoE is a series of open-sourced Mixture-of-Expert (MoE) models based on LLaMA and SlimPajama. We build LLaMA-MoE with the following two steps:
- Partition LLaMA's FFNs into sparse experts and insert top-K gate for each layer of experts.
- Continually pre-train the initialized MoE model with an optimized data sampling weights from Sheared LLaMA and filtered datasets from SlimPajama.

### TinyLlama
- https://github.com/jzhang38/TinyLlama/
- https://arxiv.org/pdf/2401.02385.pdf

TinyLlamaé¡¹ç›®æ—¨åœ¨åœ¨3ä¸‡äº¿tokensä¸Šè¿›è¡Œé¢„è®­ç»ƒï¼Œæ„å»ºä¸€ä¸ªæ‹¥æœ‰11äº¿å‚æ•°çš„Llamaæ¨¡å‹ã€‚ç»è¿‡ç²¾å¿ƒä¼˜åŒ–ï¼Œæˆ‘ä»¬"ä»…"éœ€16å—A100-40Gçš„GPUï¼Œä¾¿å¯åœ¨90å¤©å†…å®Œæˆè¿™ä¸ªä»»åŠ¡ğŸš€ğŸš€ã€‚è®­ç»ƒå·²äº2023-09-01å¼€å§‹ã€‚

æˆ‘ä»¬é‡‡ç”¨äº†ä¸Llama 2å®Œå…¨ç›¸åŒçš„æ¶æ„å’Œåˆ†è¯å™¨ã€‚è¿™æ„å‘³ç€TinyLlamaå¯ä»¥åœ¨è®¸å¤šåŸºäºLlamaçš„å¼€æºé¡¹ç›®ä¸­å³æ’å³ç”¨ã€‚æ­¤å¤–ï¼ŒTinyLlamaåªæœ‰1.1Bçš„å‚æ•°ï¼Œä½“ç§¯å°å·§ï¼Œé€‚ç”¨äºéœ€è¦é™åˆ¶è®¡ç®—å’Œå†…å­˜å ç”¨çš„å¤šç§åº”ç”¨ã€‚

## 4 è¯„ä»·

### å¤©ç§¤ï¼ˆFlagEvalï¼‰
- https://flageval.baai.ac.cn/#/home

å¤§è¯­è¨€è¯„æµ‹ä½“ç³»åŠå¼€æ”¾å¹³å°ï¼šæ„å»ºâ€œèƒ½åŠ›-ä»»åŠ¡-æŒ‡æ ‡â€ä¸‰ç»´è¯„æµ‹æ¡†æ¶ï¼Œç»†ç²’åº¦åˆ»ç”»æ¨¡å‹çš„è®¤çŸ¥èƒ½åŠ›è¾¹ç•Œã€‚

### ç¬è±¸ï¼ˆXiezhiï¼‰Benchmark
- https://arxiv.org/abs/2306.05783
- https://github.com/MikeGu721/XiezhiBenchmark

Xiezhiæ˜¯ä¸€ä¸ªç»¼åˆçš„ã€å¤šå­¦ç§‘çš„ã€èƒ½å¤Ÿè‡ªåŠ¨æ›´æ–°çš„é¢†åŸŸçŸ¥è¯†è¯„ä¼°Benchmarkã€‚XiezhiåŒ…å«äº†å“²å­¦ã€ç»æµå­¦ã€æ³•å­¦ã€æ•™è‚²å­¦ã€æ–‡å­¦ã€å†å²å­¦ã€è‡ªç„¶ç§‘å­¦ã€å·¥å­¦ã€å†œå­¦ã€åŒ»å­¦ã€å†›äº‹å­¦ã€ç®¡ç†å­¦ã€è‰ºæœ¯å­¦è¿™13ä¸ªå­¦ç§‘é—¨ç±»ï¼Œ24ä¸‡é“å­¦ç§‘é¢˜ç›®ï¼Œ516ä¸ªå…·ä½“å­¦ç§‘ï¼Œ249587é“é¢˜ç›®ã€‚è¿™ 516 ä¸ªå­¦ç§‘ä»¥åŠåˆ†ç±»æ–¹å¼æºè‡ªä¸­å›½æ•™è‚²éƒ¨é¢å¸ƒçš„å­¦ç§‘åˆ†ç±»æ³•ã€‚ä½œè€…ä»ä¸­å›½ç ”ç©¶ç”Ÿå…¥å­¦è€ƒè¯•ä¸­æ‰‹åŠ¨é€‰æ‹©å¹¶æ³¨é‡Šäº† 20,000 é“å¤šé€‰é¢˜ï¼Œæ¶µç›–äº†è¿™ 516 ä¸ªæ ‡ç­¾ï¼Œä»¥å½¢æˆXiezhi-Metaæ•°æ®é›†ã€‚Xiezhi-Metaè¢«ç”¨æ¥è®­ç»ƒä¸€ä¸ªèƒ½å¤Ÿè®¡ç®—é¢˜ç›®å’Œå­¦ç§‘æ ‡ç­¾ä¹‹é—´ç›¸å…³æ€§çš„æ ‡æ³¨æ¨¡å‹ã€‚ä½œè€…ä»¬éšåæ”¶é›†äº†æ¥è‡ªä¸åŒè€ƒè¯•çš„ 150,000 ä¸ªå¤šé¡¹é€‰æ‹©é¢˜ï¼Œä»¥åŠæ¥è‡ªå­¦æœ¯Surveyçš„ 70,000 ä¸ªå¤šé¡¹é€‰æ‹©é¢˜ï¼Œå¹¶ä½¿ç”¨æ ‡æ³¨æ¨¡å‹å¯¹æ‰€æœ‰è¿™äº›é—®é¢˜è¿›è¡Œäº†æ³¨é‡Šã€‚

ä¸ºäº†æ–¹ä¾¿è¿›è¡Œå®éªŒï¼Œå¹¶èƒ½å¤Ÿæœ‰æ•ˆåœ°è¯„ä¼°LLMå¯¹äºè·¨å­¦ç§‘çŸ¥è¯†çš„å¤„ç†èƒ½åŠ›ï¼Œä½œè€…ä»¬æå‡ºäº†Xiezhi-Specialtyå’ŒXiezhi-Interdisciplineï¼Œè¿™ä¸¤ä¸ªæ•°æ®é›†éƒ½æä¾›äº†ä¸­è‹±æ–‡çš„ç‰ˆæœ¬ï¼Œå¹¶ç”± 15,000 ä¸ªæ›´å¹³è¡¡ã€æ›´ä¸æ•æ„Ÿã€æ›´ä¸ä»¥ä¸­å›½ä¸ºä¸­å¿ƒçš„å¤šé€‰é¢˜ç»„æˆã€‚ Xiezhi-Specialty åŒ…å«å¯ä»¥ä½¿ç”¨å•ä¸€é¢†åŸŸçš„çŸ¥è¯†è§£å†³çš„é—®é¢˜ï¼Œè€Œ Xiezhi-Interdiscipline åŒ…å«éœ€è¦æ¥è‡ªå¤šä¸ªé¢†åŸŸçš„çŸ¥è¯†æ‰èƒ½è§£å†³çš„é—®é¢˜ã€‚

### C-Eval: A Multi-Level Multi-Discipline Chinese Evaluation Suite for Foundation Models
- https://arxiv.org/abs/2305.08322
- https://cevalbenchmark.com/
- https://github.com/SJTU-LIT/ceval

C-Eval is a comprehensive Chinese evaluation suite for foundation models. It consists of 13948 multi-choice questions spanning 52 diverse disciplines and four difficulty levels.

### HaluEval: A Large-Scale Hallucination Evaluation Benchmark for Large Language Models
- https://mp.weixin.qq.com/s/cuoO2V4X-GQOuWyA-e9BeQ
- https://arxiv.org/abs/2305.11747
- https://github.com/RUCAIBox/HaluEval

ä¸ºäº†è¿›ä¸€æ­¥ç ”ç©¶å¤§æ¨¡å‹å¹»è±¡çš„å†…å®¹ç±»å‹å’Œå¤§æ¨¡å‹ç”Ÿæˆå¹»è±¡çš„åŸå› ï¼Œæœ¬æ–‡æå‡ºäº†ç”¨äºå¤§è¯­è¨€æ¨¡å‹å¹»è±¡è¯„ä¼°çš„åŸºå‡†â€”â€”HaluEvalã€‚æˆ‘ä»¬åŸºäºç°æœ‰çš„æ•°æ®é›†ï¼Œé€šè¿‡è‡ªåŠ¨ç”Ÿæˆå’Œæ‰‹åŠ¨æ ‡æ³¨çš„æ–¹å¼æ„å»ºäº†å¤§é‡çš„å¹»è±¡æ•°æ®ç»„æˆHaluEvalçš„æ•°æ®é›†ï¼Œå…¶ä¸­åŒ…å«ç‰¹å®šäºé—®ç­”ã€å¯¹è¯ã€æ–‡æœ¬æ‘˜è¦ä»»åŠ¡çš„30000æ¡æ ·æœ¬ä»¥åŠæ™®é€šç”¨æˆ·æŸ¥è¯¢çš„5000æ¡æ ·æœ¬ã€‚åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬è¯¦ç»†ä»‹ç»äº†HaluEvalæ•°æ®é›†çš„æ„å»ºè¿‡ç¨‹ï¼Œå¯¹æ„å»ºçš„æ•°æ®é›†è¿›è¡Œäº†å†…å®¹åˆ†æï¼Œå¹¶åˆæ­¥æ¢ç´¢äº†å¤§æ¨¡å‹è¯†åˆ«å’Œå‡å°‘å¹»è±¡çš„ç­–ç•¥ã€‚

### KoLA: Carefully Benchmarking World Knowledge of Large Language Models
- https://mp.weixin.qq.com/s/xVj1blhRtpO-Y1HgQ8Wl-A
- https://arxiv.org/pdf/2306.09296.pdf
- https://kola.xlore.cn

KoLAåŸºäº19ä¸ªå…³æ³¨å®ä½“ã€æ¦‚å¿µå’Œäº‹ä»¶çš„ä»»åŠ¡ã€‚å‚è€ƒäº†Bloomè®¤çŸ¥ä½“ç³»ï¼ŒKoLAä»çŸ¥è¯†çš„è®°å¿†ã€ç†è§£ã€åº”ç”¨å’Œåˆ›é€ 4ä¸ªå±‚çº§ï¼Œä»æ·±åº¦è€Œéå¹¿åº¦å»è¡¡é‡å¤§è¯­è¨€æ¨¡å‹å¤„ç†ä¸–ç•ŒçŸ¥è¯†çš„èƒ½åŠ›ã€‚å®éªŒç»“æœè¡¨æ˜ï¼ŒGPT-4è™½ç„¶å¾ˆå¼ºï¼Œä½†ä¾ç„¶æœªèƒ½éœ¸æ¦œï¼Œåœ¨çŸ¥è¯†åˆ›é€ å±‚æ¬¡çš„æµ‹è¯•ä¸­ä»…æ’ç¬¬ä¸‰åã€‚

### LucyEvalâ€”ä¸­æ–‡å¤§è¯­è¨€æ¨¡å‹æˆç†Ÿåº¦è¯„æµ‹
- https://mp.weixin.qq.com/s/-K7wmnaTdEexlAoTB47mFw
- http://lucyeval.besteasy.com/
- https://arxiv.org/abs/2308.04823

æœ¬è¯„æµ‹åŸºå‡†åŒ…å«11000é“ä¸åŒç±»å‹çš„é¢˜ç›®ï¼Œæ¶µç›–ç§‘æŠ€å·¥ç¨‹ã€äººæ–‡ä¸ç¤¾ä¼šç§‘å­¦ã€æ•°å­¦è®¡ç®—ã€åŒ»å¸ˆèµ„æ ¼è€ƒè¯•ã€å¸æ³•è€ƒè¯•ã€æ³¨å†Œä¼šè®¡å¸ˆè€ƒè¯•ç­‰ç§‘ç›®ä¸‹çš„55ä¸ªå­ç§‘ç›®ï¼Œç”±ç”²éª¨æ˜“AIç ”ç©¶é™¢äººå·¥æ•´ç†æ ‡æ³¨ã€‚é¢˜ç›®åˆ†ä¸ºåè¯è§£é‡Šã€ç®€ç­”é¢˜å’Œè®¡ç®—é¢˜ä¸‰ç§ç±»å‹ã€‚åŒæ—¶ï¼Œç”²éª¨æ˜“AIç ”ç©¶é™¢è¿˜è®¾è®¡äº†ä¸€å¥—å¤åˆæ‰“åˆ†æ–¹å¼ï¼Œä½¿è¯„åˆ†è¿‡ç¨‹æ›´åŠ åˆç†ã€ç§‘å­¦ã€‚

### CMB: A Comprehensive Medical Benchmark in Chinese
- https://mp.weixin.qq.com/s/M8V-XaCRuk-UkAhqBkPgGg
- https://arxiv.org/abs/2308.08833
- https://github.com/FreedomIntelligence/CMB
- https://cmedbenchmark.llmzoo.com/

æˆ‘ä»¬æå‡ºäº†ä¸­æ–‡åŒ»ç–—æ¨¡å‹è¯„ä¼°åŸºå‡† CMBï¼Œå…¶åŒ…æ‹¬äº†ä¸åŒä¸´åºŠèŒä¸šã€ä¸åŒèŒä¸šé˜¶æ®µè€ƒè¯•ä¸­çš„å¤šé¡¹é€‰æ‹©é¢˜ï¼ˆCMB-Examï¼‰å’ŒåŸºäºçœŸå®ç—…ä¾‹çš„å¤æ‚ä¸´åºŠè¯Šæ–­é—®é¢˜ï¼ˆCMB-Clinï¼‰ã€‚é€šè¿‡æµ‹è¯„å®éªŒ,æˆ‘ä»¬å‘ç°ï¼šï¼ˆ1ï¼‰GPT-4 åœ¨åŒ»å­¦é¢†åŸŸè¡¨ç°å‡ºæ˜¾è‘—ä¼˜è¶Šæ€§ï¼Œäºæ­¤åŒæ—¶ä¸­æ–‡é€šç”¨å¤§æ¨¡å‹ä¹Ÿè¡¨ç°å¾—ç›¸å½“å‡ºè‰²ï¼›ï¼ˆ2ï¼‰åŒ»ç–—å¤§æ¨¡å‹åœ¨æ€§èƒ½æ–¹é¢ä»ç„¶è½åäºé€šç”¨æ¨¡å‹ï¼Œè¿˜æœ‰å¾ˆå¤§çš„æå‡ç©ºé—´ï¼ˆ3ï¼‰æœ‰å‚è€ƒç­”æ¡ˆå’Œè¯„åˆ†æ ‡å‡†çš„é—®è¯Šè‡ªåŠ¨è¯„ä¼°ä¸ä¸“å®¶è¯„ä¼°é«˜åº¦å¯¹é½ï¼Œæä¾›äº†ä¸€ä¸ªåŒ»å­¦é¢†åŸŸè¶…çº§å¯¹é½çš„åˆæ­¥å°è¯•ã€‚

### Multiscale Positive-Unlabeled Detection of AI-Generated Texts
- https://mp.weixin.qq.com/s/KBN8TMwXD1bcE2X_dImXVg
- https://arxiv.org/abs/2305.18149
- https://github.com/mindspore-lab/mindone/tree/master/examples/detect_chatgpt
- https://github.com/YuchuanTian/AIGC_text_detector

Recent releases of Large Language Models (LLMs), e.g. ChatGPT, are astonishing at generating human-like texts, but they may get misused for fake scholarly texts, fake news, fake tweets, et cetera. Previous works have proposed methods to detect these multiscale AI-generated texts, including simple ML classifiers, pretrained-model-based training-agnostic methods, and finetuned language classification models. However, mainstream detectors are formulated without considering the factor of corpus length: shorter corpuses are harder to detect compared with longer ones for shortage of informative features. In this paper, a Multiscale Positive-Unlabeled (MPU) training framework is proposed to address the challenge of multiscale text detection. Firstly, we acknowledge the human-resemblance property of short machine texts, and rephrase text classification as a Positive-Unlabeled (PU) problem by marking these short machine texts as "unlabeled" during training. In this PU context, we propose the length-sensitive Multiscale PU Loss, where we use a recurrent model in abstraction to estimate positive priors of scale-variant corpuses. Additionally, we introduce a Text Multiscaling module to enrich training corpuses. Experiments show that our MPU method augments detection performance on long AI-generated text, and significantly improves short-corpus detection of language model detectors. Language Models trained with MPU could outcompete existing detectors by large margins on multiscale AI-generated texts. 

### PandaLM
- https://github.com/WeOpenML/PandaLM
- https://zhuanlan.zhihu.com/p/630173415
- https://mp.weixin.qq.com/s/HE6jez3G9aEO5qLkvwtKXg

This is the official repository for PandaLM: ReProducible and Automated Language Model Assessment.

PandaLM aims to provide reproducible and automated comparisons between different large language models (LLMs). By giving PandaLM the same context, it can compare the responses of different LLMs and provide a reason for the decision, along with a reference answer. The target audience for PandaLM may be organizations that have confidential data and research labs with limited funds that seek reproducibility. These organizations may not want to disclose their data to third parties or may not be able to afford the high costs of secret data leakage using third-party APIs or hiring human annotators. With PandaLM, they can perform evaluations without compromising data security or incurring high costs, and obtain reproducible results. To demonstrate the reliability and consistency of our tool, we have created a diverse human-annotated test dataset of approximately 1,000 samples, where the contexts and the labels are all created by humans. On our test dataset, PandaLM-7B has achieved 94% ChatGPT's evaluation ability in terms of accuracy. The papers and more features are coming soon.

### Auto-J
- https://gair-nlp.github.io/auto-j/
- https://github.com/GAIR-NLP/auto-j
- https://arxiv.org/abs/2310.05470

We develop Auto-J, a new open-source generative judge that can effectively evaluate different LLMs on how they align to human preference. It is featured with:
- Generality: Auto-J is trained on data from real-world user queries and responses from various LLMs, covering a wide range of 58 real-world scenarios.
- Flexibility: Auto-J supports both pairwise response comparison and single-response evaluation by just switching to corresponding prompts.
- Interpretability: Auto-J provides detailed critiques that enhance the reliability of its evaluation outcomes and facilitate humans' involvement in the evaluation loop.

### CLEVA: Chinese Language Models EVAluation Platform
- https://arxiv.org/abs/2308.04813
- https://github.com/LaVi-Lab/CLEVA

CLEVA is a Chinese Language Models EVAluation Platform developed by CUHK LaVi Lab. CLEVA would like to thank Shanghai AI Lab for the great collaboration in the process. The main features of CLEVA include:

- A comprehensive Chinese Benchmark, featuring 31 tasks (11 application assessments + 20 ability evaluation tasks), with a total of 370K Chinese test samples (33.98% are newly collected, mitigating data contamination issues);
- A standardized Prompt-Based Evaluation Methodology, incorporating unified pre-processing for all data and using a consistent set of Chinese prompt templates for evaluation.
- A trustworthy Leaderboard, as CLEVA uses a significant amount of new data to minimize data contamination and regularly organizes evaluations.

The leaderboard is evaluated and maintained by CLEVA using new test data. Past leaderboard data (processed test samples, annotated prompt templates, etc.) are made available to users for local evaluation runs.

### ALCUNA: Large Language Models Meet New Knowledge
- https://github.com/arvid-pku/alcuna

With the rapid development of NLP, large-scale language models (LLMs) excel in various tasks across multiple domains now. However, existing benchmarks may not adequately measure these models' capabilities, especially when faced with new knowledge. In this paper, we address the lack of benchmarks to evaluate LLMs' ability to handle new knowledge, an important and challenging aspect in the rapidly evolving world. We propose an approach called KnowGen that generates new knowledge by altering existing entity attributes and relationships, resulting in artificial entities that are distinct from real-world entities. With KnowGen, we introduce a benchmark named ALCUNA to assess LLMs' abilities in knowledge understanding, differentiation, and association. We benchmark several LLMs, reveals that their performance in face of new knowledge is not satisfactory, particularly in reasoning between new and internal knowledge. We also explore the impact of entity similarity on the model's understanding of entity knowledge and the influence of contextual entities. We appeal to the need for caution when using LLMs in new scenarios or with new knowledge, and hope that our benchmarks can help drive the development of LLMs in face of new knowledge.

### HalluQAï¼šEvaluating Hallucinations in Chinese Large Language Models
- https://github.com/xiami2019/HalluQA/

Evaluating Hallucinations in Chinese Large Language Models

HalluQA contains 450 meticulously designed adversarial questions, spanning multiple domains, and takes into account Chinese historical culture, customs, and social phenomena. The pipeline of data collection is shown above. At step 1, we write questions which we think may induce model hallucinations. At step 2, we use ChatGPT3.5/Puyu/GLM-130B to generate answers and collect adversarial questions. At step 3, we write multiple correct and wrong answers for each adversarial question and add support evidence. At step 4, we check all annotated question-answer pairs and remove low quality samples.

### GLoRE: Evaluating Logical Reasoning of Large Language Models  
- https://arxiv.org/abs/2310.09107

Recently, large language models (LLMs), including notable models such as GPT-4 and burgeoning community models, have showcased significant general language understanding abilities. However, there has been a scarcity of attempts to assess the logical reasoning capacities of these LLMs, an essential facet of natural language understanding. To encourage further investigation in this area, we introduce GLoRE, a meticulously assembled General Logical Reasoning Evaluation benchmark comprised of 12 datasets that span three different types of tasks. Our experimental results show that compared to the performance of human and supervised fine-tuning, the logical reasoning capabilities of open LLM models necessitate additional improvement; ChatGPT and GPT-4 show a strong capability of logical reasoning, with GPT-4 surpassing ChatGPT by a large margin. We propose a self-consistency probing method to enhance the accuracy of ChatGPT and a fine-tuned method to boost the performance of an open LLM. We release the datasets and evaluation programs to facilitate future research.

### HelpSteer
- https://huggingface.co/datasets/nvidia/HelpSteer

HelpSteer is an open-source Helpfulness Dataset (CC-BY-4.0) that supports aligning models to become more helpful, factually correct and coherent, while being adjustable in terms of the complexity and verbosity of its responses.

Leveraging this dataset and SteerLM, we train a Llama 2 70B to reach 7.54 on MT Bench, the highest among models trained on open-source datasets based on MT Bench Leaderboard as of 15 Nov 2023.

### AlignBench: å¤šç»´åº¦ä¸­æ–‡å¯¹é½è¯„æµ‹åŸºå‡†
- https://github.com/THUDM/AlignBench

AlignBench æ˜¯ç¬¬ä¸€ä¸ªå¤šç»´åº¦å…¨é¢è¯„ä¼°ä¸­æ–‡å¤§æ¨¡å‹å¯¹é½æ°´å¹³çš„è¯„æµ‹åŸºå‡†ã€‚æ­¤ä»“åº“åŒ…å«äº† AlignBench çš„ä»‹ç»ä¿¡æ¯ã€æ•°æ®å’Œä»£ç ã€‚

### UHGEval
- https://github.com/IAAR-Shanghai/UHGEval
- https://arxiv.org/abs/2311.15296

Benchmarking the Hallucination of Chinese Large Language Models via Unconstrained Generation

- Safety: Ensuring the security of experimental data is of utmost importance.
- Flexibility: Easily expandable, with all modules replaceable.

### Purple Llama (Meta)
- https://ai.meta.com/blog/purple-llama-open-trust-safety-generative-ai/

Weâ€™re announcing Purple Llama, an umbrella project featuring open trust and safety tools and evaluations meant to level the playing field for developers to responsibly deploy generative AI models and experiences in accordance with best practices shared in our Responsible Use Guide.

### OMGEval
- https://github.com/blcuicall/OMGEval

è¿‘ä¸€å¹´ï¼Œå¤§æ¨¡å‹å‘å±•è¿…é€Ÿï¼Œå¸¦åŠ¨äº†â¼€ç³»åˆ—é€šç”¨äººå·¥æ™ºèƒ½æŠ€æœ¯çš„è¿…é€Ÿå‘å±•ï¼Œå¯¹å¤§æ¨¡å‹æ€§èƒ½çš„è¯„æµ‹éšä¹‹æ¶Œç°ã€‚

ä»è¯„æµ‹èƒ½åŠ›ä¸Šæ¥çœ‹ï¼Œç”±äºç›®å‰çš„è¯„æµ‹æ•°æ®é›†ä¸»è¦æ˜¯åˆ©ç”¨äººç±»è¯•é¢˜åŠå…¶æ ‡å‡†ç­”æ¡ˆè¿›è¡Œè¯„æµ‹ï¼Œè¿™ç§è¯„ä»·æ–¹å¼æ›´åå‘å¯¹æ¨ç†èƒ½åŠ›çš„è¯„ä¼°ï¼Œå­˜åœ¨è¯„ä¼°ç»“æœå’Œæ¨¡å‹çœŸå®èƒ½åŠ›æœ‰â¼€å®šåå·®ã€‚ä¾‹å¦‚ï¼Œè‹±æ–‡æ•°æ®é›†ä¸­ï¼ŒHELM1ä½¿ç”¨16ä¸ªNLPæ•°æ®é›†ï¼ŒMMLU2ç”¨57é¡¹äººç±»è€ƒè¯•ç§‘ç›®æ¥è¯„æµ‹å¤§æ¨¡å‹ã€‚ä¸­æ–‡æ•°æ®é›†ä¸­ï¼ŒGAOKAO3ã€C-Eval4ç­‰ä¹Ÿé‡‡ç”¨äººç±»è¯•é¢˜ï¼Œä»–ä»¬åœ¨è‡ªåŠ¨åŒ–è¯„æµ‹æµç¨‹ä¸­éƒ½åªåŒ…å«æœ‰æ ‡å‡†ç­”æ¡ˆçš„é—®é¢˜ï¼Œæ— æ³•å…¨é¢è¡¡é‡ç”Ÿæˆå¼å¤§æ¨¡å‹çš„ç»¼åˆèƒ½åŠ›ã€‚

æ­¤å¤–ï¼Œç›®å‰ä¹Ÿæœ‰ä¸€äº›å·¥ä½œå…³æ³¨åˆ°äº†æ¨¡å‹çš„å¼€æ”¾å¼é—®ç­”ï¼Œç”±æ–¯å¦ç¦å¤§å­¦æå‡ºçš„çš„AlpacaEval5è¢«å¹¿æ³›è®¤å¯ï¼Œä½†ä»…ç”±è‹±æ–‡é—®é¢˜ç»„æˆï¼Œå†³å®šäº†åªèƒ½è¯„ä¼°æ¨¡å‹åœ¨è‹±æ–‡ä¸Šçš„è¡¨ç°ã€‚åŒ…å«ä¸­æ–‡å¼€æ”¾å¼é—®ç­”çš„SuperCLUE6æ•°æ®é›†æ˜¯é¦–ä¸ªæå‡ºå¼€æ”¾å¼é—®ç­”çš„ä¸­æ–‡æ•°æ®é›†ï¼Œä½†å…¶æ•°æ®é›†é—­æºï¼Œä¸”ä¹Ÿä»…ç”±ä¸­æ–‡é—®é¢˜ç»„æˆã€‚å¯ä»¥çœ‹åˆ°ï¼Œç›®å‰å·²æœ‰çš„å¼€æ”¾å¼é—®é¢˜æ•°æ®é›†éƒ½æ˜¯åœ¨å•ä¸€è¯­è¨€ä¸Šè¿›è¡Œè¯„æµ‹çš„ï¼Œç”¨æ¥è¡¡é‡æ¨¡å‹çš„å¤šè¯­è¨€èƒ½åŠ›çš„å¼€æºçš„å¼€æ”¾å¼é—®ç­”æ•°æ®é›†ä»ç„¶ç©ºç¼ºã€‚

ç»¼ä¸Šæ‰€è¿°ï¼Œæ„å»ºä¸€ä¸ªå¤šè¯­è¨€çš„å¼€æ”¾å¼é—®ç­”æ•°æ®é›†ç”¨ä»¥å…¨é¢è¯„æµ‹å¤§æ¨¡å‹çš„ç»¼åˆèƒ½åŠ›æ˜¯æœ‰å¿…è¦çš„ã€‚æˆ‘ä»¬å°†ä»ä¸­æ–‡å…¥æ‰‹ï¼Œé€æ¸è¿ç§»è‡³å…¶ä»–è¯­è¨€ã€‚

### SciGuard&SciMT-Safety
- https://arxiv.org/abs/2312.06632
- https://github.com/SciMT/SciMT-benchmark

The expanding application of Artificial Intelligence (AI) in scientific fields presents unprecedented opportunities for discovery and innovation. However, this growth is not without risks. AI models in science, if misused, can amplify risks like creation of harmful substances, or circumvention of established regulations. In this study, we aim to raise awareness of the dangers of AI misuse in science, and call for responsible AI development and use in this domain. We first itemize the risks posed by AI in scientific contexts, then demonstrate the risks by highlighting real-world examples of misuse in chemical science. These instances underscore the need for effective risk management strategies. In response, we propose a system called SciGuard to control misuse risks for AI models in science. We also propose a red-teaming benchmark SciMT-Safety to assess the safety of different systems. Our proposed SciGuard shows the least harmful impact in the assessment without compromising performance in benign tests. Finally, we highlight the need for a multidisciplinary and collaborative effort to ensure the safe and ethical use of AI models in science. We hope that our study can spark productive discussions on using AI ethically in science among researchers, practitioners, policymakers, and the public, to maximize benefits and minimize the risks of misuse.

### HaluEval 2.0, The Dawn After the Dark: An Empirical Study on Factuality Hallucination in Large Language Models
- https://github.com/RUCAIBox/HaluEval-2.0
- https://arxiv.org/abs/2401.03205

In the era of large language models (LLMs), hallucination (i.e., the tendency to generate factually incorrect content) poses great challenge to trustworthy and reliable deployment of LLMs in real-world applications. To tackle the LLM hallucination, three key questions should be well studied: how to detect hallucinations (detection), why do LLMs hallucinate (source), and what can be done to mitigate them (mitigation). To address these challenges, this work presents a systematic empirical study on LLM hallucination, focused on the the three aspects of hallucination detection, source and mitigation. Specially, we construct a new hallucination benchmark HaluEval 2.0, and designs a simple yet effective detection method for LLM hallucination. Furthermore, we zoom into the different training or utilization stages of LLMs and extensively analyze the potential factors that lead to the LLM hallucination. Finally, we implement and examine a series of widely used techniques to mitigate the hallucinations in LLMs. Our work has led to several important findings to understand the hallucination origin and mitigate the hallucinations in LLMs. 

### DebugBench: Evaluating Debugging Capability of Large Language Models
- https://github.com/thunlp/DebugBench
- https://arxiv.org/abs/2401.04621

Large Language Models (LLMs) have demonstrated exceptional coding capability. However, as another critical component of programming proficiency, the debugging capability of LLMs remains relatively unexplored. Previous evaluations of LLMs' debugging ability are significantly limited by the risk of data leakage, the scale of the dataset, and the variety of tested bugs. To overcome these deficiencies, we introduce `DebugBench', an LLM debugging benchmark consisting of 4,253 instances. It covers four major bug categories and 18 minor types in C++, Java, and Python. To construct DebugBench, we collect code snippets from the LeetCode community, implant bugs into source data with GPT-4, and assure rigorous quality checks. We evaluate two commercial and three open-source models in a zero-shot scenario. We find that (1) while closed-source models like GPT-4 exhibit inferior debugging performance compared to humans, open-source models such as Code Llama fail to attain any pass rate scores; (2) the complexity of debugging notably fluctuates depending on the bug category; (3) incorporating runtime feedback has a clear impact on debugging performance which is not always helpful. As an extension, we also compare LLM debugging and code generation, revealing a strong correlation between them for closed-source models. These findings will benefit the development of LLMs in debugging.

### GenMedicalEval
- https://github.com/MediaBrain-SJTU/GenMedicalEval

ä¸€ä¸ªåŒ»ç–—å¤§è¯­è¨€æ¨¡å‹çš„ç»¼åˆè¯„æµ‹æ¡†æ¶ã€‚

### R-Judge
- https://github.com/Lordog/R-Judge
- https://arxiv.org/abs/2401.10019

Large language models (LLMs) have exhibited great potential in autonomously completing tasks across real-world applications. Despite this, these LLM agents introduce unexpected safety risks when operating in interactive environments. Instead of centering on LLM-generated content safety in most prior studies, this work addresses the imperative need for benchmarking the behavioral safety of LLM agents within diverse environments. We introduce R-Judge, a benchmark crafted to evaluate the proficiency of LLMs in judging safety risks given agent interaction records. R-Judge comprises 162 agent interaction records, encompassing 27 key risk scenarios among 7 application categories and 10 risk types. It incorporates human consensus on safety with annotated safety risk labels and high-quality risk descriptions. Utilizing R-Judge, we conduct a comprehensive evaluation of 8 prominent LLMs commonly employed as the backbone for agents. The best-performing model, GPT-4, achieves 72.29% in contrast to the human score of 89.38%, showing considerable room for enhancing the risk awareness of LLMs. Notably, leveraging risk descriptions as environment feedback significantly improves model performance, revealing the importance of salient safety risk feedback. Furthermore, we design an effective chain of safety analysis technique to help the judgment of safety risks and conduct an in-depth case study to facilitate future research.

### TravelPlanner
- https://osu-nlp-group.github.io/TravelPlanner/

We introduce TravelPlanner: a comprehensive benchmark designed to evaluate the planning abilities of language agents in real-world scenarios across multiple dimensions. Without losing generality, TravelPlanner casts travel planning as its test environment, with all relevant information meticulously crafted to minimize data contamination. TravelPlanner does not have a singular ground truth for each query. Instead, the benchmark employs several pre-defined evaluation scripts to assess each tested plan, determining whether the language agent can effectively use tools to create a plan that aligns with both the implicit commonsense and explicit user needs outlined in the query (i.e., commonsense constraint and hard constraint). Every query in TravelPlanner has undergone thorough human verification to guarantee that feasible solutions exist. Additionally, TravelPlanner evaluates the language agent's capability by varying the breadth and depth of planning, controlled through the number of travel days and the quantity of hard constraints.

### EasyJailbreak
- https://github.com/EasyJailbreak/EasyJailbreak
- http://easyjailbreak.cn/
- https://easyjailbreak.github.io/EasyJailbreakDoc.github.io/

EasyJailbreak is an easy-to-use Python framework designed for researchers and developers focusing on LLM security. Specifically, EasyJailbreak decomposes the mainstream jailbreaking process into several iterable steps: initialize mutation seeds, select suitable seeds, add constraint, mutate, attack, and evaluate. On this basis, EasyJailbreak provides a component for each step, constructing a playground for further research and attempts. More details can be found in our paper.

## 5 æ–‡æœ¬å‘é‡
### Matryoshka Representation Learning
- https://arxiv.org/abs/2205.13147
- https://github.com/RAIVNLab/MRL

Learned representations are a central component in modern ML systems, serving a multitude of downstream tasks. When training such representations, it is often the case that computational and statistical constraints for each downstream task are unknown. In this context rigid, fixed capacity representations can be either over or under-accommodating to the task at hand. This leads us to ask: can we design a flexible representation that can adapt to multiple downstream tasks with varying computational resources? Our main contribution is Matryoshka Representation Learning (MRL) which encodes information at different granularities and allows a single embedding to adapt to the computational constraints of downstream tasks. MRL minimally modifies existing representation learning pipelines and imposes no additional cost during inference and deployment. MRL learns coarse-to-fine representations that are at least as accurate and rich as independently trained low-dimensional representations. The flexibility within the learned Matryoshka Representations offer: (a) up to 14x smaller embedding size for ImageNet-1K classification at the same level of accuracy; (b) up to 14x real-world speed-ups for large-scale retrieval on ImageNet-1K and 4K; and (c) up to 2% accuracy improvements for long-tail few-shot classification, all while being as robust as the original representations. Finally, we show that MRL extends seamlessly to web-scale datasets (ImageNet, JFT) across various modalities -- vision (ViT, ResNet), vision + language (ALIGN) and language (BERT).

### Jina Embeddings
- https://huggingface.co/jinaai

æ­£å¼å¼€æºäº†ä¸¤æ¬¾åŒè¯­å‘é‡æ¨¡å‹ï¼šä¸­è‹±åŒè¯­ï¼ˆChinese-Englishï¼‰å’Œè‹±å¾·åŒè¯­ï¼ˆEnglish-Germanï¼‰å‘é‡æ¨¡å‹ï¼Œè¿™ä¹Ÿæ˜¯å…¨çƒé¦–æ¬¡æ¨å‡ºæ”¯æŒ 8K åŒè¯­æ–‡æœ¬çš„å¼€æºå‘é‡æ¨¡å‹ã€‚

### BGE-M3
- https://github.com/FlagOpen/FlagEmbedding
- https://huggingface.co/BAAI/bge-m3

In this project, we introduce BGE-M3, which is distinguished for its versatility in Multi-Functionality, Multi-Linguality, and Multi-Granularity.

- Multi-Functionality: It can simultaneously perform the three common retrieval functionalities of embedding model: dense retrieval, multi-vector retrieval, and sparse retrieval.
- Multi-Linguality: It can support more than 100 working languages.
- Multi-Granularity: It is able to process inputs of different granularities, spanning from short sentences to long documents of up to 8192 tokens.

### Nomic Embed
- https://github.com/nomic-ai/contrastors
- https://static.nomic.ai/reports/2024_Nomic_Embed_Text_Technical_Report.pdf
- https://arxiv.org/abs/2402.01613
- https://huggingface.co/nomic-ai/nomic-embed-text-v1.5

This technical report describes the training of nomic-embed-text-v1, the first fully reproducible, open-source, open-weights, open-data, 8192 context length English text embedding model that outperforms both OpenAI Ada-002 and OpenAI text-embedding-3-small on short and long-context tasks. We release the training code and model weights under an Apache 2 license. In contrast with other open-source models, we release a training data loader with 235 million curated text pairs that allows for the full replication of nomic-embed-text-v1.

### Moka Massive Mixed Embeddingï¼ˆM3Eï¼‰
- https://huggingface.co/moka-ai/m3e-small

- Mokaï¼Œæ­¤æ¨¡å‹ç”± MokaAI è®­ç»ƒï¼Œå¼€æºå’Œè¯„æµ‹ï¼Œè®­ç»ƒè„šæœ¬ä½¿ç”¨ uniem ï¼Œè¯„æµ‹ BenchMark ä½¿ç”¨ MTEB-zh
- Massiveï¼Œæ­¤æ¨¡å‹é€šè¿‡åƒä¸‡çº§ (2200w+) çš„ä¸­æ–‡å¥å¯¹æ•°æ®é›†è¿›è¡Œè®­ç»ƒ
- Mixedï¼Œæ­¤æ¨¡å‹æ”¯æŒä¸­è‹±åŒè¯­çš„åŒè´¨æ–‡æœ¬ç›¸ä¼¼åº¦è®¡ç®—ï¼Œå¼‚è´¨æ–‡æœ¬æ£€ç´¢ç­‰åŠŸèƒ½ï¼Œæœªæ¥è¿˜ä¼šæ”¯æŒä»£ç æ£€ç´¢
- Embeddingï¼Œæ­¤æ¨¡å‹æ˜¯æ–‡æœ¬åµŒå…¥æ¨¡å‹ï¼Œå¯ä»¥å°†è‡ªç„¶è¯­è¨€è½¬æ¢æˆç¨ å¯†çš„å‘é‡

### GRIT
- https://arxiv.org/abs/2402.09906
- https://github.com/ContextualAI/gritlm

All text-based language problems can be reduced to either generation or embedding. Current models only perform well at one or the other. We introduce generative representational instruction tuning (GRIT) whereby a large language model is trained to handle both generative and embedding tasks by distinguishing between them through instructions. Compared to other open models, our resulting GritLM 7B sets a new state of the art on the Massive Text Embedding Benchmark (MTEB) and outperforms all models up to its size on a range of generative tasks. By scaling up further, GritLM 8x7B outperforms all open generative language models that we tried while still being among the best embedding models. Notably, we find that GRIT matches training on only generative or embedding data, thus we can unify both at no performance loss. Among other benefits, the unification via GRIT speeds up Retrieval-Augmented Generation (RAG) by > 60% for long documents, by no longer requiring separate retrieval and generation models.

## 6 å…¶å®ƒ
### Alpaca-CoT
- https://github.com/PhoebusSi/Alpaca-CoT
- https://mp.weixin.qq.com/s/Q5Q3RpQ80XmpbfhSxq2R1Q

An Instruction Fine-Tuning Platform with Instruction Data Collection and Unified Large Language Models Interface

Alpaca-CoTé¡¹ç›®æ—¨åœ¨æ¢ç©¶å¦‚ä½•æ›´å¥½åœ°é€šè¿‡instruction-tuningçš„æ–¹å¼æ¥è¯±å¯¼LLMå…·å¤‡ç±»ä¼¼ChatGPTçš„äº¤äº’å’Œinstruction-followingèƒ½åŠ›ã€‚ä¸ºæ­¤ï¼Œæˆ‘ä»¬å¹¿æ³›æ”¶é›†äº†ä¸åŒç±»å‹çš„instructionï¼ˆå°¤å…¶æ˜¯Chain-of-Thoughtæ•°æ®é›†ï¼‰ï¼Œå¹¶åŸºäºLLaMAç»™å‡ºäº†æ·±å…¥ç»†è‡´çš„å®è¯ç ”ç©¶ï¼Œä»¥ä¾›æœªæ¥å·¥ä½œå‚è€ƒã€‚æ®æˆ‘ä»¬æ‰€çŸ¥ï¼Œæˆ‘ä»¬æ˜¯é¦–ä¸ªå°†CoTæ‹“å±•è¿›Alpacaçš„å·¥ä½œï¼Œå› æ­¤ç®€ç§°ä¸º"Alpaca-CoT"ã€‚

### Auto-GPT
- https://github.com/torantulino/auto-gpt

Auto-GPT is an experimental open-source application showcasing the capabilities of the GPT-4 language model. This program, driven by GPT-4, chains together LLM "thoughts", to autonomously achieve whatever goal you set. As one of the first examples of GPT-4 running fully autonomously, Auto-GPT pushes the boundaries of what is possible with AI.

### ChatPiXiu
- https://github.com/catqaq/ChatPiXiu

æˆ‘ä»¬æ˜¯ç¾¡é±¼æ™ºèƒ½ã€xianyu.aiã€‘ï¼Œä¸»è¦æˆå‘˜æ˜¯ä¸€ç¾¤æ¥è‡ªè€å’Œå±±ä¸‹ã€è¥¿æ¹–è¾¹ä¸Šçš„å’¸é±¼ä»¬ï¼Œå¡˜ä¸»å«ä½œç¾¡é±¼ï¼Œæƒ³åœ¨LLMsæ—¶ä»£åšç‚¹æœ‰æ„ä¹‰çš„äº‹ï¼æˆ‘ä»¬çš„å£å·æ˜¯ï¼šåšOpenNLPå’ŒOpenXï¼å¸Œæœ›åœ¨CloseAIå·æ­»æˆ‘ä»¬ä¹‹å‰é€€å‡ºæ±Ÿæ¹–ï¼

ä¹Ÿè®¸æœ‰ä¸€å¤©ï¼Œç­‰åˆ°GPT-Xå‘å¸ƒçš„æ—¶å€™ï¼Œæœ‰äººä¼šè¯´NLPä¸å­˜åœ¨äº†ï¼Œä½†æ˜¯æˆ‘ä»¬æƒ³è¯æ˜æœ‰äººæ›¾ç»æ¥è¿‡ã€çƒ­çˆ±è¿‡ï¼åœ¨ä»¥ChatGPT/GPT4ä¸ºä»£è¡¨çš„LLMsæ—¶ä»£ï¼Œåœ¨è¢«CloseAIå·æ­»ä¹‹å‰ï¼Œæˆ‘ä»¬å‘èµ·äº†OpenNLPè®¡åˆ’ï¼Œå®—æ—¨æ˜¯OpenNLP for everyone!

ChatPiXiué¡¹ç›®ä¸ºOpenNLPè®¡åˆ’çš„ç¬¬2ä¸ªæ­£å¼çš„å¼€æºé¡¹ç›®ï¼Œæ—¨åœ¨Open ChatGPT for everyoneï¼åœ¨ä»¥ChatGPT/GPT4ä¸ºä»£è¡¨çš„LLMsæ—¶ä»£ï¼Œåœ¨è¢«OpenAIå·æ­»ä¹‹å‰ï¼Œåšä¸€ç‚¹æœ‰æ„ä¹‰çš„äº‹æƒ…ï¼æœªæ¥æœ‰ä¸€å¤©ï¼Œç­‰åˆ°GPT-Xå‘å¸ƒçš„æ—¶å€™ï¼Œæˆ–è®¸æœ‰äººä¼šè¯´NLPä¸å­˜åœ¨äº†ï¼Œä½†æ˜¯æˆ‘ä»¬æƒ³è¯æ˜æœ‰äººæ›¾æ¥è¿‡ï¼

### Gorilla
- https://mp.weixin.qq.com/s/p9tx3q3Lpr4fNqdyxWhzyA
- gorilla.cs.berkeley.edu
- arxiv.org/abs/2305.15334
- https://github.com/ShishirPatil/gorilla/

å¤§å‹è¯­è¨€æ¨¡å‹æ€§èƒ½å¼ºå¤§ï¼Œä½†ä¸ºäº†æ›´å¥½åœ°ç”¨äºè§£å†³å®é™…é—®é¢˜ï¼Œå„å¼å„æ ·çš„ API æ˜¯å¿…ä¸å¯å°‘çš„ã€‚

åŠ åˆ©ç¦å°¼äºšå¤§å­¦ä¼¯å…‹åˆ©åˆ†æ ¡å’Œå¾®è½¯ç ”ç©¶é™¢é€ å‡ºäº†ä¸€åªã€Œå¤§çŒ©çŒ©ã€Gorillaï¼Œè¯¥æ¨¡å‹èƒ½æ ¹æ®ç”¨æˆ·è¾“å…¥çš„è‡ªç„¶è¯­è¨€ä¸ºç”¨æˆ·é€‰æ‹©åˆé€‚çš„ API æ¥æ‰§è¡Œå¯¹åº”ä»»åŠ¡ã€‚ç†è®ºä¸Šè®²ï¼Œè¿™ä¸ªæ¨¡å‹å¯ä»¥æ ¹æ®ç”¨æˆ·éœ€æ±‚è°ƒç”¨å…¶å®ƒå„ç§ AI æ¨¡å‹ï¼Œå› æ­¤ Gorilla æœ‰æœ›æˆä¸ºä¸€ä¸ªç»Ÿå¾¡å…¶å®ƒ AI çš„ AI æ¨¡å‹ã€‚è¯¥é¡¹ç›®çš„ä»£ç ã€æ¨¡å‹ã€æ•°æ®å’Œæ¼”ç¤ºéƒ½å·²å‘å¸ƒã€‚

### HuggingGPT
- https://mp.weixin.qq.com/s/o51CmLt2JViJ4nsKfBJfwg
- https://arxiv.org/pdf/2303.17580.pdf

HuggingGPTåˆ©ç”¨ChatGPTä½œä¸ºæ§åˆ¶å™¨ï¼Œè¿æ¥HuggingFaceç¤¾åŒºä¸­çš„å„ç§AIæ¨¡å‹ï¼Œæ¥å®Œæˆå¤šæ¨¡æ€å¤æ‚ä»»åŠ¡ã€‚

è¿™æ„å‘³ç€ï¼Œä½ å°†æ‹¥æœ‰ä¸€ç§è¶…é­”æ³•ï¼Œé€šè¿‡HuggingGPTï¼Œä¾¿å¯æ‹¥æœ‰å¤šæ¨¡æ€èƒ½åŠ›ï¼Œæ–‡ç”Ÿå›¾ã€æ–‡ç”Ÿè§†é¢‘ã€è¯­éŸ³å…¨èƒ½æ‹¿æäº†ã€‚

### LLMPrunerï¼šå¤§è¯­è¨€æ¨¡å‹è£å‰ªå·¥å…·
- https://mp.weixin.qq.com/s/u0UcCxzJOkF4fO_JI6ToQA
- https://github.com/yangjianxin1/LLMPruner

åœ¨è®¸å¤šä¸‹æ¸¸ä»»åŠ¡ä¸­ï¼Œæˆ‘ä»¬å¾€å¾€åªéœ€è¦ä½¿ç”¨åˆ°ä¸€ä¸¤ç§è¯­è¨€ï¼Œä¾‹å¦‚åœ¨ä¸­æ–‡åœºæ™¯ä¸­ï¼Œä¸€èˆ¬åªä¼šç”¨åˆ°ä¸­è‹±æ–‡ã€‚ æ‰€ä»¥æˆ‘ä»¬å¯ä»¥å¯¹å¤§è¯­è¨€æ¨¡å‹çš„è¯è¡¨è¿›è¡Œè£å‰ªï¼Œåªç•™ä¸‹æ‰€éœ€çš„éƒ¨åˆ†è¯è¡¨ï¼Œè¿™æ ·ä¸ä»…èƒ½å¤Ÿå……åˆ†ä¿ç•™æ¨¡å‹çš„é¢„è®­ç»ƒçŸ¥è¯†ï¼Œå¹¶ä¸”å‡å°‘æ¨¡å‹å‚æ•°é‡ï¼Œé™ä½æ˜¾å­˜å ç”¨ï¼Œæå‡è®­ç»ƒé€Ÿåº¦ï¼Œä½¿ç”¨æ›´å°‘çš„æ˜¾å¡è¿›è¡Œä¸‹æ¸¸ä»»åŠ¡çš„finetuneè®­ç»ƒã€‚

åŸºäºä¸Šè¿°åŸå› ï¼Œç¬”è€…å¼€å‘äº†LLMPruneré¡¹ç›®ï¼Œç›®å‰ä¸»è¦åŒ…å«è£å‰ªåçš„å„ç§å‚æ•°è§„æ¨¡çš„Bloomæ¨¡å‹ã€‚å¯¹Bloomè¿›è¡Œè¯è¡¨è£å‰ªï¼Œä¿ç•™å¸¸ç”¨çš„ä¸­è‹±æ–‡tokenï¼Œè¯è¡¨ç”±250880å°†è‡³46145ï¼Œç¼©å‡ä¸ºåŸæ¥çš„18.39%ã€‚

### LLM-Pruner: On the Structural Pruning of Large Language Models
- https://github.com/horseee/LLM-Pruner
- https://arxiv.org/abs/2305.11627
- https://mp.weixin.qq.com/s/feqFfy4n31eztoZfodMieQ

åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬æå‡ºäº† LLM-Prunerï¼Œä¸€ç§ç”¨äºå¤§å‹è¯­è¨€æ¨¡å‹çš„ç»“æ„åŒ–å‰ªææ–¹æ³•ã€‚LLM-Pruner æ—¨åœ¨ä»¥ä»»åŠ¡æ— å…³çš„æ–¹å¼å‹ç¼©åºå¤§çš„è¯­è¨€æ¨¡å‹ï¼ŒåŒæ—¶å°½é‡å‡å°‘å¯¹åŸå§‹è®­ç»ƒè¯­æ–™åº“çš„ä¾èµ–ï¼Œå¹¶ä¿ç•™ LLM çš„è¯­è¨€èƒ½åŠ›ã€‚LLM-Pruner é€šè¿‡è¿­ä»£åœ°æ£€æŸ¥æ¨¡å‹ä¸­çš„æ¯ä¸ªç¥ç»å…ƒä½œä¸ºè¯†åˆ«ä¾èµ–ç»„çš„è§¦å‘å™¨ï¼Œä»è€Œæ„å»º LLM çš„ä¾èµ–å›¾ã€‚éšåï¼ŒLLM-Pruner ä½¿ç”¨å‚æ•°çº§å’Œæƒé‡çº§ä¼°è®¡æ¥è¯„ä¼°è¿™äº›ç»„çš„é‡è¦æ€§ã€‚

æœ€åï¼Œæˆ‘ä»¬åˆ©ç”¨ LoRA å¯¹è¢«å‰ªææ¨¡å‹è¿›è¡Œå¿«é€Ÿæ¢å¤å’Œè°ƒæ•´ã€‚æˆ‘ä»¬ä½¿ç”¨å¤šä¸ª zero-shot æ•°æ®é›†è¯„ä¼°äº† LLM-Pruner åœ¨ä¸‰ä¸ªä¸åŒæ¨¡å‹ï¼ˆLLaMAï¼ŒVicuna å’Œ ChatGLMï¼‰ä¸Šçš„æœ‰æ•ˆæ€§ã€‚æˆ‘ä»¬çš„å®éªŒç»“æœè¡¨æ˜ï¼ŒLLM-Pruner æˆåŠŸåœ°å‰ªæäº†æ¨¡å‹ï¼Œåœ¨ä¿ç•™ zero-shot èƒ½åŠ›çš„åŒæ—¶å‡è½»äº†è®¡ç®—è´Ÿæ‹…ã€‚

### LLM for Recommendation Systems
- https://github.com/WLiK/LLM4Rec
- https://arxiv.org/abs/2305.19860
- https://mp.weixin.qq.com/s/WCUjCahiak4STbb0QjJInQ

Large Language Models (LLMs) have emerged as powerful tools in the field of Natural Language Processing (NLP) and have recently gained significant attention in the domain of Recommendation Systems (RS). These models, trained on massive amounts of data using self-supervised learning, have demonstrated remarkable success in learning universal representations and have the potential to enhance various aspects of recommendation systems by some effective transfer techniques such as fine-tuning and prompt tuning, and so on. The crucial aspect of harnessing the power of language models in enhancing recommendation quality is the utilization of their high-quality representations of textual features and their extensive coverage of external knowledge to establish correlations between items and users. To provide a comprehensive understanding of the existing LLM-based recommendation systems, this survey presents a taxonomy that categorizes these models into two major paradigms, respectively Discriminative LLM for Recommendation (DLLM4Rec) and Generative LLM for Recommendation (GLLM4Rec), with the latter being systematically sorted out for the first time. Furthermore, we systematically review and analyze existing LLM-based recommendation systems within each paradigm, providing insights into their methodologies, techniques, and performance. Additionally, we identify key challenges and several valuable findings to provide researchers and practitioners with inspiration.

### Self-Instruct
- https://github.com/yizhongw/self-instruct
- https://arxiv.org/abs/2212.10560

Self-Instruct is a framework that helps language models improve their ability to follow natural language instructions. It does this by using the model's own generations to create a large collection of instructional data. With Self-Instruct, it is possible to improve the instruction-following capabilities of language models without relying on extensive manual annotation.

### ToolBench&ToolLLM
- https://github.com/OpenBMB/ToolBench
- https://arxiv.org/pdf/2304.08354.pdf
- https://arxiv.org/pdf/2307.16789.pdf
- https://mp.weixin.qq.com/s/DuoQJj1OBl5iFPvjidDiCg

This project (ToolBench)  aims to construct open-source, large-scale, high-quality instruction tuning SFT data to facilitate the construction of powerful LLMs with general tool-use capability. We provide the dataset, the corresponding training and evaluation scripts, and a capable model ToolLLaMA fine-tuned on ToolBench.

ğŸ”¨This project (ToolLLM) aims to construct open-source, large-scale, high-quality instruction tuning SFT data to facilitate the construction of powerful LLMs with general tool-use capability. We aim to empower open-source LLMs to master thousands of diverse real-world APIs. We achieve this by collecting a high-quality instruction-tuning dataset. It is constructed automatically using the latest ChatGPT (gpt-3.5-turbo-16k), which is upgraded with enhanced function call capabilities. We provide the dataset, the corresponding training and evaluation scripts, and a capable model ToolLLaMA fine-tuned on ToolBench.

### Wanda (Pruning by Weights and activations)
- https://github.com/locuslab/wanda
- https://mp.weixin.qq.com/s/UoQLCQiFnKZUQPedDM_MCQ
- https://arxiv.org/pdf/2306.11695.pdf

A Simple and Effective Pruning Approach for Large Language Models

### Streaming LLM
- https://github.com/mit-han-lab/streaming-llm

Deploying Large Language Models (LLMs) in streaming applications such as multi-round dialogue, where long interactions are expected, is urgently needed but poses two major challenges. Firstly, during the decoding stage, caching previous tokens' Key and Value states (KV) consumes extensive memory. Secondly, popular LLMs cannot generalize to longer texts than the training sequence length. Window attention, where only the most recent KVs are cached, is a natural approach --- but we show that it fails when the text length surpasses the cache size. We observe an interesting phenomenon, namely attention sink, that keeping the KV of initial tokens will largely recover the performance of window attention. In this paper, we first demonstrate that the emergence of attention sink is due to the strong attention scores towards initial tokens as a ``sink'' even if they are not semantically important. Based on the above analysis, we introduce StreamingLLM, an efficient framework that enables LLMs trained with a finite length attention window to generalize to infinite sequence length without any fine-tuning. We show that StreamingLLM can enable Llama-2, MPT, Falcon, and Pythia to perform stable and efficient language modeling with up to 4 million tokens and more. In addition, we discover that adding a placeholder token as a dedicated attention sink during pre-training can further improve streaming deployment. In streaming settings, StreamingLLM outperforms the sliding window recomputation baseline by up to 22.2x speedup.

### Sheared LLAMA (Structured Pruning)
- https://xiamengzhou.github.io/sheared-llama/

We introduce the Sheared-LLaMA models, the strongest 1.3B and 2.7B public base large language models (LLMs). Our models are produced by LLM-Shearing, an efficient method of constructing LLMs by first pruning a larger existing model and then continually pre-training it. Sheared-LLaMA models are first pruned from the LLaMA2-7B model, and then trained on only 50B tokens, 5% budget of the previous strongest public 3B model.

### QA-LoRA
- https://arxiv.org/abs/2309.14717
- https://github.com/yuhuixu1993/qa-lora

Recently years have witnessed a rapid development of large language models (LLMs). Despite the strong ability in many language-understanding tasks, the heavy computational burden largely restricts the application of LLMs especially when one needs to deploy them onto edge devices. In this paper, we propose a quantization-aware low-rank adaptation (QA-LoRA) algorithm. The motivation lies in the imbalanced degrees of freedom of quantization and adaptation, and the solution is to use group-wise operators which increase the degree of freedom of quantization meanwhile decreasing that of adaptation. QA-LoRA is easily implemented with a few lines of code, and it equips the original LoRA with two-fold abilities: (i) during fine-tuning, the LLM's weights are quantized (e.g., into INT4) to reduce time and memory usage; (ii) after fine-tuning, the LLM and auxiliary weights are naturally integrated into a quantized model without loss of accuracy. We apply QA-LoRA to the LLaMA and LLaMA2 model families and validate its effectiveness in different fine-tuning datasets and downstream scenarios. 

### AgentLM (AgentTuning, AgentInstruct)
- https://github.com/THUDM/AgentTuning

AgentTuning represents the very first attempt to instruction-tune LLMs using interaction trajectories across multiple agent tasks. Evaluation results indicate that AgentTuning enables the agent capabilities of LLMs with robust generalization on unseen agent tasks while remaining good on general language abilities. We have open-sourced the AgentInstruct dataset and AgentLM.

### XAgent
- https://github.com/OpenBMB/XAgent

XAgent is an open-source experimental Large Language Model (LLM) driven autonomous agent that can automatically solve various tasks. It is designed to be a general-purpose agent that can be applied to a wide range of tasks. XAgent is still in its early stages, and we are working hard to improve it.

ğŸ† Our goal is to create a super-intelligent agent that can solve any given task!

### OpenAgents
- https://github.com/xlang-ai/OpenAgents

Current language agent frameworks aim to facilitate the construction of proof-of-concept language agents while neglecting the non-expert user access to agents and paying little attention to application-level designs. We built OpenAgents, an open platform for using and hosting language agents in the wild of everyday life.

### gpu_poor
- https://github.com/RahulSChand/gpu_poor

Calculate how much GPU memory you need & breakdown of where it goes for training/inference of any LLM model with quantization (GGML/bitsandbytes), inference frameworks (vLLM/llama.cpp/HF) & QLoRA.

### CAMEL:Communicative Agents for â€œMindâ€ Exploration of Large Scale Language Model Society 
- https://ghli.org/camel.pdf 
- https://github.com/camel-ai/camel 
- https://www.camel-ai.org/

CAMEL-AI.org is an open-source community dedicated to the study of autonomous and communicative agents. We believe that studying these agents on a large scale offers valuable insights into their behaviors, capabilities, and potential risks. To facilitate research in this field, we provide, implement, and support various types of agents, tasks, prompts, models, datasets, and simulated environments.

### Transformer Index for GEnerative Recommenders (TIGER)
- https://arxiv.org/pdf/2305.05065.pdf

Modern recommender systems perform large-scale retrieval by first embedding queries and item candidates in the same unified space, followed by approximate nearest neighbor search to select top candidates given a query embedding. In this paper, we propose a novel generative retrieval approach, where the retrieval model autoregressively decodes the identifiers of the target candidates. To that end, we create semantically meaningful tuple of codewords to serve as a Semantic ID for each item. Given Semantic IDs for items in a user session, a Transformer-based sequence-to-sequence model is trained to predict the Semantic ID of the next item that the user will interact with. To the best of our knowledge, this is the first Semantic ID-based generative model for recommendation tasks. We show that recommender systems trained with the proposed paradigm significantly outperform the current SOTA models on various datasets. In addition, we show that incorporating Semantic IDs into the sequence-to-sequence model enhances its ability to generalize, as evidenced by the improved retrieval performance observed for items with no prior interaction history.

### KnowPAT
- https://github.com/zjukg/KnowPAT
- https://arxiv.org/abs/2311.06503

Knowledgeable Preference Alignment for LLMs in Domain-specific Question Answering

For domain-specific application of large language models (LLMs), external knowledge and LLMs should work together to achieve best user experience. LLMs should acquire an ability to make the right choices about retrieved external knowledge to meet the human needs. Knowledgeable Preference AlignmenT (KnowPAT) is a new pipeline to align LLMs with human's knowledge preference. KnowPAT incorporates domain knowledge graphs to construct preference set and design new alignment objective to fine-tune the LLMs.

### AuthentiGPT: Detecting Machine-Generated Text
- https://arxiv.org/abs/2311.07700

Large language models (LLMs) have opened up enormous opportunities while simultaneously posing ethical dilemmas. One of the major concerns is their ability to create text that closely mimics human writing, which can lead to potential misuse, such as academic misconduct, disinformation, and fraud. To address this problem, we present AuthentiGPT, an efficient classifier that distinguishes between machine-generated and human-written texts. Under the assumption that human-written text resides outside the distribution of machine-generated text, AuthentiGPT leverages a black-box LLM to denoise input text with artificially added noise, and then semantically compares the denoised text with the original to determine if the content is machine-generated. With only one trainable parameter, AuthentiGPT eliminates the need for a large training dataset, watermarking the LLM's output, or computing the log-likelihood. Importantly, the detection capability of AuthentiGPT can be easily adapted to any generative language model. With a 0.918 AUROC score on a domain-specific dataset, AuthentiGPT demonstrates its effectiveness over other commercial algorithms, highlighting its potential for detecting machine-generated text in academic settings.

### Curiosity-driven Red-teaming for Large Language Models
- https://openreview.net/forum?id=4KqkizXgXU

Large language models (LLMs) hold great potential for various natural language applications but risk generating incorrect or toxic content. In order to probe when an LLM generates unwanted content, the current paradigm is to recruit human testers to create input prompts (i.e., test cases) designed to elicit unfavorable responses from LLMs. This procedure is called red teaming. However, relying solely on human testers can be both expensive and time-consuming. Recent works automate red teaming by training LLMs (i.e., red team LLMs) with reinforcement learning (RL) to maximize the chance of eliciting undesirable responses (i.e., successful test cases) from the target LLMs being evaluated. However, while effective at provoking undesired responses, current RL methods lack test case diversity as RL-based methods tend to consistently generate the same few successful test cases once found. To overcome this limitation, we introduce curiosity-driven exploration to train red team models. This approach jointly maximizes the test case effectiveness and novelty. Maximizing novelty motivates the red-team model to search for new and diverse test cases. We evaluate our method by performing red teaming against LLMs in text continuation and instruction following tasks. Our experiments show that curiosity-driven exploration achieves greater diversity in all the experiments compared to existing RL-based red team methods while maintaining effectiveness. Remarkably, curiosity-driven exploration also enhances the effectiveness when performing red teaming in instruction following test cases, generating a higher number of successful test cases. We even demonstrate that curiosity-driven exploration successfully provokes toxic responses from the LLaMA2 model that has undergone finetuning based on human preferences.

### Language Models are Super Marioï¼ˆDARE, Drop And REscaleï¼‰
- https://arxiv.org/pdf/2311.03099.pdf
- https://github.com/yule-BUAA/MergeLM

In this work, we uncover that Language Models (LMs), either encoder- or decoder-based, can obtain new capabilities by assimilating the parameters of homologous models without the need for retraining or GPUs.

- We introduce a novel operation called DARE to directly set most of (90% or even 99%) the delta parameters to zeros without affecting the capabilities of SFT LMs.
- We sparsify delta parameters of multiple SFT homologous models with DARE as a general preprocessing technique and subsequently merge them into a single model by parameter averaging.

### TinyGSM
- https://arxiv.org/abs/2312.09241

Small-scale models offer various computational advantages, and yet to which extent size is critical for problem-solving abilities remains an open question. Specifically for solving grade school math, the smallest model size so far required to break the 80% barrier on the GSM8K benchmark remains to be 34B. Our work studies how high-quality datasets may be the key for small language models to acquire mathematical reasoning. We introduce TinyGSM, a synthetic dataset of 12.3M grade school math problems paired with Python solutions, generated fully by GPT-3.5. After finetuning on TinyGSM, we find that a duo of a 1.3B generation model and a 1.3B verifier model can achieve 81.5% accuracy, outperforming existing models that are orders of magnitude larger. This also rivals the performance of the GPT-3.5 teacher model (77.4%), from which our model's training data is generated. Our approach is simple and has two key components: 1) the high-quality dataset TinyGSM, 2) the use of a verifier, which selects the final outputs from multiple candidate generations.

### MathPile
- https://huggingface.co/papers/2312.17120
- https://gair-nlp.github.io/MathPile/
- https://github.com/GAIR-NLP/MathPile
- https://huggingface.co/datasets/GAIR/MathPile
- https://huggingface.co/datasets/GAIR/MathPile_Commercial

High-quality, large-scale corpora are the cornerstone of building powerful foundation models. In this work, we introduce MathPile a diverse and high-quality math-centric corpus comprising about 9.5 billion tokens. 

### Blending Is All You Need: Cheaper, Better Alternative to Trillion-Parameters LLM
- https://huggingface.co/ChaiML
- https://arxiv.org/pdf/2401.02994.pdf

In conversational AI research, there's a noticeable trend towards developing models with a larger number of parameters, exemplified by models like ChatGPT. While these expansive models tend to generate increasingly better chat responses, they demand significant computational resources and memory. This study explores a pertinent question: Can a combination of smaller models collaboratively achieve comparable or enhanced performance relative to a singular large model? We introduce an approach termed "blending", a straightforward yet effective method of integrating multiple chat AIs. Our empirical evidence suggests that when specific smaller models are synergistically blended, they can potentially outperform or match the capabilities of much larger counterparts. For instance, integrating just three models of moderate size (6B/13B paramaeters) can rival or even surpass the performance metrics of a substantially larger model like ChatGPT (175B+ paramaters). This hypothesis is rigorously tested using A/B testing methodologies with a large user base on the Chai research platform over a span of thirty days. The findings underscore the potential of the "blending" strategy as a viable approach for enhancing chat AI efficacy without a corresponding surge in computational demands.

### Personal LLM Agents - Survey
- https://github.com/MobileLLM/Personal_LLM_Agents_Survey
- https://arxiv.org/abs/2401.05459

Personal LLM Agents are defined as a special type of LLM-based agents that are deeply integrated with personal data, personal devices, and personal services. They are perferably deployed to resource-constrained mobile/edge devices and/or powered by lightweight AI models. The main purpose of personal LLM agents is to assist end-users and augment their abilities, helping them to focus more and do better on interesting and important affairs.

### AUTOACT
- https://arxiv.org/abs/2401.05268
- https://github.com/zjunlp/AutoAct

Language agents have achieved considerable performance on various complex tasks. Despite the incessant exploration in this field, existing language agent systems still struggle with costly, non-reproducible data reliance and face the challenge of compelling a single model for multiple functions. To this end, we introduce AutoAct, an automatic agent learning framework that does not rely on large-scale annotated data and synthetic trajectories from closed-source models (e.g., GPT-4). Given limited data with a tool library, AutoAct first automatically synthesizes planning trajectories without any assistance from humans or strong closed-source models. Then, AutoAct leverages a division-of-labor strategy to automatically differentiate based on the target task information and synthesized trajectories, producing a sub-agent group to complete the task. We conduct comprehensive experiments with different LLMs, which demonstrates that AutoAct yields better or parallel performance compared to various strong baselines. We even notice that AutoAct, when using the Llama-2-13b model, can achieve performance comparable to that of the zero-shot GPT-3.5-Turbo agent.

### MetaGPT
- https://arxiv.org/abs/2308.00352
- https://github.com/geekan/MetaGPT

Remarkable progress has been made on automated problem solving through societies of agents based on large language models (LLMs). Existing LLM-based multi-agent systems can already solve simple dialogue tasks. Solutions to more complex tasks, however, are complicated through logic inconsistencies due to cascading hallucinations caused by naively chaining LLMs. Here we introduce MetaGPT, an innovative meta-programming framework incorporating efficient human workflows into LLM-based multi-agent collaborations. MetaGPT encodes Standardized Operating Procedures (SOPs) into prompt sequences for more streamlined workflows, thus allowing agents with human-like domain expertise to verify intermediate results and reduce errors. MetaGPT utilizes an assembly line paradigm to assign diverse roles to various agents, efficiently breaking down complex tasks into subtasks involving many agents working together. On collaborative software engineering benchmarks, MetaGPT generates more coherent solutions than previous chat-based multi-agent systems. 

### Multi-LLM-Agent
- https://github.com/X-PLUG/Multi-LLM-Agent
- https://arxiv.org/abs/2401.07324

Large Language Model (LLM) agents significantly extend the capabilities of standalone LLMs, empowering them to interact with external tools (e.g., APIs, functions) and complete complex tasks in a self-directed fashion. The challenge of tool use demands that LLMs not only understand user queries and generate answers but also excel in task planning, memory management, tool invocation, and result summarization. While traditional approaches focus on training a single LLM with all these capabilities, performance limitations become apparent, particularly with smaller models. Moreover, the entire LLM may require retraining when tools are updated. To overcome these challenges, we propose a novel strategy that decomposes the aforementioned capabilities into a planner, caller, and summarizer. Each component is implemented by a single LLM that focuses on a specific capability and collaborates with other components to accomplish the task. This modular framework facilitates individual updates and the potential use of smaller LLMs for building each capability. To effectively train this framework, we introduce a two-stage training paradigm. First, we fine-tune a backbone LLM on the entire dataset without discriminating sub-tasks, providing the model with a comprehensive understanding of the task. Second, the fine-tuned LLM is used to instantiate the planner, caller, and summarizer respectively, which are continually fine-tuned on respective sub-tasks. Evaluation across various tool-use benchmarks illustrates that our proposed multi-LLM framework surpasses the traditional single-LLM approach, highlighting its efficacy and advantages in tool learning.

### More Agents Is All You Need
- https://arxiv.org/abs/2402.05120
- https://anonymous.4open.science/r/more_agent_is_all_you_need

We find that, simply via a sampling-and-voting method, the performance of large language models (LLMs) scales with the number of agents instantiated. Also, this method is orthogonal to existing complicated methods to further enhance LLMs, while the degree of enhancement is correlated to the task difficulty. We conduct comprehensive experiments on a wide range of LLM benchmarks to verify the presence of our finding, and to study the properties that can facilitate its occurrence.

### Mistral-Interact
- https://github.com/HBX-hbx/Mistral-Interact
- https://arxiv.org/abs/2402.09205

Current language model-driven agents often lack mechanisms for effective user participation, which is crucial given the vagueness commonly found in user instructions. Although adept at devising strategies and performing tasks, these agents struggle with seeking clarification and grasping precise user intentions. To bridge this gap, we introduce Intention-in-Interaction (IN3), a novel benchmark designed to inspect users' implicit intentions through explicit queries. Next, we propose the incorporation of model experts as the upstream in agent designs to enhance user-agent interaction. Employing IN3, we empirically train Mistral-Interact, a powerful model that proactively assesses task vagueness, inquires user intentions, and refines them into actionable goals before starting downstream agent task execution. Integrating it into the XAgent framework, we comprehensively evaluate the enhanced agent system regarding user instruction understanding and execution, revealing that our approach notably excels at identifying vague user tasks, recovering and summarizing critical missing information, setting precise and necessary agent execution goals, and minimizing redundant tool usage, thus boosting overall efficiency. All the data and codes are released.

### AgentLite
- https://github.com/SalesforceAIResearch/AgentLite
- https://arxiv.org/abs/2402.15538

AgentLite is a research-oriented library designed for building and advancing LLM-based task-oriented agent systems. It simplifies the implementation of new agent/multi-agent architectures, enabling easy orchestration of multiple agents through a manager agent. Whether you're building individual agents or complex multi-agent systems, AgentLite provides a straightforward and lightweight foundation for your research and development.

### KnowAgent
- https://www.zjukg.org/project/KnowAgent/
- https://arxiv.org/abs/2403.03101
- https://github.com/zjunlp/KnowAgent

Our development is grounded on several key steps: Initially, we create an extensive action knowledge base, which amalgamates action planning knowledge pertinent to specific tasks. This database acts as an external reservoir of information, steering the model's action generation process. Subsequently, by converting action knowledge into text, we enable the model to deeply understand and utilize this knowledge in creating action trajectories. Finally, through a knowledgeable self-learning phase, we use trajectories developed from the model's iterative processes to continually improve its understanding and application of action knowledge. This process not only strengthens the agents' planning abilities but also enhances their potential for application in complex situations.

### LlamaGym
- https://github.com/KhoomeiK/LlamaGym

"Agents" originated in reinforcement learning, where they learn by interacting with an environment and receiving a reward signal. However, LLM-based agents today do not learn online (i.e. continuously in real time) via reinforcement.

OpenAI created Gym to standardize and simplify RL environments, but if you try dropping an LLM-based agent into a Gym environment for training, you'd find it's still quite a bit of code to handle LLM conversation context, episode batches, reward assignment, PPO setup, and more.

LlamaGym seeks to simplify fine-tuning LLM agents with RL. Right now, it's a single Agent abstract class that handles all the issues mentioned above, letting you quickly iterate and experiment with agent prompting & hyperparameters across any Gym environment.

### WorkArena
- https://arxiv.org/abs/2403.07718
- https://github.com/ServiceNow/WorkArena
- https://github.com/ServiceNow/BrowserGym

We study the use of large language model-based agents for interacting with software via web browsers. Unlike prior work, we focus on measuring the agents' ability to perform tasks that span the typical daily work of knowledge workers utilizing enterprise software systems. To this end, we propose WorkArena, a remote-hosted benchmark of 29 tasks based on the widely-used ServiceNow platform. We also introduce BrowserGym, an environment for the design and evaluation of such agents, offering a rich set of actions as well as multimodal observations. Our empirical evaluation reveals that while current agents show promise on WorkArena, there remains a considerable gap towards achieving full task automation. Notably, our analysis uncovers a significant performance disparity between open and closed-source LLMs, highlighting a critical area for future exploration and development in the field.

### AgentBench
- https://llmbench.ai/agent
- https://github.com/THUDM/AgentBench

æˆ‘ä»¬æå‡ºäº†AgentBenchï¼Œè¿™æ˜¯ä¸€ä¸ªå¤šç»´æ¼”è¿›åŸºå‡†æµ‹è¯•ï¼ŒåŒ…æ‹¬8ä¸ªä¸åŒç¯å¢ƒï¼Œç”¨äºè¯„ä¼°å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMsï¼‰åœ¨å¤šå›åˆå¼€æ”¾å¼ç”Ÿæˆç¯å¢ƒä¸­çš„æ¨ç†å’Œå†³ç­–èƒ½åŠ›ã€‚é€šè¿‡å¯¹25ä¸ªè¯­è¨€æ¨¡å‹çš„å¹¿æ³›æµ‹è¯•ï¼Œæˆ‘ä»¬å‘ç°é¡¶çº§å•†ä¸šè¯­è¨€æ¨¡å‹åœ¨å¤æ‚ç¯å¢ƒä¸­è¡¨ç°å‡ºè‰²ï¼Œä¸”ä¸å¼€æºæ¨¡å‹ä¹‹é—´å­˜åœ¨æ˜¾è‘—å·®è·ã€‚

### ä¸­æ–‡MT-Bench
- https://github.com/HIT-SCIR/huozi

æœ¬æ•°æ®é›†æ˜¯è‹±æ–‡MT-Benchå¯¹è¯èƒ½åŠ›è¯„æµ‹æ•°æ®é›†çš„ä¸­æ–‡ç‰ˆã€‚å®ƒåŒ…å«äº†ä¸€ç³»åˆ—å¤šè½®å¯¹è¯é—®é¢˜ï¼Œæ¯ä¸€ç»„é—®é¢˜éƒ½ç»è¿‡äº†ç²¾å¿ƒçš„äººå·¥æ ¡å¯¹ï¼Œå¹¶ä¸ºé€‚åº”ä¸­æ–‡è¯­å¢ƒè¿›è¡Œäº†å¿…è¦çš„è°ƒæ•´ã€‚

### E-EVAL
- https://eevalbenchmark.com
- https://github.com/AI-EDU-LAB/E-EVAL
- https://arxiv.org/abs/2401.15927

E-EVAL is a comprehensive Chinese K12 education evaluation benchmark that contains 4,352 multiple-choice questions across three difficulty levels, primary, middle and high school, for a total of 23 subjects.

### ConflictingQA
- https://arxiv.org/abs/2402.11782
- https://github.com/AlexWan0/rag-convincingness

Retrieval-augmented language models are being increasingly tasked with subjective, contentious, and conflicting queries such as "is aspartame linked to cancer". To resolve these ambiguous queries, one must search through a large range of websites and consider "which, if any, of this evidence do I find convincing?". In this work, we study how LLMs answer this question. In particular, we construct ConflictingQA, a dataset that pairs controversial queries with a series of real-world evidence documents that contain different facts (e.g., quantitative results), argument styles (e.g., appeals to authority), and answers (Yes or No). We use this dataset to perform sensitivity and counterfactual analyses to explore which text features most affect LLM predictions. Overall, we find that current models rely heavily on the relevance of a website to the query, while largely ignoring stylistic features that humans find important such as whether a text contains scientific references or is written with a neutral tone. Taken together, these results highlight the importance of RAG corpus quality (e.g., the need to filter misinformation), and possibly even a shift in how LLMs are trained to better align with human judgements.

### Medical Information Retrieval-Augmented Generation Evaluation ï¼ˆMIRAGEï¼‰
- https://arxiv.org/abs/2402.13178
- https://teddy-xionggz.github.io/benchmark-medical-rag/

While large language models (LLMs) have achieved state-of-the-art performance on a wide range of medical question answering (QA) tasks, they still face challenges with hallucinations and outdated knowledge. Retrieval-augmented generation (RAG) is a promising solution and has been widely adopted. However, a RAG system can involve multiple flexible components, and there is a lack of best practices regarding the optimal RAG setting for various medical purposes. To systematically evaluate such systems, we propose the Medical Information Retrieval-Augmented Generation Evaluation (MIRAGE), a first-of-its-kind benchmark including 7,663 questions from five medical QA datasets. Using MIRAGE, we conducted large-scale experiments with over 1.8 trillion prompt tokens on 41 combinations of different corpora, retrievers, and backbone LLMs through the MedRAG toolkit introduced in this work. Overall, MedRAG improves the accuracy of six different LLMs by up to 18% over chain-of-thought prompting, elevating the performance of GPT-3.5 and Mixtral to GPT-4-level. Our results show that the combination of various medical corpora and retrievers achieves the best performance. In addition, we discovered a log-linear scaling property and the "lost-in-the-middle" effects in medical RAG. We believe our comprehensive evaluations can serve as practical guidelines for implementing RAG systems for medicine.

### âˆBench
- https://arxiv.org/abs/2402.13718
- https://github.com/OpenBMB/InfiniteBench

Processing and reasoning over long contexts is crucial for many practical applications of Large Language Models (LLMs), such as document comprehension and agent construction. Despite recent strides in making LLMs process contexts with more than 100K tokens, there is currently a lack of a standardized benchmark to evaluate this long-context capability. Existing public benchmarks typically focus on contexts around 10K tokens, limiting the assessment and comparison of LLMs in processing longer contexts. In this paper, we propose âˆBench, the first LLM benchmark featuring an average data length surpassing 100K tokens. âˆBench comprises synthetic and realistic tasks spanning diverse domains, presented in both English and Chinese. The tasks in âˆBench are designed to require well understanding of long dependencies in contexts, and make simply retrieving a limited number of passages from contexts not sufficient for these tasks. In our experiments, based on âˆBench, we evaluate the state-of-the-art proprietary and open-source LLMs tailored for processing long contexts. The results indicate that existing long context LLMs still require significant advancements to effectively process 100K+ context. We further present three intriguing analyses regarding the behavior of LLMs processing long context.

### Red Teaming Resistance Benchmark
- https://huggingface.co/spaces/HaizeLabs/red-teaming-resistance-benchmark
- https://github.com/haizelabs/redteaming-resistance-benchmark

Hello! This repository contains the code and data used to benchmark redteaming prompts against various models as seen in our Huggingface Leaderboard. This project is aimed to reveal weaknesses in both open-sourced and blackbox language models through redteaming attacks covering a diverse range of behaviors and topics.


### Unlocking Efficiency in Large Language Model Inference: A Comprehensive Survey of Speculative Decoding
- https://github.com/hemingkx/SpeculativeDecodingPapers
- https://arxiv.org/abs/2401.07851

To mitigate the high inference latency stemming from autoregressive decoding in Large Language Models (LLMs), Speculative Decoding has emerged as a novel decoding paradigm for LLM inference. In each decoding step, this method first efficiently drafts several future tokens and then verifies them in parallel. Unlike autoregressive decoding, Speculative Decoding facilitates the simultaneous decoding of multiple tokens per step, thereby accelerating inference. This paper presents a comprehensive overview and analysis of this promising decoding paradigm. We begin by providing a formal definition and formulation of Speculative Decoding. Then, we organize in-depth discussions on its key facets, including current leading techniques, the challenges faced, and potential future directions in this field. We aim for this work to serve as a catalyst for further research on Speculative Decoding, ultimately contributing to more efficient LLM inference.

### QAnything
- https://github.com/netease-youdao/QAnything

QAnything(Question and Answer based on Anything) is a local knowledge base question-answering system designed to support a wide range of file formats and databases, allowing for offline installation and use.

With QAnything, you can simply drop any locally stored file of any format and receive accurate, fast, and reliable answers.

Currently supported formats include: PDF, Word (doc/docx), PPT, Markdown, Eml, TXT, Images (jpg, png, etc.), Web links and more formats coming soonâ€¦

### Meta-Prompting
- https://arxiv.org/abs/2401.12954
- https://github.com/suzgunmirac/meta-prompting

We introduce meta-prompting, an effective scaffolding technique designed to enhance the functionality of language models (LMs). This approach transforms a single LM into a multi-faceted conductor, adept at managing and integrating multiple independent LM queries. By employing high-level instructions, meta-prompting guides the LM to break down complex tasks into smaller, more manageable subtasks. These subtasks are then handled by distinct "expert" instances of the same LM, each operating under specific, tailored instructions. Central to this process is the LM itself, in its role as the conductor, which ensures seamless communication and effective integration of the outputs from these expert models. It additionally employs its inherent critical thinking and robust verification processes to refine and authenticate the end result. This collaborative prompting approach empowers a single LM to simultaneously act as a comprehensive orchestrator and a panel of diverse experts, significantly enhancing its performance across a wide array of tasks. The zero-shot, task-agnostic nature of meta-prompting greatly simplifies user interaction by obviating the need for detailed, task-specific instructions. Furthermore, our research demonstrates the seamless integration of external tools, such as a Python interpreter, into the meta-prompting framework, thereby broadening its applicability and utility. Through rigorous experimentation with GPT-4, we establish the superiority of meta-prompting over conventional scaffolding methods: When averaged across all tasks, including the Game of 24, Checkmate-in-One, and Python Programming Puzzles, meta-prompting, augmented with a Python interpreter functionality, surpasses standard prompting by 17.1%, expert (dynamic) prompting by 17.3%, and multipersona prompting by 15.2%.

### Lepton Search
- https://github.com/leptonai/search_with_lepton

Build your own conversational search engine using less than 500 lines of code.

### RLMRec
- https://github.com/HKUDS/RLMRec
- https://arxiv.org/abs/2310.15950

Recommender systems have seen significant advancements with the influence of deep learning and graph neural networks, particularly in capturing complex user-item relationships. However, these graph-based recommenders heavily depend on ID-based data, potentially disregarding valuable textual information associated with users and items, resulting in less informative learned representations. Moreover, the utilization of implicit feedback data introduces potential noise and bias, posing challenges for the effectiveness of user preference learning. While the integration of large language models (LLMs) into traditional ID-based recommenders has gained attention, challenges such as scalability issues, limitations in text-only reliance, and prompt input constraints need to be addressed for effective implementation in practical recommender systems. To address these challenges, we propose a model-agnostic framework RLMRec that aims to enhance existing recommenders with LLM-empowered representation learning. It proposes a recommendation paradigm that integrates representation learning with LLMs to capture intricate semantic aspects of user behaviors and preferences. RLMRec incorporates auxiliary textual signals, develops a user/item profiling paradigm empowered by LLMs, and aligns the semantic space of LLMs with the representation space of collaborative relational signals through a cross-view alignment framework. This work further establish a theoretical foundation demonstrating that incorporating textual signals through mutual information maximization enhances the quality of representations. In our evaluation, we integrate RLMRec with state-of-the-art recommender models, while also analyzing its efficiency and robustness to noise data.

### Open-Source AI Cookbook
- https://huggingface.co/learn/cookbook/

The Open-Source AI Cookbook is a collection of notebooks illustrating practical aspects of building AI applications and solving various machine learning tasks using open-source tools and models.

### MaLA-500
- https://huggingface.co/MaLA-LM/mala-500
- https://arxiv.org/abs/2401.13303

Large language models have advanced the state of the art in natural language processing. However, their predominant design for English or a limited set of languages creates a substantial gap in their effectiveness for low-resource languages. To bridge this gap, we introduce MaLA-500, a novel large language model designed to cover an extensive range of 534 languages. To train MaLA-500, we employ vocabulary extension and continued pretraining on LLaMA 2 with Glot500-c. Our experiments on SIB-200 show that MaLA-500 achieves state-of-the-art in-context learning results.

### NVIDIA Chat with RTX
- https://www.nvidia.com/en-us/ai-on-rtx/chat-with-rtx-generative-ai/

Chat With RTX is a demo app that lets you personalize a GPT large language model (LLM) connected to your own contentâ€”docs, notes, videos, or other data. Leveraging retrieval-augmented generation (RAG), TensorRT-LLM, and RTX acceleration, you can query a custom chatbot to quickly get contextually relevant answers. And because it all runs locally on your Windows RTX PC or workstation, youâ€™ll get fast and secure results.

### RAG vs Fine-tuning
- https://arxiv.org/pdf/2401.08406.pdf

There are two common ways in which developers are incorporating proprietary and domain-specific data when building applications of Large Language Models (LLMs): Retrieval-Augmented Generation (RAG) and Fine-Tuning. RAG augments the prompt with the external data, while fine-Tuning incorporates the additional knowledge into the model itself. However, the pros and cons of both approaches are not well understood. In this paper, we propose a pipeline for fine-tuning and RAG, and present the tradeoffs of both for multiple popular LLMs, including Llama2-13B, GPT-3.5, and GPT-4. Our pipeline consists of multiple stages, including extracting information from PDFs, generating questions and answers, using them for fine-tuning, and leveraging GPT-4 for evaluating the results. We propose metrics to assess the performance of different stages of the RAG and fine-Tuning pipeline. We conduct an in-depth study on an agricultural dataset. Agriculture as an industry has not seen much penetration of AI, and we study a potentially disruptive application - what if we could provide location-specific insights to a farmer? Our results show the effectiveness of our dataset generation pipeline in capturing geographic-specific knowledge, and the quantitative and qualitative benefits of RAG and fine-tuning. We see an accuracy increase of over 6 p.p. when fine-tuning the model and this is cumulative with RAG, which increases accuracy by 5 p.p. further. In one particular experiment, we also demonstrate that the fine-tuned model leverages information from across geographies to answer specific questions, increasing answer similarity from 47% to 72%. Overall, the results point to how systems built using LLMs can be adapted to respond and incorporate knowledge across a dimension that is critical for a specific industry, paving the way for further applications of LLMs in other industrial domains.

### Chain of Abstraction
- https://arxiv.org/pdf/2401.17464.pdf

To achieve faithful reasoning that aligns with human expectations, large language models (LLMs) need to ground their reasoning to real-world knowledge (e.g., web facts, math and physical rules). Tools help LLMs access this external knowledge, but there remains challenges for fine-tuning LLM agents (e.g., Toolformer) to invoke tools in multi-step reasoning problems, where inter-connected tool calls require holistic and efficient tool usage planning.
In this work, we propose a new method for LLMs to better leverage tools in multi-step reasoning. Our method, Chain-of-Abstraction (CoA), trains LLMs to first decode reasoning chains with abstract placeholders, and then call domain tools to reify each reasoning chain by filling in specific knowledge. This planning with abstract chains enables LLMs to learn more general reasoning strategies, which are robust to shifts of domain knowledge (e.g., math results) relevant to different reasoning questions. It also allows LLMs to perform decoding and calling of external tools in parallel, which avoids the inference delay caused by waiting for tool responses. In mathematical reasoning and Wiki QA domains, we show that our method consistently outperforms previous chain-of-thought and tool-augmented baselines on both in-distribution and out-of-distribution test sets, with an average ~6% absolute QA accuracy improvement. LLM agents trained with our method also show more efficient tool use, with inference speed being on average ~1.4x faster than baseline tool-augmented LLMs.

### åºåˆ—çŒ´å­å¼€æºæ•°æ®é›†
- https://github.com/mobvoi/seq-monkey-data

åºåˆ—çŒ´å­æ˜¯å‡ºé—¨é—®é—®æä¾›çš„è¶…å¤§è§„æ¨¡è¯­è¨€æ¨¡å‹ï¼ŒåŸºäºå…¶é€šç”¨çš„è¡¨ç¤ºä¸æ¨ç†èƒ½åŠ›ï¼Œæ”¯æŒå¤šè½®äº¤äº’ï¼Œèƒ½å¤Ÿå¤§å¹…åº¦æé«˜ç”Ÿäº§æ•ˆç‡å’Œæ•°æ®å¤„ç†èƒ½åŠ›ï¼Œè¢«å¹¿æ³›åº”ç”¨äºé—®ç­”ç³»ç»Ÿã€è‡ªç„¶è¯­è¨€å¤„ç†ã€æœºå™¨ç¿»è¯‘ã€æ–‡æœ¬æ‘˜è¦ç­‰é¢†åŸŸã€‚

åºåˆ—çŒ´å­æ•°æ®é›†æ˜¯ç”¨äºè®­ç»ƒåºåˆ—çŒ´å­æ¨¡å‹çš„æ•°æ®é›†åˆï¼Œç°é€‰æ‹©éƒ¨åˆ†æ•°æ®é›†å‘å…¬ä¼—å¼€æ”¾ã€‚

### Transformer Debugger
- https://github.com/openai/transformer-debugger

Transformer Debugger (TDB) is a tool developed by OpenAI's Superalignment team with the goal of supporting investigations into specific behaviors of small language models. The tool combines automated interpretability techniques with sparse autoencoders.

TDB enables rapid exploration before needing to write code, with the ability to intervene in the forward pass and see how it affects a particular behavior. It can be used to answer questions like, "Why does the model output token A instead of token B for this prompt?" or "Why does attention head H attend to token T for this prompt?" It does so by identifying specific components (neurons, attention heads, autoencoder latents) that contribute to the behavior, showing automatically generated explanations of what causes those components to activate most strongly, and tracing connections between components to help discover circuits.

### RecAI
- https://arxiv.org/abs/2403.06465
- https://github.com/microsoft/RecAI

This paper introduces RecAI, a practical toolkit designed to augment or even revolutionize recommender systems with the advanced capabilities of Large Language Models (LLMs). RecAI provides a suite of tools, including Recommender AI Agent, Recommendation-oriented Language Models, Knowledge Plugin, RecExplainer, and Evaluator, to facilitate the integration of LLMs into recommender systems from multifaceted perspectives. The new generation of recommender systems, empowered by LLMs, are expected to be more versatile, explainable, conversational, and controllable, paving the way for more intelligent and user-centric recommendation experiences. We hope the open-source of RecAI can help accelerate evolution of new advanced recommender systems. 

> æŒç»­æ›´æ–°ä¸­ (Continuously Updated)... 
